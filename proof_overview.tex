\section{Overview of the proof strategy}\label{sec:proof_outline}

The key result in this paper is Theorem~\ref{thm:local_clustering_hyperbolic}. In particular, it is the key ingredient in the proofs of Theorem~\ref{thm:clustering_coefficient_hyperbolic} and Theorem~\ref{thm:asymptotics_average_clustering_P}. Therefore, in this section we first give a detailed overview of the structure for the proof of Theorem~\ref{thm:local_clustering_hyperbolic}. The proof itself, based on intermediate propositions, can be found in Section~\ref{ssec:proof_main_results}. Here we also prove Theorem~\ref{thm:clustering_coefficient_hyperbolic}. The proof of Theorem~\ref{thm:asymptotics_average_clustering_P} can be found in Section~\ref{sec:asymptotics_average_clustering_ast_P} where we also derive the exact expressions for $c_\infty$ and $c_\infty(k)$.

Figure~\ref{fig:overview_proof} shows a schematic overview of the proof of Theorem~\ref{thm:local_clustering_hyperbolic} based on the different propositions described below, plus the sections in which theses propositions are proved.

\begin{figure}[!t]
\centering

\begin{tikzpicture}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\tikzstyle{block} = [draw, text centered, rounded corners, draw=black, thick, fill=white]
\tikzstyle{textblock} = [draw, text centered, draw=black, fill=white]

\tikzset{
  double arrow/.style args={#1 colored by #2 and #3}{
    -latex,line width=#1,#2, % first arrow
    postaction={draw,-latex,#3,line width=(#1)/2,
                shorten <=(#1)/3,shorten >=(#1)}, % second arrow
  }
}

\draw node (anchor) at (0,0) {};

%Hyperbolic graph: top left

\path (anchor)+(0,0) node (hyp_header) {\begin{minipage}[c]{10em}
	\begin{center}
		\textbf{Hyperbolic graph}\\
		$G_{\H,n}(\alpha, \nu)$
	\end{center}
\end{minipage}};

\path (hyp_header.south)+(0,-0.75) node (c_hyp) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Local clustering\\
	$\displaystyle c_{\H,n}(k_n)$
	\end{center}
\end{minipage}};






%Adjusted local clustering: middle left

\path (c_hyp.south)+(0,-3) node (c_ast_hyp) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Adjusted local clustering\\
	$\displaystyle c_{\H,n}^\ast(k_n)$
	\end{center}
\end{minipage}};

\path (c_ast_hyp.north)+(-2,1) node (hyp_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Lemma \ref{lem:clustering_ast_H}\\
		Section~\ref{ssec:coupling_H_HP}
	\end{center}
\end{minipage}};

%Poisson Hyperbolic graph: middle left

%\path (c_hyp.south)+(0,-6) node (c_pois_hyp) [block] {\begin{minipage}[c]{12em}
%	\begin{center}
%	Local clustering\\
%	$\displaystyle c_{\widetilde{\H},n}(k_n)$
%	\end{center}
%\end{minipage}};



\path (c_ast_hyp.south)+(0,-3) node (pois_hyp_header) {\begin{minipage}[c]{13em}
	\begin{center}
		\textbf{Poisson Hyperbolic graph}\\
		$G_{\HP,n}(\alpha,\nu)$
	\end{center}
\end{minipage}};

\path (pois_hyp_header.north)+(-2,1) node (pois_hyp_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:clustering_ast_H_Pois}\\
		Section~\ref{ssec:coupling_H_HP}
	\end{center}
\end{minipage}};





%Poisson Hyperbolic graph: bottom left

\path (pois_hyp_header.south)+(0,-1) node (c_ast_pois_hyp) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Adjusted local clustering\\
	$\displaystyle c_{\HP,n}^\ast(k_n)$
	\end{center}
\end{minipage}};



%Infinite limit model: top right



\path (hyp_header.east)+(6,0) node (pois_header) {\begin{minipage}[c]{10em}
	\begin{center}
		\textbf{Infinite limit model}\\
		$G_{\Pcal}(\alpha, \nu)$
	\end{center}
\end{minipage}};

\path (pois_header)+(0,-1.25) node (c_infty) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Clustering limit\\
	$\displaystyle c_\infty(k_n)$
	\end{center}
\end{minipage}};

\path (c_infty.south)+(2,-0.75) node (exp_c_pois_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:convergence_average_clustering_P_n}\\
		Section \ref{sec:clustering_Pn_to_P}
	\end{center}
\end{minipage}};




%Finite box model: bottom right

\path (c_ast_pois_hyp.east)+(6,0) node (c_ast_pois_n) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Adjusted local clustering\\
	$\displaystyle c_{\Pcal,n}^\ast(k_n)$
	\end{center}
\end{minipage}};

\path (c_ast_pois_n.south)+(-4.25,-0.5) node (c_ast_pois_n_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:couling_c_H_P}\\
		Section \ref{ssec:coupling_HP_ast_P}
	\end{center}
\end{minipage}};

\path (c_ast_pois_n.north)+(0,2.5) node (exp_c_pois_n) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Expected local clustering\\
	$\displaystyle \Exp{c_{\Pcal,n}^\ast(k_n)}$
	\end{center}
\end{minipage}};

\path (exp_c_pois_n.south)+(2,-0.75) node (exp_c_pois_n_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:concentration_local_clustering_P_n}\\
		Section \ref{sec:concentration_c_P_n}
	\end{center}
\end{minipage}};

\path (exp_c_pois_n.north)+(0,0.75) node (pois_n_header) {\begin{minipage}[c]{13em}
	\begin{center}
		\textbf{Finite box model}\\
		$G_{\Pcal,n}(\alpha, \nu)$
	\end{center}
\end{minipage}};








%Arrows

\path (c_hyp.south)+(0,-0.2) node (arrow_1l) {};
\path (c_ast_hyp.north)+(0,0.2) node (arrow_1r) {};

\draw [double arrow=6pt colored by black and white] (arrow_1l) -- (arrow_1r);

\path (c_ast_hyp.south)+(0,-0.1) node (arrow_2l) {};
\path (pois_hyp_header.north)+(0,0.1) node (arrow_2r) {};

\draw [double arrow=6pt colored by black and white] (arrow_2l) -- (arrow_2r);

\path (c_ast_pois_hyp.east)+(0.3,0) node (arrow_3l) {};
\path (c_ast_pois_n.west)+(-0.5,0) node (arrow_3r) {};

\draw [double arrow=6pt colored by black and white] (arrow_3l) -- (arrow_3r);

\path (c_ast_pois_n.north)+(0,0.2) node (arrow_4l) {};
\path (exp_c_pois_n.south)+(0,-0.2) node (arrow_4r) {};

\draw [double arrow=6pt colored by black and white] (arrow_4l) -- (arrow_4r);

\path (exp_c_pois_n.north)+(0,1.5) node (arrow_5l) {};
\path (c_infty.south)+(0,-0.2) node (arrow_5r) {};

\draw [double arrow=6pt colored by black and white] (arrow_5l) -- (arrow_5r);

\begin{pgfonlayer}{background}

\path (c_hyp)+(-3.5,2) node (hyp_a) {};
\path (c_ast_pois_hyp)+(3.5,-1.25) node (hyp_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!10] (hyp_a) rectangle (hyp_b);

\path (pois_hyp_header)+(-2.5,0.75) node (pois_hyp_a) {};
\path (c_ast_pois_hyp)+(2.5,-1) node (pois_hyp_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!20] (pois_hyp_a) rectangle (pois_hyp_b);

\path (c_infty)+(-3.5,2) node (pois_a) {};
\path (c_ast_pois_n)+(3.5,-1.25) node (pois_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!10] (pois_a) rectangle (pois_b);

\path (exp_c_pois_n)+(-2.5,2) node (pois_n_a) {};
\path (c_ast_pois_n)+(2.5,-1) node (pois_n_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!20] (pois_n_a) rectangle (pois_n_b);

\end{pgfonlayer}

\end{tikzpicture}

\caption{Overview of the proof strategy for Theorem \ref{thm:local_clustering_hyperbolic}.}
\label{fig:overview_proof}
\end{figure}

The main idea behind the proof of Theorem \ref{thm:local_clustering_hyperbolic} is to couple the hyperbolic graph $G_{\H, n}(\alpha, \nu)$ with a finite subgraph $G_{\Pcal,n}(\alpha,\nu)$ of an infinite graph $G_\Pcal(\alpha,\nu)$ whose nodes are given by a Poisson Point Process (see Section~\ref{ssec:infinite_model}). The infinite graph will then yield the limit expressions for the local clustering coefficient and function. A similar approach is used in \cite{fountoulakis2018law} to analyze the size of the largest component in the hyperbolic model and in \cite{komjathy2018explosion} to analyze explosion times in a more general class of models. 
The advantage of the infinite limit model is two-fold. Firstly, it simplifies the actual computations, e.g. by replacing hyperbolic densities with exponential densities and the hyperbolic distance with a computationally easier expression. Secondly, it directly yields the limit as a result rather than having to determine this later from a long expression depending on $n$. 

Very roughly, the proof falls into five parts: 1) replacing the randomly sampled nodes in the hyperbolic graph with a Poisson Point Process, 2) justifying the transitioning from this Poisson version of the hyperbolic random graph to the finite model, 3) proving concentration results for local clustering, 4) show that the limit expression correspond to those in the infinite model and finally 5) calculating the expected local clustering coefficient and function in the infinite limit model.
	
In this section, we state the required definitions, auxiliary lemmas and propositions and show how to assemble them to obtain Theorem~\ref{thm:local_clustering_hyperbolic}.

\subsection{Finite box model}\label{ssec:finite_model}

First of all we define the finite graph $G_{\mathcal{P},n}(\alpha, \nu)$ which we will couple to $G_{\H, n}(\alpha, \nu)$. A similar approach was used in~\cite{fountoulakis2018law} to analyze the largest component. Define $\Rcal = \mathbb{R} \times \mathbb{R}_+$ and let $\mathcal{P}=\mathcal{P}_{\alpha,\nu}$ be a Poisson point process on $\Rcal$ with intensity function
\begin{equation}\label{eq:def_intensity_function_f}
	f_{\alpha,\nu}(x,y) = \frac{\alpha \nu}{\pi} e^{-\alpha y}.
\end{equation} 

In addition we denote the intensity measure of the Poisson process $\mathcal{P}$ by $\mu_{\alpha, \nu}$, i.e. for every Borel-measurable subset $S \subseteq \mathbb{R} \times \mathbb{R}_+$
\begin{equation}\label{eq:def_mu_P}
	\mu_{\alpha,\nu}(S) = \int_S f_{\alpha,\nu}(x,y) \, dx \, dy,
\end{equation}
and for any point $p \in \Rcal$.

We will write $p = (x, y)$ for points in $\Rcal$. Then the \emph{infinite limit model} $G_{\mathcal{P}}(\alpha, \nu)$ is defined to have vertex set $\mathcal{P}$ and edge set such that
\[
	(p_i, p_j) \in E(G_{\mathcal{P}}(\alpha, \nu)) \iff |x_i - x_j| \leq e^{\frac{y_i + y_j}{2}}.
\]

\begin{remark}[Notations for points]\label{rmk:point_notation}
We will be working extensively with expressions in terms of points of $\Pcal_{\alpha, \nu}$, often relating them back to points in the hyperbolic disc $\Dcal_{\Rcal_n}$. Therefore, in the remainder of this paper we will always use $u = (r,\theta)$ to denote points in $\Dcal_{\Rcal_n}$ in polar coordinates while $p = (x,y)$ will denote points in $\Rcal := \mathbb{R} \times \mathbb{R}_+$ in Cartesian coordinates. In addition, when we write $p^\prime \in \mathbb{R} \times \mathbb{R}_+$ we will denote its Cartesian coordinates by $(x^\prime, y^\prime)$ and similarly for $p_i$, $u^\prime$ and $u_i$, e.g. $p_i = (x_i, y_i)$. In addition, for a point $p = (x,y)$, we will refer to $y$ as the \emph{height} of $p$.
\end{remark}

For the definition of the finite graph, recall that $R_n = 2\log(n/\nu)$ and consider the finite box $\Rcal_n = (-\frac{\pi}{2}e^{R_n/2}, \frac{\pi}{2}e^{R_n/2}] \times (0, R_n]$ in $\Rcal$. Then the \emph{finite box model} graph $G_{\mathcal{P},n}(\alpha, \nu)$ has vertex set $\mathcal{V}_n := \mathcal{P}_{\alpha, \nu} \cap \Rcal_n$ and edges set such that
\[
	(p_i, p_j) \in E(G_{\mathcal{P},n}(\alpha, \nu)) \iff |x_i - x_j|_{\pi e^{R_n/2}} \leq e^{\frac{y_i + y_j}{2}},
\]
where $|x|_{\pi e^{R_n/2}} = \inf_{k \in \mathbb{Z}} |x + k \pi e^{R_n/2}|$. In order words, $G_{\mathcal{P},n}(\alpha, \nu)$ is the subgraph of $G_{\mathcal{P}}(\alpha, \nu)$ induced on $\mathcal{V}_n$, where we have identified the boundaries of $(-\frac{\pi}{2}e^{R_n/2}, \frac{\pi}{2}e^{R_n/2}]$ to exclude boundary effects and to make the model symmetric in the horizontal $x$-axis. 

For a point $p \in \Rcal_n$, we will write $\BallPon{p}$ to denote the \emph{ball} around $p$, i.e.
\begin{equation}\label{eq:def_ball_P_n}
	\BallPon{p} = \left\{p^\prime \in \Rcal_n : |x_i - x_j|_{\pi e^{R_n/2}} \leq e^{\frac{y_i + y_j}{2}}\right\}.
\end{equation}
With this notation we then have that $\BallPon{p} \cap \PPP$ denotes the set of neighbors of a vertex $p \in G_{\Pcal,n}(\alpha,\nu)$.  


\subsection{Coupling the hyperbolic model to the finite box model}\label{ssec:coupling_H_P}

To couple the hyperbolic graph to $G_{\mathcal{P},n}(\alpha, \nu)$ we consider the original hyperbolic graph on a Poisson distributed number of vertices as an intermediate step. For this we define $G_{\HP,n}(\alpha, \nu)$ to be the hyperbolic random graph where the vertex set is given by $N \stackrel{d}{=} \Po(n)$ points, distributed according to the $(\alpha, R_n)$-quasi uniform distribution~\eqref{eq:def_hyperbolic_point_distribution} defined in Section \ref{ssec:hyperbolic_model}. The following two lemmas from \cite{fountoulakis2018law} establish a coupling between this version of the hyperbolic random graph and the finite box model and relate the hyperbolic neighborhoods to the neighborhood balls $\BallPo{p}$. The ensuing proposition verifies that this coupling also essentially preserves the local clustering function, i.e. that the difference between the local clustering function in the hyperbolic model and the finite box graph converges to zero faster than the proposed scalings in the main result, Theorem \ref{thm:local_clustering_hyperbolic}. Hence, it justifies the transition to the finite box model. 

\begin{lemma}[{\cite[Lemma 27]{fountoulakis2018law}}]\label{lem:coupling_hyperbolic_poisson}
Let $\mathcal{V}_{\HP, n}$ denote the vertex set of $G_{\HP,n}(\alpha, \nu)$ and $\mathcal{V}_n$ the vertex set of $G_{\Pcal,n}(\alpha, \nu)$. Define the map $\Psi : [0,R_n] \times (-\pi, \pi] \to \mathcal{R}_n$ by
\begin{equation}\label{eq:def_Psi}
	\Psi(r,\theta) = \left(\theta \frac{e^{R_n/2}}{2}, R_n - r\right).
\end{equation}
Then there exists a coupling such that, a.a.s., $\mathcal{V}_n = \Psi(\mathcal{V}_{\HP,n})$. %Moreover, if $\Ccal_n$ is the event that ${\cal V}_n = \Psi\left(\mathcal{V}_{\HP,n}\right)$ then
%\begin{equation}\label{eq:convergence_miscoupling_hyperbolic_poisson}
%	\Prob{\Ccal_n^c} = \bigO{n^{-(2\alpha - 1)}}. 
%\end{equation}
\end{lemma}

In the remainder of this paper we will write $\BallHyp{p}$ to denote the image under $\Psi$ of the ball of hyperbolic radius $R_n$ around the point $\Psi^{-1}(p)$, i.e. 
\[
	\BallHyp{p} := \left\{p^\prime := \Psi(u) \, : \, u \in \Dcal_{R_n} \text{ and } d_\H(\Psi^{-1}(p),u) \le R_n\right\}.
\]
Note that we have that $\BallHyp{p} \subseteq \mathcal{R}_n$. In particular, a point $p = (x,y) \in \Rcal$ corresponds to $u := \Psi^{-1}(p) = (2 e^{-R_n/2} x, R_n - y)$. 

Let $u, u^\prime \in \Dcal_R$. The hyperbolic law of cosines implies that $d_{\H}(u,u^\prime) \leq R_n$ if and only if their relative angle $\theta(u, u^\prime) := |\theta - \theta^\prime|_{2\pi}$ satisfies $\theta(u, u^\prime) \leq \theta_{R_n}(r,r^\prime)$, where $\theta_{R_n}(r,r^\prime)$ is the solution of the following equation
\[
	\cosh R_n =\cosh r \cosh r^\prime - \sinh r \sinh r^\prime \cos \theta_{R_n}(r,r^\prime).
\]
To write this differently, define
\begin{equation}\label{eq:def_Omega_hyperbolic}
	\Omega(r,r^\prime) := \frac{1}{2}e^{R_n/2} \arccos\left( \frac{\cosh r \cosh r^\prime - \cosh R_n}
	{\sinh r \sinh r^\prime} \right).
\end{equation}
Then $d_{\H}(u,u^\prime) \leq R_n$ if and only if $\theta(u, u^\prime) \leq 2 e^{-R_n/2}\Omega(r,r^\prime)$. Under the coupling map $\Psi$, this is equivalent to $|x-x^\prime|_{\pi e^{R_n/2}} \le \Omega(r,r^\prime)$.

Now consider a point $p \in \mathcal{V}_n$ and write $\Psi^{-1}(p) = (r,\theta)$. Then the triangle inequality implies that
for any point $u^\prime \in \Dcal_R$
\begin{equation}\label{eq:tail_inclusion_hyperbolic_ball}
	r^\prime \leq y = R_n - r \Rightarrow d_{\H} (\Psi^{-1}(p),u^\prime) \leq R_n.
\end{equation}
In other words, we have $\Rcal_n ([r, R_n])  \subset \BallHyp{p}$. The shape of $\BallHyp{p}$ at the lower parts of $\Rcal_n$ is described by the following lemma which appears in~\cite{fountoulakis2018law}. 


\begin{lemma}[{\cite[Lemma 28]{fountoulakis2018law}}]\label{lem:asymptotics_Omega_hyperbolic}
There exists a constant $K>0$ such that, for every $\varepsilon > 0$ and for $R_n$ sufficiently large, the following holds.
For every $r,r^\prime \in [\varepsilon R_n,R_n]$ with $r + r^\prime > R_n$ we have that 
\begin{equation}\label{eq:asymp1}
	e^{\frac{1}{2}(y+y^\prime)} - K e^{\frac{3}{2}(y+y^\prime) - R_n} \leq \Omega(r, r^\prime) 
	\leq  e^{\frac{1}{2}(y+y^\prime)} + K e^{\frac{3}{2}(y+y^\prime) - R_n},
\end{equation}
where $y := R_n - r, y^\prime := R - r^\prime$. 
Moreover:
\begin{equation}\label{eq:asymp2} 
\Omega(r,r^\prime) \geq e^{\frac12(y+y^\prime)} \quad \text{if \quad $r, r^\prime < R_n - K$.} 
\end{equation}
\end{lemma}

This result allows us to couple the neighborhoods in the hyperbolic random graph $G_{\H,n}(\alpha,\nu)$ to those in the finite box model $G_{\Pcal,n}(\alpha,\nu)$. This coupling is however not exact and hence we need to compute the difference in triangle counts between the two models. For this, and other computations later on, it will be more convenient to consider the following slight modified version of the local clustering function,
\begin{equation}\label{eq:def_local_clustering_ast_general}
	c_{G}^\ast(k) = \begin{cases}
			\frac{1}{\Exp{N_G(k)}} \sum_{v \in V(G)} \ind{D_G(v) = k} \frac{\T_G(v)}{\binom{k}{2}} &\mbox{if } N_G(k) \ge 1\\
			0 &\mbox{else.}
		\end{cases}
\end{equation}
Notice that the only difference between $c_G(k)$ and $c_G^\ast(k)$ is that we replace $N_G(k)$ by its expectation $\Exp{N_G(k)}$. Following the notational convention, see Remark~\ref{rmk:notation}, throughout the remainder of this paper we write $c_{\HP,n}^\ast(k)$ and $c_{\mathcal{P},n}^\ast(k)$ to denote the modified local clustering function in $G_{\HP,n}(\alpha, \nu)$ and $G_{\mathcal{P},n}(\alpha,\nu)$, respectively.

The following lemma justifies working with this modified version, for the proof see Section~\ref{ssec:coupling_H_HP}.

\begin{lemma}\label{lem:clustering_ast_H}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and $(k_n)_{n\ge 1}$ be any positive sequence, possibly constant, such that $k_n = \smallO{n^{\frac{1}{2\alpha + 1}}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\H,n}(k_n) - c_{\H,n}^\ast(k_n)\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{lemma}

We then establish that the modified local clustering function in the hyperbolic model $G_{\H,n}(\alpha,\nu)$ behaves similarly to that in the Poisson version $G_{\HP, n}(\alpha,\nu)$.

\begin{proposition}\label{prop:clustering_ast_H_Pois}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and $(k_n)_{n\ge 1}$ be any increasing sequence such that $k_n = \smallO{n^{\frac{1}{2\alpha + 1}}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\H,n}^\ast(k_n) - c_{\HP,n}^\ast(k_n)\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}
\MS{I think we can drop the condition to be increasing here and below, also the $n^{1/3}$ should be removed.}

The next step is to show that the modified clustering is preserved under the coupling described above. The proof can be found in Section~\ref{ssec:coupling_HP_ast_P}.

\begin{proposition}[Coupling result for local clustering]\label{prop:couling_c_H_P}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and $(k_n)_{n\ge 1}$ be any increasing sequence such that $k_n = \smallO{\min\left\{n^{\frac{1}{2\alpha + 1}}, n^{\frac{1}{3}}\right\}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\HP,n}^\ast(k_n) - c_{\Pcal,n}^\ast(k_n)\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}

These two results imply that the difference between the local clustering function of the hyperbolic random graph and the modified local clustering function of the finite box graph converges to zero faster than the proposed scaling $s_\alpha(k_n)$ in Theorem \ref{thm:local_clustering_hyperbolic}. Hence, to prove this theorem it is enough to prove it for $c_{\mathcal{P},n}^\ast(k)$. 

\subsection{Infinite limit model}\label{ssec:infinite_model}

To analyze the limiting expressions for clustering in the finite random graph $G_{\Pcal,n}(\alpha, \nu)$ we shall use an infinite graph model which can be understood as taking the finite graph $G_{\Pcal,n}(\alpha,\nu)$ and taking $n \to \infty$. Recall that $\Rcal = \mathbb{R} \times \mathbb{R}_+$ and that $\mathcal{P}_{\alpha,\nu}$ is a Poisson point process on $\Rcal$ with intensity function
\[
	f_{\alpha,\nu}(x,y) = \frac{\alpha \nu}{\pi} e^{-\alpha y}.
\]

The \emph{infinite limit model} $G_{\mathcal{P}}(\alpha, \nu)$ is defined to have vertex set $\mathcal{P}$ and edge set such that
\[
	(p_i, p_j) \in E(G_{\mathcal{P}}(\alpha, \nu)) \iff |x_i - x_j| \leq e^{\frac{y_i + y_j}{2}}.
\]
Similar to the finite graph, we write $\BallPo{p}$ to denote the \emph{ball} around $p$, i.e.
\begin{equation}\label{eq:def_ball_P}
	\BallPo{p} = \{p^\prime \in \Rcal : |x - x^\prime| \leq e^{\frac{y + y^\prime}{2}}\}.
\end{equation}

To analyze expressions in the both the finite and infinite model we will make use of the~\emph{Campbell-Mecke} formula. 
For a Poisson point process $\mathcal{P}$ on a measurable space $S$ with intensity $\lambda$ and a measurable non-negative function $h: S^r \rightarrow \mathbb{R}$ we have
\begin{equation}\label{eq:def_Campbell-Mecke}
\begin{split}
& \Exp{\sum_{x_1,\ldots, x_r \in \mathcal{P}}^{\neq} h (x_1, \ldots, x_r,
\mathcal{P} \setminus \{x_1,\ldots, x_r\}) }\\
& = \int_S \cdots \int_S
\Exp{h(x_1,\ldots, x_r,\mathcal{P} \setminus \{x_1,\ldots, x_r\}) \lambda (x_1) \cdots \lambda (x_r) dx_1 \cdots dx_r},
\end{split}
\end{equation}
where the sum ranges over all distinct $r$-tuples of points of $\mathcal{P}$.

Using the Campbell-Mecke formula we can compute the intensity measure of the ball $\BallPo{p}$, i.e. the expected number of points falling into it, as
\begin{equation}\label{eq:mu_ball_y_P}
	\mu_{\alpha, \nu}(\BallPo{p}) = \int_0^\infty \int_{-\infty}^\infty \ind{|x-x^\prime| \le e^{\frac{y + y^\prime}{2}}}
	f_{\alpha,\nu}(x^\prime, y^\prime) \, dx^\prime \, dy^\prime 
	= \frac{4\alpha \nu}{(2\alpha - 1)\pi} e^{\frac{y}{2}} := \xi_{\alpha,\nu}e^{\frac{y}{2}},
\end{equation}

We shall use $\rho(p,k)$ and $\rho(y,k)$ (for a point $p=(x,y) \in \mathcal{R}$) to denote the probability mass function of a Poisson random variable with expectation $\mu_{\alpha, \nu}(\BallPo{p})$, i.e.
\[
	\rho(p,k) = \rho(y,k) = \Prob{\Po\left(\xi_{\alpha,\nu} e^{y/2}\right) = k}.
\]
Note that $\rho(y,k)$ denotes the probability that a vertex $(x,y) \in G_{\Pcal}(\alpha,\nu)$ has degree $k$, which due to the translation symmetry of the Poisson Point Process in the $x$ direction depends only on the \emph{height} $y$.

\begin{remark}[Degree distributions in the other models]
Similar to the infinite graph, the degree of a node $p$ in the Poisson hyperbolic graph $G_{\HP,n}$ and the finite random graph $G_{\Pcal,n}$ is distributed as a Poisson random variable with mean $\Mu{\BallHyp{p}}$ and $\Mu{\BallPon{p}}$, respectively. Following the notation above we will denote these distributions by $\rho_{\HP,n}(y,k)$ and $\rho_{\Pcal,n}(y,k)$, since these again are independent of the $x$-coordinate of $p$.
\end{remark}

We can also define a local clustering coefficient and function in this model. However, since $G_\Pcal$ has an infinite number of nodes the corresponding definitions are slightly different than for the finite size models. Intuitively the local clustering coefficient is the probability that two random neighbors of a randomly sampled node form a triangle, while the local clustering function is the same probability but conditioned on the sampled node having degree $k$.

Again, due to symmetry in the $x$ direction we can assume without loss of generality that a randomly sampled point $p$ is $(0,y)$. For any $y \in \R_+$ we define the probability density function on $\Rcal :=  \R \times \R_+$ by  
\begin{equation}\label{eq:def_eta_P}
	\eta_y(x^\prime, y^\prime) = \frac{\ind{p^\prime \in \BallPo{(0,y)}} f_{\alpha,\nu}(x^\prime,y^\prime)}{\mu_{\alpha,\nu}(\BallPo{(0,y)})}.
\end{equation}
That is $\eta_y$ is the density $f_{\alpha,\nu}$ restricted to the ball $\BallPo{(0,y)}$, properly normalized. Or in other words, it denotes the probability density of a randomly sampled point in $\BallPo{(0,y)}$, i.e. a randomly sampled neighbor of $(0,y)$. 

We then define
\begin{equation}\label{eq:def_delta_p}
	\Delta_{\Pcal}(y) = \iint_{\Rcal^2} T_\Pcal(y, x_1, x_2, y_1, y_2) \eta_{y}(x_1,y_1)\eta_{y}(x_2,y_2) \dd x_1 \dd x_2  \dd y_1  \dd y_2,
\end{equation}
with 
\[
	T_\Pcal(y, x_1, x_2, y_1, y_2) 
	= \ind{|x_1| \, \le \, e^{(y+y_1)/2}}\ind{|x_2| \, \le \, e^{(y+y_2)/2}}\ind{|x_1-x_2| \, \le \, e^{(y_1+y_2)/2}},
\]
which is the probability that two randomly sampled points in $\BallPo{(0,y)}$ form a triangle with $(0,y)$.

Finally, we note that the height $y$ of a randomly sampled point has the exponential density $\alpha e^{-\alpha y}$: the distribution function of the radial coordinate of a vertex sampled in the disk is $\frac{\cosh(\alpha  r)-1}{\cosh(\alpha R)-1}$ which is asymptotically equivalent to $e^{\alpha(r-R)} = e^{-\alpha y}$, if $r$ and $R$ are large, resp. tending to infinity and $y=R-r$ and because of the minus sign in front of the $r$, the distribution function in $r$ turns into the complementary distribution function of $y$, from which we recognize the exponential distribution with parameter $\alpha$.%\PvdH{Could someone add an intuition or better explanation why this is the case.} 

With these expressions we define the limiting local clustering coefficient as
\begin{equation}\label{eq:def_average_clustering_infinite_model}
	c_\Pcal := \int_0^\infty \Delta_{\Pcal}(y) (1 - \rho(y,0) - \rho(y,1)) \alpha e^{-\alpha y} \dd y,
\end{equation}
while the limiting local clustering function is defined as
\begin{equation}\label{eq:def_c_infty_k}
	c_\Pcal(k) = \frac{\int_0^\infty \rho(y,k) \Delta_\Pcal(y) \alpha e^{-\alpha y} \dd y}{\int_0^\infty \rho(y,k) \alpha e^{-\alpha y} \dd y}.
\end{equation}

In Section~\ref{sec:asymptotics_average_clustering_ast_P} we will compute both these quantities and show that $c_\Pcal = c_\infty$ and $c_\Pcal(k) = c_\infty(k)$, where $c_\infty$ and $c_\infty(k)$ are given in, respectively, Theorem~\ref{thm:clustering_coefficient_hyperbolic} and Theorem~\ref{thm:local_clustering_hyperbolic}.

\subsection{From the finite to the infinite model}

To compute the limit of the modified local clustering function $c_{\mathcal{P},n}^\ast(k)$ in the finite graph $G_{\mathcal{P},n}(\alpha, \nu)$ we first prove in Section~\ref{sec:concentration_c_P_n} that it is concentrated around its expectation $\Exp{c_{\mathcal{P},n}^\ast(k_n)}$.

\begin{proposition}[Concentration local clustering function in $G_{\mathcal{P},n}(\alpha, \nu)$]\label{prop:concentration_local_clustering_P_n}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and let $(k_n)_{n \ge 1}$ be any non-decreasing sequence satisfying $k_n = \smallO{n^{\frac{1}{2\alpha+1}}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\mathcal{P},n}^\ast(k_n) - \Exp{c_{\mathcal{P},n}^\ast(k_n)}\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}

With this concentration result, we are left with the task to compute the limit of $\Exp{c_{\mathcal{P},n}^\ast(k_n)}$ as $n \to \infty$ and show that it is equivalent to $c_\infty(k_n)$. To accomplish this we move to the infinite limit model $G_\Pcal(\alpha,\nu)$ and show that the difference between the expected value of the clustering function $c_G^\ast(k)$ in $G_{\mathcal{P},n}(\alpha,\nu)$ and $G_{\mathcal{P}}(\alpha,\nu)$ goes to zero faster than the proposed scaling in Theorem \ref{thm:local_clustering_hyperbolic}.


\begin{proposition}[Transition to infinite limit model]\label{prop:convergence_average_clustering_P_n}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and let $(k_n)_{n \ge 1}$ be any positive sequence tending to infinity and satisfying $k_n = \smallO{n^{\frac{1}{2\alpha+1}}}$. Then, as $n \to \infty$,
\[
	\left|\Exp{c_{\Pcal,n}^\ast(k_n)} - c_\Pcal(k_n)\right| = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}
\MS{Is it really necessary that the sequence tends to infinity in the thm above?}

\subsection{Proof of the main results}\label{ssec:proof_main_results}

We are now ready to prove our main results, using the propositions stated in the previous sections. We begin with Theorem~\ref{thm:local_clustering_hyperbolic}.

\begin{proof}[Proof of Theorem \ref{thm:local_clustering_hyperbolic}]
%By applying Proposition~\ref{prop:convergence_average_clustering_P_n}, Proposition~\ref{prop:convergence_average_clustering_P_n} and Theorem~\ref{thm:asymptotics_average_clustering_P} we get
%\begin{align*}
%	&\hspace{-30pt}\Exp{\left|\frac{c_{\Pcal,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|}\\
%	&\le \frac{\Exp{\left|c_{\Pcal,n}^\ast(k_n) - \Exp{}c_{\Pcal,n}^\ast(k_n)\right|}}{C_{\alpha,\nu}s_\alpha(k_n)}
%		+ \frac{\left|\Exp{c_{\Pcal,n}^\ast(k_n)} - c_\infty(k_n)\right|}{C_{\alpha,\nu}s_\alpha(k_n)}
%		+ \left|\frac{c_{\infty}(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right| \\
%	&= \smallO{1}.
%\end{align*}
First of all, due to cancellation of equal terms we can rewrite
\begin{align*}
    c_{\H,n}(k_n)-c_\infty(k_n) =& c_{\H,n}(k_n)-c_{\H,n}^\ast(k_n)+c_{\H,n}^\ast(k_n)-c_{\HP,n}^\ast(k_n)+c_{\HP,n}^\ast(k_n)-c_{\Pcal,n}^\ast(k_n) \\
    &+c_{\Pcal,n}^\ast(k_n)-\E c_{\Pcal,n}^\ast(k_n)+\E c_{\Pcal,n}^\ast(k_n)-c_\infty(k_n)
\end{align*}
Then, we take absolute values and apply the triangle inequality. By monotonicity of expectation, we can apply it to both sides and obtain
\begin{align*}
    \E[|c_{\H,n}(k_n)-c_\infty(k_n)|] \leq & \E[|c_{\H,n}(k_n)-c_{\H,n}^\ast(k_n)|]+\E[|c_{\H,n}^\ast(k_n)-c_{\HP,n}^\ast(k_n)|]\\&+\E[|c_{\HP,n}^\ast(k_n)-c_{\Pcal,n}^\ast(k_n)|] 
    +\E[|c_{\Pcal,n}^\ast(k_n)-\E c_{\Pcal,n}^\ast(k_n)|]\\&+\E[|\E c_{\Pcal,n}^\ast(k_n)-c_\infty(k_n)|]
\end{align*}
At this point, the lemmas and propositions presented above in this section can be applied in order to show that all summands are $\smallO{s_\alpha(k_n)}$: Lemma~\ref{lem:clustering_ast_H} for the transition to the modified clustering function in the first term, Proposition~\ref{prop:clustering_ast_H_Pois} for the Poissonization in the disk in the second term, Proposition~\ref{prop:couling_c_H_P} for the coupling from the disk to the finite box model in the third term, Proposition~\ref{prop:concentration_local_clustering_P_n} for the concentration in the fourth term and finally Proposition~\ref{prop:convergence_average_clustering_P_n} for the transition to the infinite limit model where we also used that $c_{\Pcal}(k_n) = c_\infty(k_n)$ as obtained at the end of Section~\ref{sec:asymptotics_average_clustering_ast_P}. All of this together yields that:
\begin{align*}
    \E[|c_{\H,n}(k_n)-c_\infty(k_n)|] = \smallO{s_\alpha(k_n)} = \smallO{c_\infty(k_n)}
\end{align*}
i.e. the statement of the theorem.

%\[
%	\Exp{\left|\frac{c_{\Pcal,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|}
%	\le \left|\frac{c_{\infty}(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right| 
%	+ \frac{\Exp{\left|c_{\Pcal,n}^\ast(k_n) - c_\infty(k_n)\right|}}{C_{\alpha,\nu}s_\alpha(k_n)} = \smallO{1}.
%\]

%Combining this with Proposition~\ref{prop:couling_c_H_P} yields
%\[
%	\Exp{\left|\frac{c_{\H,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|}
%	\le \Exp{\left|\frac{c_{\Pcal,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|} 
%	+ \frac{\Exp{\left|c_{\H,n}^\ast(k_n) - c_{\Pcal,n}^\ast(k_n)\right|}}{C_{\alpha,\nu}s_\alpha(k_n)} = \smallO{1}.
%\]
%and the result then follows by applying Lemma~\ref{lem:clustering_ast_H}. 
\end{proof}

We can now use this result to prove Theorem~\ref{thm:clustering_coefficient_hyperbolic}. Before we state the proof we summarize some results regarding the degrees in the hyperbolic model. The proof of this lemma follows directly from Lemma~\ref{lem:diff_Nk_hyperbolic_binomial_poisson} and Lemma~\ref{lem:N_k_HP_P}, see Section~\ref{sec:coupling_H_P_n}.

\MS{I think we need to introduce resp. explain $\Prob{D_\Pcal = k_n}$ in the lemma below.}
\begin{lemma}\label{lem:N_k_H_P}
Let $\alpha > \frac{1}{2}$ and $k_n$ be a positive sequence, possibly constant, such that $k_n = \smallO{n^{\frac{1}{2\alpha + 1}}}$. Then
\[
	\lim_{n\to \infty} \Exp{\left|\frac{\Exp{N_{\H,n}(k_n)}}{n \Prob{D_\Pcal = k_n}} - 1\right|} = 0
\]
and hence, as $n \to \infty$
\[
	\Exp{N_{\H,n}(k_n)} = \bigT{n k_n^{-(2\alpha + 1)}}.
\]
\end{lemma}

\begin{proof}[Proof of Theorem~\ref{thm:clustering_coefficient_hyperbolic}]

First, let $a_n$ be any sequence such that $a_n \to \infty$. Then
\begin{align*}
	c_{\H,n} &= \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) \le a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}}
		+ \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) > a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}}\\
	&= \frac{1}{n} \sum_{t = 3}^{a_n} \sum_{i = 1}^n \ind{D_{\H,n}(i) = t} \frac{T_{\H,n}(i)}{\binom{t}{2}}
		+ \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) > a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}}\\
	&= \frac{1}{n} \sum_{t = 3}^{a_n} \Exp{N_{\H,n}(t)} c_{\H,n}^\ast(t)
		+ \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) > a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}},
\end{align*}
\MS{Should the summation in $t$ not start from $t=2$?}
where the expectation of last term is bounded from above by $\Prob{D_{\H,n} > a_n}$. Similarly,
\[
	c_\Pcal = \sum_{t = 3}^{a_n} \Prob{D_\Pcal = t} c_\Pcal(t) + \sum_{t > a_n} \Prob{D_\Pcal = t} c_\Pcal(t)
\]
Recall that (see [??]) $c_\infty = c_\Pcal$ and $c_\infty(k) = c_\Pcal(k)$. Therefore
\begin{align*}
	\Exp{|c_{\H,n} - c_\Pcal|}
	&\le \Exp{\left|\frac{1}{n} \sum_{t = 3}^{a_n} \left(\Exp{N_{\H,n}(t)} c_{\H,n}^\ast(t) - 	
		n \Prob{D_\Pcal = t}c_\Pcal(t)\right)\right|}\\ 
	&\hspace{10pt}+ \Prob{D_{\H,n} > a_n} + \Prob{D_{\Pcal} > a_n},
\end{align*}
and since the last to probabilities are $\smallO{1}$ it is enough to prove that
\[
	\lim_{n \to \infty} \Exp{\left|\frac{1}{n} \sum_{t = 3}^{a_n} \left(\Exp{N_{\H,n}(t)} c_{\H,n}^\ast(t) - 	
			n \Prob{D_\Pcal = t}c_\Pcal(t)\right)\right|} = 0.
\]

We write
\begin{align*}
	&\hspace{-30pt}\Exp{\left|\frac{1}{n} \sum_{t = 3}^{a_n} \left(\Exp{N_{\H,n}(t)} c_{\H,n}^\ast(t) - 	
		n \Prob{D_\Pcal = t}c_\Pcal(t)\right)\right|}\\
	&\le \sum_{t = 3}^{a_n} \Prob{D_\Pcal = t} \Exp{\left|c_{\H,n}^\ast(t) - c_{\infty}(t)\right|}\\
	&\hspace{10pt}+ \frac{1}{n} \sum_{t = 3}^{a_n} \Exp{\left|N_{\H,n}(t) - n \Prob{D_\Pcal = t}\right|}\Exp{c_\Pcal(t)},
\end{align*}
and will show that both terms go to zero for some appropriately chosen sequence $a_n$.

Note that Theorem~\ref{thm:local_clustering_hyperbolic} and Lemma~\ref{lem:clustering_ast_H} together state that for any sequence $k_n  = \smallO{n^{1/(2\alpha + 1)}}$
\begin{equation}\label{eq:convergence_c_H_P}
	\lim_{n \to \infty} \Exp{\left|c_{\H,n}(k_n) - c_{\Pcal}(k_n)\right|} = 0.
\end{equation}

Let $b_n := \log(n)^{-1} n^{1/(2\alpha + 1)}$ and define the sequence $k_n$ by
\[
	k_n = \arg \max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\Pcal}(t)\right|}.
\]
Then $k_n = \smallO{n^{1/(2\alpha + 1)}}$ and by~\eqref{eq:convergence_c_H_P}
\[
	\max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\Pcal}(t)\right|} = \Exp{\left|c_{\H,n}(k_n) - c_{\infty}(k_n)\right|} \to 0.
\]
Similarly we note that by Lemma~\ref{lem:N_k_H_P}
\[
	\max_{3 \le t \le b_n} \Exp{\left|\frac{N_{\H,n}(t)}{n \Prob{D_\Pcal = t}} - 1\right|} \to 0.
\]

Now define
\[
	a_n := \left\lfloor \min \left\{
	\left(\max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|}\right)^{-1/2},
	\left(\arg \max_{3 \le t \le b_n} \Exp{\left|\frac{N_{\H,n}(t)}{N_\Pcal(t)} - 1\right|}\right)^{-1/2},
	b_n - 1 \right\} \right\rfloor
\]
so that $a_n < b_n = \smallO{n^{1/(2\alpha + 1)}}$, $a_n \to \infty$, 
\[
	a_n \max_{3 \le t \le a_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|} 
	\le a_n \max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|} \to 0,
\]
and similarly
\[
	a_n \max_{3 \le t \le a_n} \Exp{\left|\frac{N_{\H,n}(t)}{n \Prob{D_\Pcal = t}} - 1\right|} \to 0.
\]

Then, since $\Exp{\Prob{D_\Pcal = t}} = \bigT{1} t^{-(2\alpha + 1)}$
\begin{align*}
	&\hspace{-30pt}\sum_{t = 3}^{a_n} \Prob{D_\Pcal = t} \Exp{\left|c_{\H,n}^\ast(t) - c_{\Pcal}(t)\right|}\\
	&\le \bigT{1} 3^{-(2\alpha+1)} a_n \max_{3 \le t \le a_n} \Exp{\left|c_{\H,n}^\ast(t) - c_{\Pcal}(t)\right|}
	= \smallO{1},
\end{align*}
while $\Exp{c_\Pcal(t)} \le 1$ implies that
\begin{align*}
	&\hspace{-30pt}\frac{1}{n} \sum_{t = 3}^{a_n} \Exp{\left|N_{\H,n}(t) - n \Prob{D_\Pcal = t}\right|}\Exp{c_\Pcal(t)} \\
	&\le \sum_{t = 3}^{a_n} \Prob{D_\Pcal = t} \Exp{\left|\frac{N_{\H,n}(t)}{n \Prob{D_\Pcal = t}} - 1\right|} \\
	&\le \bigT{1} 3^{-(2\alpha+1)} a_n \max_{3 \le t \le a_n} 
		\Exp{\left|\frac{N_{\H,n}(t)}{n \Prob{D_\Pcal = t}} - 1\right|} = \smallO{1}.
\end{align*}
This finishes the first part of the proof. The second part, which derives the exact expression for $c_\Pcal$ can be found in [??] \PvdH{Add reference to section.}
\end{proof}