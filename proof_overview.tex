\section{Overview of the proof strategy for Theorem~\ref{thm:asymptotic_local_clustering_hyperbolic}}\label{sec:proof_outline}

We first give a detailed overview of the structure for the proof of Theorem~\ref{thm:asymptotic_local_clustering_hyperbolic}. The proof itself can be found in Section~\ref{ssec:proof_main_results}, where we also prove Theorem~\ref{thm:clustering_coefficient_hyperbolic}. Figure~\ref{fig:overview_proof} shows a schematic overview of the proof of Theorem~\ref{thm:asymptotic_local_clustering_hyperbolic} based on the different propositions described below, plus the sections in which theses propositions are proved.

\begin{figure}[!t]
\centering

\begin{tikzpicture}

\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}

\tikzstyle{block} = [draw, text centered, rounded corners, draw=black, thick, fill=white]
\tikzstyle{textblock} = [draw, text centered, draw=black, fill=white]

\tikzset{
  double arrow/.style args={#1 colored by #2 and #3}{
    -latex,line width=#1,#2, % first arrow
    postaction={draw,-latex,#3,line width=(#1)/2,
                shorten <=(#1)/3,shorten >=(#1)}, % second arrow
  }
}

\draw node (anchor) at (0,0) {};

%Hyperbolic graph: top left

\path (anchor)+(0,0) node (hyp_header) {\begin{minipage}[c]{10em}
	\begin{center}
		\textbf{Hyperbolic graph}\\
		$G_{\H,n}(\alpha, \nu)$
	\end{center}
\end{minipage}};

\path (hyp_header.south)+(0,-0.75) node (c_hyp) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Local clustering\\
	$\displaystyle c_{\H,n}(k_n)$
	\end{center}
\end{minipage}};






%Adjusted local clustering: middle left

\path (c_hyp.south)+(0,-3) node (c_ast_hyp) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Adjusted local clustering\\
	$\displaystyle c_{\H,n}^\ast(k_n)$
	\end{center}
\end{minipage}};

\path (c_ast_hyp.north)+(-2,1) node (hyp_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Lemma \ref{lem:clustering_ast_H}\\
		Section~\ref{ssec:coupling_H_HP}
	\end{center}
\end{minipage}};

%Poisson Hyperbolic graph: middle left

%\path (c_hyp.south)+(0,-6) node (c_pois_hyp) [block] {\begin{minipage}[c]{12em}
%	\begin{center}
%	Local clustering\\
%	$\displaystyle c_{\widetilde{\H},n}(k_n)$
%	\end{center}
%\end{minipage}};



\path (c_ast_hyp.south)+(0,-3) node (pois_hyp_header) {\begin{minipage}[c]{13em}
	\begin{center}
		\textbf{Poisson Hyperbolic graph}\\
		$G_{\HP,n}(\alpha,\nu)$
	\end{center}
\end{minipage}};

\path (pois_hyp_header.north)+(-2,1) node (pois_hyp_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:clustering_ast_H_Pois}\\
		Section~\ref{ssec:coupling_H_HP}
	\end{center}
\end{minipage}};





%Poisson Hyperbolic graph: bottom left

\path (pois_hyp_header.south)+(0,-1) node (c_ast_pois_hyp) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Adjusted local clustering\\
	$\displaystyle c_{\HP,n}^\ast(k_n)$
	\end{center}
\end{minipage}};



%Infinite limit model: top right



\path (hyp_header.east)+(6,0) node (pois_header) {\begin{minipage}[c]{10em}
	\begin{center}
		\textbf{Infinite limit model}\\
		$G_{\Pcal}(\alpha, \nu)$
	\end{center}
\end{minipage}};

\path (pois_header)+(0,-1.25) node (c_infty) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Clustering limit\\
	$\displaystyle c_\infty(k_n)$
	\end{center}
\end{minipage}};

\path (c_infty.south)+(2,-0.75) node (exp_c_pois_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:convergence_average_clustering_P_n}\\
		Section \ref{sec:clustering_Pn_to_P}
	\end{center}
\end{minipage}};




%Finite box model: bottom right

\path (c_ast_pois_hyp.east)+(6,0) node (c_ast_pois_n) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Adjusted local clustering\\
	$\displaystyle c_{\Pcal,n}^\ast(k_n)$
	\end{center}
\end{minipage}};

\path (c_ast_pois_n.south)+(-4.25,-0.5) node (c_ast_pois_n_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:couling_c_H_P}\\
		Section \ref{ssec:coupling_HP_ast_P}
	\end{center}
\end{minipage}};

\path (c_ast_pois_n.north)+(0,2.5) node (exp_c_pois_n) [block] {\begin{minipage}[c]{10em}
	\begin{center}
	Expected local clustering\\
	$\displaystyle \Exp{c_{\Pcal,n}^\ast(k_n)}$
	\end{center}
\end{minipage}};

\path (exp_c_pois_n.south)+(2,-0.75) node (exp_c_pois_n_text) [textblock] {\begin{minipage}[c]{7em}
	\begin{center}
		Proposition \ref{prop:concentration_local_clustering_P_n}\\
		Section \ref{sec:concentration_c_P_n}
	\end{center}
\end{minipage}};

\path (exp_c_pois_n.north)+(0,0.75) node (pois_n_header) {\begin{minipage}[c]{13em}
	\begin{center}
		\textbf{Finite box model}\\
		$G_{\Pcal,n}(\alpha, \nu)$
	\end{center}
\end{minipage}};








%Arrows

\path (c_hyp.south)+(0,-0.2) node (arrow_1l) {};
\path (c_ast_hyp.north)+(0,0.2) node (arrow_1r) {};

\draw [double arrow=6pt colored by black and white] (arrow_1l) -- (arrow_1r);

\path (c_ast_hyp.south)+(0,-0.1) node (arrow_2l) {};
\path (pois_hyp_header.north)+(0,0.1) node (arrow_2r) {};

\draw [double arrow=6pt colored by black and white] (arrow_2l) -- (arrow_2r);

\path (c_ast_pois_hyp.east)+(0.3,0) node (arrow_3l) {};
\path (c_ast_pois_n.west)+(-0.5,0) node (arrow_3r) {};

\draw [double arrow=6pt colored by black and white] (arrow_3l) -- (arrow_3r);

\path (c_ast_pois_n.north)+(0,0.2) node (arrow_4l) {};
\path (exp_c_pois_n.south)+(0,-0.2) node (arrow_4r) {};

\draw [double arrow=6pt colored by black and white] (arrow_4l) -- (arrow_4r);

\path (exp_c_pois_n.north)+(0,1.5) node (arrow_5l) {};
\path (c_infty.south)+(0,-0.2) node (arrow_5r) {};

\draw [double arrow=6pt colored by black and white] (arrow_5l) -- (arrow_5r);

\begin{pgfonlayer}{background}

\path (c_hyp)+(-3.5,2) node (hyp_a) {};
\path (c_ast_pois_hyp)+(3.5,-1.25) node (hyp_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!10] (hyp_a) rectangle (hyp_b);

\path (pois_hyp_header)+(-2.5,0.75) node (pois_hyp_a) {};
\path (c_ast_pois_hyp)+(2.5,-1) node (pois_hyp_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!20] (pois_hyp_a) rectangle (pois_hyp_b);

\path (c_infty)+(-3.5,2) node (pois_a) {};
\path (c_ast_pois_n)+(3.5,-1.25) node (pois_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!10] (pois_a) rectangle (pois_b);

\path (exp_c_pois_n)+(-2.5,2) node (pois_n_a) {};
\path (c_ast_pois_n)+(2.5,-1) node (pois_n_b) {};
\path[rounded corners, draw=black, dashed, thick, fill=black!20] (pois_n_a) rectangle (pois_n_b);

\end{pgfonlayer}

\end{tikzpicture}

\caption{Overview of the proof strategy for Theorem \ref{thm:asymptotic_local_clustering_hyperbolic}.}
\label{fig:overview_proof}
\end{figure}

The main idea behind the proof of Theorem \ref{thm:asymptotic_local_clustering_hyperbolic} is to couple the hyperbolic graph $G_{\H, n}(\alpha, \nu)$ with a subgraph of an infinite graph $G_\Pcal(\alpha,\nu)$ (see Section~\ref{ssec:infinite_model}). A similar approach is used in \cite{fountoulakis2018law} to analyze the size of the largest component in the hyperbolic model and in \cite{komjathy2018explosion} to analyze explosion times in a more general class of models.. 
The advantage of the infinite limit model is two-fold. First, it simplifies the actual computations, e.g. by replacing hyperbolic densities with exponential densities and the hyperbolic distance with a computationally easier expression. Secondly, it directly yields the limit as a result rather than having to determine this later from a long expression depending on $n$. 

Very roughly, the proof falls into three parts: justifying the transitioning from the hyperbolic random graph to the infinite limit model, proving concentration results for local clustering and calculating the expected local clustering coefficient and function in the infinite limit model.
	
In this section, we state the required definitions, auxiliary lemmas and propositions and show how to assemble them to obtain Theorem~\ref{thm:asymptotic_local_clustering_hyperbolic}.

\subsection{Infinite limit model}\label{ssec:infinite_model}

To analyze the limiting expressions for clustering in the hyperbolic random graph $G_{\H,n}(\alpha, \nu)$ we shall use an following infinite graph model which was also considered in~\cite{fountoulakis2018law} to analyze the largest component. Define $\Rcal = \mathbb{R} \times \mathbb{R}_+$ and let $\mathcal{P}_{\alpha,\nu}$ be a Poisson point process on $\Rcal$ with intensity function
\begin{equation}\label{eq:def_intensity_function_f}
	f_{\alpha,\nu}(x,y) = \frac{\alpha \nu}{\pi} e^{-\alpha y}.
\end{equation} 

We will write $p = (x, y)$ for points in $\Rcal$. Then the \emph{infinite limit model} $G_{\mathcal{P}}(\alpha, \nu)$ is defined to have vertex set $\mathcal{P}$ and edge set such that
\[
	(p_i, p_j) \in E(G_{\mathcal{P}}(\alpha, \nu)) \iff |x_i - x_j| \leq e^{\frac{y_i + y_j}{2}}.
\]
For a point $p \in \Rcal$, we will write $\BallPo{p}$ to denote the \emph{ball} around $p$, i.e.
\begin{equation}\label{eq:def_ball_P}
	\BallPo{p} = \{p^\prime \in \Rcal : |x - x^\prime| \leq e^{\frac{y + y^\prime}{2}}\}.
\end{equation}
With this notation we then have that $\BallPo{p} \cap \mathcal{P}$ denotes the set of neighbors of a vertex $p \in G_\Pcal(\alpha,\nu)$.  We denote the intensity measure of the Poisson process $\mathcal{P}$ by $\mu_{\alpha, \nu}$, i.e. for every Borel-measurable subset $S \subseteq \mathbb{R} \times \mathbb{R}_+$
\begin{equation}\label{eq:def_mu_P}
	\mu_{\alpha,\nu}(S) = \int_S f_{\alpha,\nu}(x,y) \, dx \, dy,
\end{equation}
and for any point $p \in \Rcal$ we let $\eta_p$ be the corresponding probability measure on $\BallPo{p}$ 
\begin{equation}\label{eq:def_etq_P}
	\eta_p(S) = \frac{\mu_{\alpha,\nu}(S \cap \BallPo{p})}{\mu_{\alpha,\nu}(\BallPo{p})}.
\end{equation}
In addition we use $\rho(p,k)$ and $\rho(y,k)$ (for a point $p=(x,y) \in \mathcal{R}$) to denote the probability mass function of a Poisson random variable with expectation 
\begin{equation}\label{eq:mu_ball_y_P}
	\mu_{\alpha, \nu}(\BallPo{p}) = \int_0^\infty \int_{-\infty}^\infty \ind{|x-x^\prime| \le e^{\frac{y + y^\prime}{2}}}
	f_{\alpha,\nu}(x^\prime, y^\prime) \, dx^\prime \, dy^\prime 
	= \frac{4\alpha \nu}{(2\alpha - 1)\pi} e^{\frac{y}{2}} := \xi_{\alpha,\nu}e^{\frac{y}{2}},
\end{equation}
i.e.
\[
	\rho(p,k) = \rho(y,k) = \Prob{\Po\left(\xi_{\alpha,\nu} e^{y/2}\right) = k}.
\]
Note that $\rho(y,k)$ denote the probability that a node $(x,y) \in G_{\Pcal}(\alpha,\nu)$ has degree $k$.

\begin{remark}[Notations for points]\label{rmk:point_notation}
We will be working extensively with expressions in terms of points of $\Pcal_{\alpha, \nu}$, often relating them back to points in the hyperbolic disc $\Dcal_{\Rcal_n}$. Therefore, in the remainder of this paper we will always use $u = (r,\theta)$ to denote points in $\Dcal_{\Rcal_n}$ in polar coordinates while $p = (x,y)$ will denote points in $\Rcal := \mathbb{R} \times \mathbb{R}_+$ in Cartesian coordinates. In addition, when we write $p^\prime \in \mathbb{R} \times \mathbb{R}_+$ we will denote its Cartesian coordinates by $(x^\prime, y^\prime)$ and similarly for $p_i$, $u^\prime$ and $u_i$, e.g. $p_i = (x_i, y_i)$.
\end{remark}


\subsection{Finite box model}
 
Next we define the finite graph $G_{\mathcal{P},n}(\alpha, \nu)$ which we will couple to $G_{\H, n}(\alpha, \nu)$. Recall that $R_n = 2\log(n/\nu)$ and that $\Pcal_{\alpha, \nu}$ is a Poisson point process on $\Rcal = \R \times \R_+$, with intensity given by~\eqref{eq:def_intensity_function_f}. Now consider the finite box $\Rcal_n = (-\frac{\pi}{2}e^{R_n/2}, \frac{\pi}{2}e^{R_n/2}] \times (0, R_n]$ in $\Rcal$. Then the \emph{finite box model} graph $G_{\mathcal{P},n}(\alpha, \nu)$ has vertex set $\mathcal{V}_n := \mathcal{P}_{\alpha, \nu} \cap \Rcal_n$ and edges set such that
\[
	(p_i, p_j) \in E(G_{\mathcal{P},n}(\alpha, \nu)) \iff |x_i - x_j|_{\pi e^{R_n/2}} \leq e^{\frac{y_i + y_j}{2}},
\]
where $|x|_{\pi e^{R_n/2}} = \inf_{k \in \mathbb{Z}} |x + k \pi e^{R_n/2}|$. In order words, $G_{\mathcal{P},n}(\alpha, \nu)$ is the subgraph of $G_{\mathcal{P}}(\alpha, \nu)$ induced on $\mathcal{V}_n$, where we have identified the boundaries of $(-\frac{\pi}{2}e^{R_n/2}, \frac{\pi}{2}e^{R_n/2}]$ to exclude boundary effects and to make the model symmetric in the horizontal $x$-axis. 

Similar to $G_{\Pcal}(\alpha,\nu)$, we define for any $p \in \Rcal_n$, its neighborhood ball
\[
	\BallPon{p} = \left\{p^\prime \in \Rcal_n : |x_i - x_j|_{\pi e^{R_n/2}} \leq e^{\frac{y_i + y_j}{2}}\right\}
\]
and associated functions $\mu_{\alpha,\nu ,n}$ and $\eta_{p,n}$ and others, by appending an additional subscript $n$. For instance
\[
	\mu_{\alpha,\nu,n}(S) = \Mu{S \cap \Rcal_n} \quad \text{and} \quad 
    \eta_{p,n}(S) = \frac{\mu_{\alpha,\nu ,n}(S \cap \BallPon{p}}{\mu_{\alpha,\nu,n}(\BallPon{p})}
    = \frac{\Mu{S\cap\BallPon{p}}}{\Mu{\BallPon{p}}}.
\]


\subsection{Coupling the hyperbolic model to the finite box model}\label{ssec:coupling_H_P}

To couple the hyperbolic graph to $G_{\mathcal{P},n}(\alpha, \nu)$ we consider the original hyperbolic graph on a Poisson distributed number of vertices as an intermediate step. For this we define $G_{\HP,n}(\alpha, \nu)$ to be the hyperbolic random graph where the vertex set is given by $N \stackrel{d}{=} \Po(n)$ points, distributed according to the $(\alpha, R_n)$-quasi uniform distribution~\eqref{eq:def_hyperbolic_point_distribution} defined in Section \ref{ssec:hyperbolic_model}. The following two lemmas from \cite{fountoulakis2018law} establishes a coupling between this version of the hyperbolic random graph and the finite box model and relate the hyperbolic neighborhoods to the neighborhood balls $\BallPo{p}$. The ensuing proposition verifies that this coupling also essentially preserves the local clustering function, i.e. that the difference between the local clustering functions in the hyperbolic model and the finite box graph converges to zero faster than the proposed scalings in the main result, Theorem \ref{thm:asymptotic_local_clustering_hyperbolic}. Hence, it justifies the transition to the finite box model. 

\begin{lemma}[{\cite[Lemma 27]{fountoulakis2018law}}]\label{lem:coupling_hyperbolic_poisson}
Let $\mathcal{V}_{\HP, n}$ denote the vertex set of $G_{\HP,n}(\alpha, \nu)$ and $\mathcal{V}_n$ the vertex set of $G_{\Pcal,n}(\alpha, \nu)$. Define the map $\Psi : [0,R_n] \times (-\pi, \pi] \to \mathcal{R}_n$ by
\begin{equation}\label{eq:def_Psi}
	\Psi(r,\theta) = \left(\theta \frac{e^{R_n/2}}{2}, R_n - r\right).
\end{equation}
Then there exists a coupling such that, a.a.s., $\mathcal{V}_n = \Psi(\mathcal{V}_{\HP,n})$. %Moreover, if $\Ccal_n$ is the event that ${\cal V}_n = \Psi\left(\mathcal{V}_{\HP,n}\right)$ then
%\begin{equation}\label{eq:convergence_miscoupling_hyperbolic_poisson}
%	\Prob{\Ccal_n^c} = \bigO{n^{-(2\alpha - 1)}}. 
%\end{equation}
\end{lemma}

In the remainder of this paper we will write $\BallHyp{p}$ to denote the image under $\Psi$ of the ball of hyperbolic radius $R_n$ around the point $\Psi^{-1}(p)$, i.e. 
\[
	\BallHyp{p} := \left\{p^\prime := \Psi(u) \, : \, u \in \Dcal_{R_n} \text{ and } d_\H(\Psi^{-1}(p),u) \le R_n\right\}.
\]
Note that we have that $\BallHyp{p} \subseteq \mathcal{R}_n$. In particular, a point $p = (x,y) \in \Rcal$ corresponds to $u := \Psi^{-1}(p) = (2 e^{R_n/2} x, R_n - y)$. 

Let $u, u^\prime \in \Dcal_R$. The hypebolic law of cosines implies that $d_{\H}(u,u^\prime) < R_n$ if and only if their relative angle $\theta(u, u^\prime) := |\theta - \theta^\prime|_{2\pi}$ satisfies $\theta(u, u^\prime) < \theta_{R_n}(r,r^\prime)$, where $\theta_{R_n}(r,r^\prime)$ is the solution of the following equation
\[
	\cosh R_n =\cosh r \cosh r^\prime - \sinh r \sinh r^\prime \cos \theta_{R_n}(r,r^\prime).
\]
To write this differently, define
\begin{equation}\label{eq:def_Omega_hyperbolic}
	\Omega(r,r^\prime) := \frac{1}{2}e^{R_n/2} \arccos\left( \frac{\cosh r \cosh r^\prime - \cosh R_n}
	{\sinh r \sinh r^\prime} \right).
\end{equation}
Then $d_{\H}(u,u^\prime) < R_n$ if and only if $\theta(u, u^\prime) \leq 2 e^{-R_n/2}\Omega(r,r^\prime)$. Under the coupling map $\Psi$, this is equivalent to $|x-x^\prime|_{\pi e^{R_n/2}} \le \Omega(r,r^\prime)$.

Now consider a point $p \in \mathcal{V}_n$ and write $\Psi^{-1}(p) = (r,\theta)$. Then the triangle inequality implies that
for any point $u^\prime \in \Dcal_R$
\begin{equation}\label{eq:tail_inclusion_hyperbolic_ball}
	r^\prime \leq y = R_n - r \Rightarrow d_H (\Psi^{-1}(p),u^\prime) \leq R_n.
\end{equation}
In other words, we have $\Rcal_n ([r, R_n])  \subset \BallHyp{p}$. The shape of $\BallHyp{p}$ at the lower parts of $\Rcal_n$ is described by the following lemma which appears in~\cite{fountoulakis2018law}. 


\begin{lemma}[{\cite[Lemma 28]{fountoulakis2018law}}]\label{lem:asymptotics_Omega_hyperbolic}
There exists a constant $K>0$ such that, for every $\varepsilon > 0$ and for $R_n$ sufficiently large, the following holds.
For every $r,r^\prime \in [\varepsilon R_n,R_n]$ with $r + r^\prime > R_n$ we have that 
\begin{equation}\label{eq:asymp1}
	e^{\frac{1}{2}(y+y^\prime)} - K e^{\frac{3}{2}(y+y^\prime) - R_n} \leq \Omega(r, r^\prime) 
	\leq  e^{\frac{1}{2}(y+y^\prime)} + K e^{\frac{3}{2}(y+y^\prime) - R_n},
\end{equation}
where $y := R_n - r, y^\prime := R - r^\prime$. 
Moreover:
\begin{equation}\label{eq:asymp2} 
\Omega(r,r^\prime) \geq e^{\frac12(y+y^\prime)} \quad \text{if \quad $r, r^\prime < R_n - K$.} 
\end{equation}
\end{lemma}

This result allows us to couple the neighborhoods in the hyperbolic random graph $G_{\H,n}(\alpha,\nu)$ to those in the finite box model $G_{\Pcal,n}(\alpha,\nu)$. This coupling is however not exact and hence we need to compute the difference in triangle counts between the two models. For this, and other computations later on, it will be more convenient to consider the following slight modified version of local clustering,
\begin{equation}\label{eq:def_local_clustering_ast_general}
	c_{G}^\ast(k) = \begin{cases}
			\frac{1}{\Exp{N_G(k)}} \sum_{v \in V(G)} \ind{D_G(v) = k} \frac{\T_G(v)}{\binom{k}{2}} &\mbox{if } N_G(k) \ge 1\\
			0 &\mbox{else.}
		\end{cases}
\end{equation}
Notice that the only difference between $c_G(k)$ and $c_G^\ast(k)$ is that we replace $N_G(k)$ by its expectation $\Exp{N_G(k)}$. Following the notational convention, see Remark~\ref{rmk:notation}, throughout the remainder of this paper we write $c_{\HP,n}^\ast(k)$ and $c_{\mathcal{P},n}^\ast(k)$ to denote the modified local clustering function in $G_{\HP,n}(\alpha, \nu)$ and $G_{\mathcal{P},n}(\alpha,\nu)$, respectively.

First we show that considering this adjusted version doesn't change anything in terms of the scaling, the proof is given in Section~\ref{ssec:coupling_H_HP}.

\begin{lemma}\label{lem:clustering_ast_H}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and $(k_n)_{n\ge 1}$ be any positive sequence, possibly constant, such that $k_n = \smallO{n^{\frac{1}{2\alpha + 1}}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\H,n}(k_n) - c_{\H,n}^\ast(k_n)\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{lemma}

We then establish that the adjusted local clustering function in the hyperbolic model $G_{\H,n}(\alpha,\nu)$ behaves similar to that in the Poisson version $G_{\HP, n}(\alpha,\nu)$.

\begin{proposition}\label{prop:clustering_ast_H_Pois}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and $(k_n)_{n\ge 1}$ be any increasing sequence such that $k_n = \smallO{n^{\frac{1}{2\alpha + 1}}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\H,n}^\ast(k_n) - c_{\HP,n}^\ast(k_n)\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}

The next step is to show that the modified clustering isn't influenced by the coupling describe above. The proof can be found in Section~\ref{ssec:coupling_HP_ast_P}.

\begin{proposition}[Coupling result for local clustering]\label{prop:couling_c_H_P}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and $(k_n)_{n\ge 1}$ be any increasing sequence such that $k_n = \smallO{\min\left\{n^{\frac{1}{2\alpha + 1}}, n^{\frac{1}{3}}\right\}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\HP,n}^\ast(k_n) - c_{\Pcal,n}^\ast(k_n)\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}

These two results imply that the difference between the local clustering functions in the hyperbolic model and modified version in the finite box graph converges to zero faster than the proposed scaling $s_\alpha(k_n)$ in Theorem \ref{thm:asymptotic_local_clustering_hyperbolic}. Hence, to proof this theorem it enough to prove it for $c_{\mathcal{P},n}^\ast(k)$. 

\subsection{From the finite to the infinite model}

To compute the limit of the adjusted local clustering $c_{\mathcal{P},n}^\ast(k)$ in the finite graph $G_{\mathcal{P},n}(\alpha, \nu)$ we first prove in Section~\ref{sec:concentration_c_P_n} that it is concentrated around its mean $\Exp{c_{\mathcal{P},n}^\ast(k_n)}$.

\begin{proposition}[Concentration local clustering in $G_{\mathcal{P},n}(\alpha, \nu)$]\label{prop:concentration_local_clustering_P_n}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and let $(k_n)_{n \ge 1}$ be any non-decreasing sequence satisfying $k_n = \smallO{n^{\frac{1}{2\alpha+1}}}$. Then, as $n \to \infty$,
\[
	\Exp{\left|c_{\mathcal{P},n}^\ast(k_n) - \Exp{c_{\mathcal{P},n}^\ast(k_n)}\right|} = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}

With this concentration result, we are left with the task to compute the limit of $\Exp{c_{\mathcal{P},n}^\ast(k_n)}$ as $n \to \infty$ and show that it is equivalent to $c_\infty(k_n)$. To accomplish this we move to the infinite limit model $G_\Pcal(\alpha,\nu)$. The next result shows that the difference between the expected value of the clustering function $c_G^\ast(k)$ in $G_{\mathcal{P},n}(\alpha,\nu)$ and $G_{\mathcal{P}}(\alpha,\nu)$ goes to zero faster than the proposed scaling in Theorem \ref{thm:asymptotic_local_clustering_hyperbolic}.


\begin{proposition}[Transition to infinite limit model]\label{prop:convergence_average_clustering_P_n}
Let $\alpha > \frac{1}{2}$, $\nu > 0$ and let $(k_n)_{n \ge 1}$ be any positive sequence tending to infinity and satisfying $k_n = \bigO{n^{\frac{1}{2\alpha+1}}}$. Then, as $n \to \infty$,
\[
	\left|\Exp{c_{\Pcal,n}^\ast(k_n)} - c_\infty(k_n)\right| = \smallO{s_\alpha(k_n)}.
\]
\end{proposition}


\subsection{Proof of the main results}\label{ssec:proof_main_results}

We are now ready to prove our main results, using the propositions stated in the previous sections. We begin with Theorem~\ref{thm:asymptotic_local_clustering_hyperbolic}.

\begin{proof}[Proof of Theorem \ref{thm:asymptotic_local_clustering_hyperbolic}]
By applying Proposition~\ref{prop:convergence_average_clustering_P_n}, Proposition~\ref{prop:convergence_average_clustering_P_n} and Theorem~\ref{thm:asymptotics_average_clustering_P} we get
\begin{align*}
	&\hspace{-30pt}\Exp{\left|\frac{c_{\Pcal,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|}\\
	&\le \frac{\Exp{\left|c_{\Pcal,n}^\ast(k_n) - \Exp{}c_{\Pcal,n}^\ast(k_n)\right|}}{C_{\alpha,\nu}s_\alpha(k_n)}
		+ \frac{\left|\Exp{c_{\Pcal,n}^\ast(k_n)} - c_\infty(k_n)\right|}{C_{\alpha,\nu}s_\alpha(k_n)}
		+ \left|\frac{c_{\infty}(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right| \\
	&= \smallO{1}.
\end{align*}
%\[
%	\Exp{\left|\frac{c_{\Pcal,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|}
%	\le \left|\frac{c_{\infty}(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right| 
%	+ \frac{\Exp{\left|c_{\Pcal,n}^\ast(k_n) - c_\infty(k_n)\right|}}{C_{\alpha,\nu}s_\alpha(k_n)} = \smallO{1}.
%\]
Combining this with Proposition~\ref{prop:couling_c_H_P} yields
\[
	\Exp{\left|\frac{c_{\H,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|}
	\le \Exp{\left|\frac{c_{\Pcal,n}^\ast(k_n)}{C_{\alpha,\nu}s_\alpha(k_n)} - 1\right|} 
	+ \frac{\Exp{\left|c_{\H,n}^\ast(k_n) - c_{\Pcal,n}^\ast(k_n)\right|}}{C_{\alpha,\nu}s_\alpha(k_n)} = \smallO{1}.
\]
and the result then follows by applying Lemma~\ref{lem:clustering_ast_H}. 
\end{proof}

We can now use this result to prove Theorem~\ref{thm:clustering_coefficient_hyperbolic}.

\begin{proof}[Proof of Theorem~\ref{thm:clustering_coefficient_hyperbolic}]
First, let $a_n$ be any sequence such that $a_n \to \infty$. Then
\begin{align*}
	c_{\H,n} &= \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) \le a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}}
		+ \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) > a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}}\\
	&= \frac{1}{n} \sum_{t = 3}^{a_n} \sum_{i = 1}^n \ind{D_{\H,n}(i) = t} \frac{T_{\H,n}(i)}{\binom{t}{2}}
		+ \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) > a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}}\\
	&= \frac{1}{n} \sum_{t = 3}^{a_n} \Exp{N_{\H,n}(t)} c_{\H,n}(t)
		+ \frac{1}{n} \sum_{i = 1}^n \ind{D_{\H,n}(i) > a_n} \frac{T_{\H,n}(i)}{\binom{D_{\H,n}(i)}{2}},
\end{align*}
where the expectation of last term is bounded from above by $\Prob{D_{\H,n} > a_n}$. We have a similar result for $c_\infty$. Therefore
\begin{align*}
	\Exp{|c_{\H,n} - c_\infty|}
	&\le \Exp{\left|\frac{1}{n} \sum_{t = 3}^{a_n} \left(\Exp{N_{\H,n}(t)} c_{\H,n}(t) - 	
		\Exp{N_\Pcal(t)}c_{\infty}(t)\right)\right|}\\ 
	&\hspace{10pt}+ \Prob{D_{\H,n} > a_n} + \Prob{D_{\Pcal} > a_n},
\end{align*}
and since the last to probabilities are $\smallO{1}$ it is enough to prove that
\[
	\lim_{n \to \infty} \Exp{\left|\frac{1}{n} \sum_{t = 3}^{a_n} \left(\Exp{N_{\H,n}(t)} c_{\H,n}(t) - 	
			\Exp{N_\Pcal(t)}c_{\infty}(t)\right)\right|} = 0.
\]

We write
\begin{align*}
	\Exp{\left|\frac{1}{n} \sum_{t = 3}^{a_n} \left(\Exp{N_{\H,n}(t)} c_{\H,n}(t) - 	
		\Exp{N_\Pcal(t)}c_{\infty}(t)\right)\right|}
	&\le \frac{1}{n} \sum_{t = 3}^{a_n} \Exp{N_\Pcal(t)} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|}\\
	&\hspace{10pt}+ \frac{1}{n} \sum_{t = 3}^{a_n} \Exp{\left|N_{\H,n}(t) - N_\Pcal(t)\right|}\Exp{c_\infty(t)},
\end{align*}
and will show that both terms go to zero for some appropriately chosen sequence $a_n$.

Note that Theorem~\ref{thm:asymptotic_local_clustering_hyperbolic} states that for any sequence $k_n  = \smallO{n^{1/(2\alpha + 1)}}$
\[
	\lim_{n \to \infty} \Exp{\left|c_{\H,n}(k_n) - c_{\infty}(k_n)\right|} = 0.
\]

Let $b_n := \log(n)^{-1} n^{1/(2\alpha + 1)}$ and define the sequence $k_n$ by
\[
	k_n = \arg \max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|}.
\]
Then $k_n = \smallO{n^{1/(2\alpha + 1)}}$ and by Theorem~\ref{thm:asymptotic_local_clustering_hyperbolic}
\[
	\max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|} = \Exp{\left|c_{\H,n}(k_n) - c_{\infty}(k_n)\right|} \to 0.
\]
Similarly we note that
\[
	\arg \max_{3 \le t \le b_n} \Exp{\left|\frac{N_{\H,n}(t)}{N_\Pcal(t)} - 1\right|} \to 0.
\]

Now define
\[
	a_n := \left\lfloor \min \left\{
	\left(\max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|}\right)^{-1/2},
	\left(\arg \max_{3 \le t \le b_n} \Exp{\left|\frac{N_{\H,n}(t)}{N_\Pcal(t)} - 1\right|}\right)^{-1/2},
	b_n - 1 \right\} \right\rfloor
\]
so that $a_n < b_n = \smallO{n^{1/(2\alpha + 1)}}$, $a_n \to \infty$, 
\[
	a_n \max_{3 \le t \le a_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|} 
	\le a_n \max_{3 \le t \le b_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|} \to 0,
\]
and similarly
\[
	a_n \arg \max_{3 \le t \le a_n} \Exp{\left|\frac{N_{\H,n}(t)}{N_\Pcal(t)} - 1\right|} \to 0.
\]

Then, since $\Exp{N_\Pcal(t)} = \bigT{1}n^{-1} t^{-(2\alpha + 1)}$
\begin{align*}
	&\hspace{-30pt}\frac{1}{n} \sum_{t = 3}^{a_n} \Exp{N_\Pcal(t)} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|}\\
	&\le \bigT{1} 3^{-(2\alpha+1)} a_n \max_{3 \le t \le a_n} \Exp{\left|c_{\H,n}(t) - c_{\infty}(t)\right|}
	= \smallO{1},
\end{align*}
while $\Exp{c_\infty(t)} \le 1$ implies that
\begin{align*}
	&\hspace{-30pt}\frac{1}{n} \sum_{t = 3}^{a_n} \Exp{\left|N_{\H,n}(t) - N_\Pcal(t)\right|}\Exp{c_\infty(t)} \\
	&\le \frac{1}{n} \sum_{t = 3}^{a_n} \Exp{N_\Pcal(t)} \Exp{\left|\frac{N_{\H,n}(t)}{N_\Pcal(t)} - 1\right|} \\
	&\le \bigT{1} 3^{-(2\alpha+1)} a_n \max_{3 \le t \le a_n} \Exp{\left|\frac{N_{\H,n}(t)}{N_\Pcal(t)} - 1\right|} 
		= \smallO{1}.
\end{align*}
This finishes the proof.
\end{proof}