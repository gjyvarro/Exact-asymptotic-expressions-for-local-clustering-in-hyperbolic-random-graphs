\section{Concentration of heights for vertices with degree $k$}\label{sec:concentration_argument}

Here we show that if we integrate with respect to a function $\hat{\rho}_n(y,k_n) = \Prob{\Po(\mu_n(y)) = k_n}$ then we may restrict integration with respect to the \emph{height} $y$ to an interval on which $\mu_n(y) = \bigT{k_n}$. We will refer to such a result as a \emph{concentration of heights} result. In addition, if $\mu_n(y)$ is equivalent to $\mu(y)$ on this interval, then we may replace $\hat{\rho}_n(y,k_n)$ in the integral with $\rho(y,k_n) = \Prob{\Po(\mu(y)) = k_n}$ (the degree distribution of the typical point in $\Ginf$). 

We start with a concentration of heights result for the infinite model $\Ginf$ (Lemma~\ref{lem:concentration_argument}) and explain in Remark~\ref{rmk:concentration_argument} how such a result will be used throughout the paper. We then present a generalization of this result (Lemma~\ref{lem:concentration_argument}) and use this to establish concentration of heights results for the Poissonized KPKVB $\GPo$ and finite box model $\Gbox$. 

Finally we provide a general result that allow to substitute $\hat{\rho}_n(y,k_n)$ in the integrand with $\rho(y,k_n)$ and show that this holds in particular for the degree distributions in $\GPo$ and $\Gbox$, given by, respectively $\rho_{\Po}(y,k_n) := \Prob{\Po(\Mu{\BallHyp{y}}) = k_n}$ and $\rho_{\text{box}}(y,k_n) := \Prob{\Po(\Mu{\BallPon{y}}) = k_n}$.

\subsection{Concentration of heights argument for the infinite model}

%Recall that $\rho(y, k)$ is the probability density function of a Poisson random variable with expectation $\mu_{\alpha, \nu}(B_\Pcal(y)) = \xie^{\frac{y}{2}}$. 
%We will consider two different types of sequences $\{k_n\}_{n \ge 1}$, those that are asymptotically bounded and those that diverge. We define
%\begin{equation}\label{eq:def_kappa_n}
%	\kappa_n := \begin{cases}
%		\log(n) &\mbox{if } k_n = \bigT{1},\\
%		\sqrt{k_n \log(k_n)} &\mbox{if } k_n = \omega(1).
%	\end{cases}
%\end{equation}
%\TM{ This is not a good definition. There are sequences that neither stay bounded nor tend to infinity, e.q.~odd values equal to 2 even values equal to $\log n$. How do you decide for a given $k_n$ which of the two cases you pick. To solve this we could either restrict to sequences that are either a) constant or b) tending to infinity; or we could make a cut-off at some specific, slow growing function such as $\log\log\log n$. }\PvdH{You are right, I overlooked this fact. I would opt to go with the setting where we consider only sequences that are either asymptotically bounded or tend to infinity. After the new proves are added we can see where we specify this.}



%Where we recall that $a \vee b = \max\{a,b\}$ and $a \wedge b = \min\{a,b\}$.

The next lemma states that for a large class of functions $h(y)$ and $k_n \to \infty$, to compute the integral 
\[
	\int_{0}^\infty \rho(y,k_n) h(y) e^{-\alpha y} \dd y
\]
%\TM{ This part is supposed to be for the infinite model, yet you integrate over the finite box $\Rcal$. Is this really meant?
%I would have expected we just integrate wrt.~$y$ and replace $f_{\alpha,\nu}(x,y)$ by $\alpha e^{-\alpha y}$, the exponential density.}\PvdH{I understand this confusion and agree that your suggestion makes more sense here. However, I choose this setup to minimize notations later. I am for changing the setup to what you are suggesting but I will have to spend some time first on checking how that will effect the definitions in later sections.}
it is enough to consider integration over a small interval on which $e^{y/2} \approx k_n$, instead of $\R_+$. 

\begin{lemma}\label{lem:concentration_argument}
Let $\alpha > \frac{1}{2}$, $\nu > 0$, $\{k_n\}_{n \ge 1}$ be any positive sequence such that $k_n \to \infty$ and $k_n = \smallO{n}$ and let $\ell_n = k_n(1 + \epsilon_n)$, with $\epsilon_n \to 0$. In addition, define for any constant $C > 0$,
\[
	\lambda_n^\pm = (\ell_n \pm C \sqrt{\ell_n \log(\ell_n)}) \wedge \xi, 
	\quad a_n^\pm = 2 \log\left(\frac{\lambda_n^\pm}{\xi}\right).
\] 
Then the following holds.
\begin{enumerate}
\item For any continuous function $h : \R_+ \rightarrow  \R$, such that $h(y) = \bigO{e^{\beta y}}$ as $y \to \infty$ for some $\beta < \alpha$, 
\begin{equation}\label{eq:error_bound_int_rho_not_K}
	\int_{\R_+ \setminus (a_n^-, a_n^+)} \rho(y,k_n) h(y) \alpha e^{-\alpha y} \dd y
	= \bigO{k_n^{-(1+C^2)/2}},
\end{equation}
as $n \to \infty$.
\item If in addition, $h(a_n) \sim h(b_n)$ whenever $a_n \sim b_n$, as $n \to \infty$. Then,
\begin{equation}\label{eq:concentration_h_rho}
	\int_0^\infty h(y) \rho(y,k_n) \alpha e^{-\alpha y^\prime} \dd y^\prime \sim  
		2\alpha \xi^{2\alpha} h(2\log(k_n/\xi)) k_n^{-(2\alpha + 1)},
\end{equation}
as $n \to \infty$.
\end{enumerate}
\end{lemma}

\begin{proof}\hfill

\paragraph{Proof of the first statement.}
Recall (see proof of Proposition~\ref{prop:asymp}) that $\rho(y,k_n)$, as a function of $y$, is strictly increasing on $[0,a_n^-]$ and strictly decreasing on $[a_n^+,\infty)$. Therefore, by our assumption on $h(y)$,
\begin{align*}
	&\hspace{-20pt}\int_{\R_+ \setminus (a_n^-, a_n^+)} h(y) \rho(y,k_n) 
		\alpha e^{-\alpha y} \dd y\\
    &= \bigO{1} \int_0^{a_n^-} e^{\beta y} \rho(y,k_n) \alpha e^{-\alpha y} \dd y 
    	+ \bigO{1}\int_{a_n^+}^{\infty} e^{\beta y} \rho(y,k_n) \alpha e^{-\alpha y}x \dd y \\
    &= \bigO{1} \int_0^{a_n^-} \rho(y,k_n) e^{-(\alpha-\beta) y} \dd y 
   		+ \bigO{1} \int_{a_n^+}^{\infty} \rho(y,k_n) e^{-(\alpha-\beta) y} \dd y\\
   	&\le \bigO{1}\rho(a_n^-,k_n)\int_0^{a_n^-} e^{-(\alpha-\beta) y} \, \dd y
   		+ \bigO{1} \rho(a_n^+,k_n) \int_{a_n^+}^{\infty} e^{-(\alpha-\beta) y} \, \dd y.
\end{align*}
Since $\alpha - \beta > 0$, we conclude that
\begin{equation}\label{eq:concentration_lemma_integral_bound}
	\int_{\R_+ \setminus (a_n^-, a_n^+)} h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \bigO{1} \left(\rho(a_n^-,k_n) + \rho(a_n^+,k_n)\right) 
\end{equation}

We shall now bound the terms $\rho(a_n^\pm,k_n)$, starting with $\rho(a_n^+,k_n)$.  Using Stirling's approximation $k! \sim \sqrt{2\pi} k^{k + 1/2} e^{-k}$ as $k \to \infty$ we write
\begin{align*}
	\rho(a_n^+,k_n) &= \frac{\mu(a_n^+)^{k_n}}{k_n!} e^{-\mu(a_n^+)} \\
	&\sim (2\pi)^{-1/2} k_n^{-1/2} \left(\frac{\mu(a_n^+)}{k_n}\right)^{k_n} e^{-(\mu(a_n^+) - k_n)}\\
	&= (2\pi)^{-1/2} k_n^{-1/2} 
		e^{-k_n\left(\frac{\mu(a_n^+)}{k_n} - 1 - \log\left(\frac{\mu(a_n^+)}{k_n}\right)\right)}.
\end{align*}

Since 
\[
	\frac{\mu(a_n^+)}{k_n} = \frac{\lambda_n^{+}}{k_n} = 1 + \epsilon_n + C \frac{\kappa_n}{k_n} 
	= 1 + \epsilon_n + C \sqrt{\frac{(1+\epsilon_n)\log((1+\epsilon_n)k_n)}{k_n}},
\]
and $x - \log(1 + x) \sim x^2/2$ as $x \to 0$, we get 
\begin{align*}
	\rho(a_n^+,k_n) 
	&\le \sqrt{2\pi} k_n^{-1/2} 
		e^{-k_n\left(\epsilon_n + C \frac{\kappa_n}{k_n} - \log\left(1 + \epsilon_n + C \frac{\kappa_n}{k_n}\right)\right)}\\
	&\sim (2\pi)^{-1/2} k_n^{-1/2} e^{-\frac{k_n \left(\epsilon_n + C \kappa_n/k_n\right)^2}{2}} \\
	&= \bigO{k_n^{-(1+C^2)/2}},		\numberthis \label{eq:concentration_lemma_bound_an+}
\end{align*}
where for the last line we used that
\[
	-k_n \frac{\left(\epsilon_n + C \kappa_n/k_n\right)^2}{2} = -\frac{C^2}{2}\log(k_n) + \bigT{1}.
\]
A similar analysis as above yields
\begin{equation}\label{eq:concentration_lemma_bound_an-}
	\rho(a_n^-,k_n) \le \bigT{1} k_n^{-1/2} e^{-\frac{k_n \left(\epsilon_n - C \kappa_n/k_n\right)^2}{2}} = \bigO{k_n^{-(1+C^2)/2}}.
\end{equation} 
Plugging~\eqref{eq:concentration_lemma_bound_an-} and~\eqref{eq:concentration_lemma_bound_an+}  into~\eqref{eq:concentration_lemma_integral_bound} yields the result. 

\paragraph{Proof of the second statement.} By the mean value theorem for definite integrals, there exists a $c_n \in (a_n^-, a_n^+)$ such that
\[
	\int_{a_n^-}^{a_n^+} h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= h(c_n) \int_{a_n^+}^{a_n^+} \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
Since $\int_0^\infty \rho(y,k_n) \alpha e^{-\alpha y} \dd y = \bigT{k_n^{-(2\alpha + 1)}}$, taking any $C > \sqrt{4\alpha + 1}$, \eqref{eq:error_bound_int_rho_not_K} implies that
\[
	\int_{a_n^+}^{a_n^+} \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= (1 + \smallO{1})\int_0^\infty \rho(y,k_n) \alpha e^{-\alpha y} \dd y,
\]
from which we conclude that (see~\eqref{eq:degree_distribution_P_asymptotics}),
\[
	\int_{a_n^+}^{a_n^+} \rho(y,k_n) \alpha e^{-\alpha y} \dd y = (1 + \smallO{1}) 2\alpha \xi^{2\alpha} k_n^{-(2\alpha + 1)},
\]
as $n \to \infty$. Finally, since $c_n \in (a_n^-, a_n^+)$ it follows that
\[
	\left|\frac{c_n}{2\log(k_n/\xi)} - 1\right| \le 2 C \sqrt{\frac{\log(k_n)}{k_n}}, 
\]
so that $c_n \sim k_n$. Therefore, by assumption on $h$ 
\[
	\int_{a_n^-}^{a_n^+} h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	\sim h(c_n) 2\alpha \xi^{2\alpha} k_n^{-(2\alpha + 1)} 
	\sim 2\alpha \xi^{2\alpha} h(2\log(k_n/\xi)) k_n^{-(2\alpha + 1),}
\]
as $n \to \infty$.
\end{proof}

Note that we can tune the error in~\eqref{eq:error_bound_int_rho_not_K} by selecting an appropriately large $C > 0$, i.e. by restricting the function $h(y)$ inside the integral to an appropriate interval around $2\log(k_n/\xi)$. This makes Lemma~\ref{lem:concentration_argument} very powerful. Below we list several important corollaries. 

\begin{corollary}\label{cor:concentration_of_heights_asymptotics}
Let $h : \R_+ \to \R$ be any continuous function such that for some $\beta < \alpha$, $h(y) = \bigO{e^{\beta y}}$ as $y \to \infty$ and $h(a_n) \sim h(b_n)$ whenever $a_n \sim b_n$. Then for any other continuous function $g: \R_+ \to \R$, such that $g(y) \sim h(y)$ as $y \to \infty$
\begin{equation}\label{eq:concentration_h_sim_rho}
	\int_0^\infty g(y) \rho(y,k_n) \alpha e^{-\alpha y^\prime} \dd y^\prime \sim  
		2\alpha \xi^{2\alpha} h(2\log(k_n/\xi)) k_n^{-(2\alpha + 1)},
\end{equation}
as $n \to \infty$.
\end{corollary}

\begin{proof}
By assumption, $g$ satisfies the conditions of the second statement of Lemma~\ref{lem:concentration_argument}. Since in addition $g(2\log(k_n/\xi)) \sim h(2\log(k_n/\xi))$, the result follows.
\end{proof}


%For any positive sequence $a_n \to \infty$ and $C > 0$ we define
%\begin{equation}\label{eq:def_K_C_set}
%	\Kcal_C(a_n) = \left\{y \in \R_+ : \frac{a_n - C \sqrt{a_n \log(a_n)}}{\xi} \vee 1 \le e^{\frac{y}{2}}
%	\le \frac{a_n + C \sqrt{a_n \log(a_n)}}{\xi} \right\}.
%\end{equation}
%In addition we define
%\begin{equation}\label{eq:def_K_C_n_set}
%	\Kcal_{C,n}(a_n) := (-I_n, I_n] \times ((0,R_n] \cap \Kcal_{C}(a_n)),
%\end{equation}
%where $I_n := \frac{\pi}{2}e^{R_n/2}$. Recall that $\Rcal = (-I_n, I_n] \times [0,R]$. 
The following corollary allows us to bound integrals of function by considering there maximum of $\Kcal_{C}(k_n)$.

\begin{corollary}\label{cor:concentration_heights_bounds_n}
Let $h_n : \R_+ \to \R_+$ be a sequence of continuous functions which such that for some $s \in \R$ and $\beta < \alpha$, as $n \to \infty$, $h_n(y) = \bigO{k_n^{s} e^{\beta y}}$ and $h_n(y) = \Omega(1)$, uniformly on $0 \le y \le R$. Then, as $n \to \infty$,
\[
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y 
	= (1 + \smallO{1}) \, n \int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
In particular,
\[
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y = \bigO{1} n \, k_n^{-(2\alpha + 1)} \max_{y \in \Kcal_{C}(k_n)} h_n(y),
\]
as $n \to \infty$.
\end{corollary}

\begin{proof}
The second result follows immediately from the first. For the first result we note that by the first statement of Lemma~\ref{lem:concentration_argument}
\begin{align*}
	\int_{[0,R] \setminus (a_n^-, a_n^+)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	&\le \bigO{k_n^s} \int_{\R_+ \setminus (a_n^-, a_n^+)} e^{\beta y } \rho(y,k_n) \alpha e^{-\alpha y} \dd y\\
	&= \bigO{k_n^{s - (1+C^2)/2}}.
\end{align*}
By assumption on $h_n(y)$,
\[
	\int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y 
	= \bigO{k_n^{s+2\beta}} \int_{\Kcal_{C}(k_n)} \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \bigO{k_n^{s+2\beta - (2\alpha + 1)}},
\]
and
\[
	\int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y 
	= \Omega(1) \int_{\Kcal_{C}(k_n)} \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \Omega(k_n^{-(2\alpha + 1)}).
\]
Hence, by taking $C > 0$ such that $(1+C^2)/2 > \max\{2\alpha + 1 + s, 2\alpha +1 - \beta\}$ we get that
\[
	\int_{[0,R] \setminus (a_n^-, a_n^+)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \smallO{1} \int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
The result then follows since
\[
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y
	= n \int_{0}^{R} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
\end{proof}

For functions $h_n(y) = k_n^s h(y)$ we obtain an asymptotic equivalent expression for the associated integral.

\begin{corollary}\label{cor:concentration_heights_asymptotics_n}
Let $h : \R_+ \to \R$ be a continuous function which  satisfies the conditions of Lemma~\ref{lem:concentration_argument} and let $h_n$ be a sequence of functions such that, as $n \to \infty$, $h_n(y) = \Omega(1)$ and $h_n(y) = \bigO{k_n^{s}} h(y)\rho(y,k_n)$, uniformly on $0 \le y \le R$. Then,
\begin{equation}
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y 
	\sim 2\alpha \xi^{2\alpha} \, n \, h_n(2\log(k_n/\xi)) k_n^{-(2\alpha + 1)},
\end{equation}
as $n \to \infty$.
\end{corollary}

\begin{proof}
The result immediately follows by first applying Corollary~\ref{cor:concentration_heights_bounds_n} and then using the second statement from Lemma~\ref{lem:concentration_argument}.
\end{proof}

\begin{remark}[Concentration of heights argument]\label{rmk:concentration_argument}
%\TM{ again, this is a loaded term. I would in the very least change to ``concentration of height'' everywhere }
All the above corollaries use the same reasoning, namely that when the integrand contains $h_n(y) \rho(y,k_n)$, for some "nice" functions $h_n(y)$, then the main contribution is determined by the integration over $\Kcal_{C}(k_n)$.  This implies, for instance, that we only need to carefully analyze the functions $h_n(y)$ on $\Kcal_{C}(y)$, while for a certain class of functions we can even simply replace it with $h_n(2\log(k_n/\xi))$. We will refer collectively to any of these arguments as a \emph{concentration of heights argument}. For example, suppose we know that $h_n(y) = \Omega(1)$ and $h_n(y) = \bigO{k_n^4} e^{\alpha/2 y}$, while $h_n(y) = (1 + \smallO{1}) k_n^2 e^{\alpha/2 y}$, uniformly on $\Kcal_{C}(k_n)$. Then by a concentration of heights argument (in this case Corollary~\ref{cor:concentration_heights_asymptotics_n})
\begin{align*}
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y 
	&= (1 + \smallO{1}) 2 \alpha \xi^{2\alpha} \, n \, k_n^2 (k_n/\xi)^{\alpha/2} k_n^{-(2\alpha + 1)} \\
	&= (1 + \smallO{1}) 2\alpha \xi^{5\alpha/2} \, n \, k_n^{1 + 5\alpha/2}.
\end{align*}
\end{remark}



\begin{remark}[Proof of Proposition~\ref{prop:asymp} revisited]
Note that due to Proposition~\ref{prop:asymptotics_P}, the function $P(y)$ from Section~\ref{sec:asymptotics_average_clustering_ast_P} satisfies all the necessary conditions in Corollary~\ref{cor:concentration_of_heights_asymptotics} with
\[
	h(y) := \begin{cases}
		e^{-\frac{y}{2}(4\alpha - 2)} c_\alpha \xi^{4\alpha - 2} &\mbox{if } \frac{1}{2} < \alpha < \frac{3}{4},\\
		\frac{y}{2} e^{-\frac{y}{2}} &\mbox{if } \alpha = \frac{3}{4},\\
		e^{-\frac{y}{2}} \frac{\alpha - \frac{1}{2}}{\alpha - \frac{3}{4}} &\mbox{if } \alpha > \frac{3}{4}.
	\end{cases}
\] 
Hence, Proposition~\ref{prop:asymp} directly follows from Proposition~\ref{prop:asymptotics_P} and a concentration of heights argument (Corollary~\ref{cor:concentration_of_heights_asymptotics}).
\end{remark}


%
%
%The next proposition establishes this result and we will spend the rest of this section on its proof.
%
%\begin{proposition}\label{prop:concentration_argument_all}
%The conclusions from Lemmas~\ref{lem:concentration_argument} and Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n} and~\ref{cor:concentration_heights_asymptotics_n} still hold if we replace $\rho(y,k_n)$ with either $\rho_{\Po}(y,k_n)$ or $\rho_{\text{box}}(y,k_n)$.
%\end{proposition}

\subsection{A more general concentration of heights argument}\label{ssec:general_concentration_lemma}

Note that since all three corollaries follow from Lemma~\ref{lem:concentration_argument}, Proposition~\ref{prop:concentration_argument_all} follows if we can prove that the conclusions from this lemma hold when we replace $\rho(y,k_n)$ with either $\rho_{\Po}(y,k_n)$ or $\rho_{\text{box}}(y,k_n)$. For this the following, slightly more general version of Lemma~\ref{lem:concentration_argument} will be important.

Although powerful, the current versions of the concentration of heights arguments are only valid for the function $\rho(y,k_n) := \Prob{\Po\left(\Mu{\BallPo{y}}\right) = k_n}$, which uses the neighborhoods in the infinite model $\Ginf$. Since we will also be working in the Poissonized KPKVB model $\GPo$ and the finite box model $\Gbox$, we would like to use concentration of heights arguments when the integrand contains either the function $\rho_{\Po}(y,k_n)$ or $\rho_{\text{box}}(y,k_n)$. To establish these result we first prove a more general version of Lemma~\ref{lem:concentration_argument}.

\begin{lemma}\label{lem:concentration_argument_rho_approximation}
Let $\alpha > \frac{1}{2}, \nu > 0$ and $k_n \to \infty$ such that $k_n = \smallO{n}$, $\ell_n = (1 + \epsilon_n)k_n$, with $\epsilon_n \to 0$ and define
\[
	\lambda_n^\pm = (\ell_n \pm C \sqrt{\ell_n \log(\ell_n)}) \wedge \xi, \quad \text{and} \quad a_n^\pm = 2 \log\left(\frac{\lambda_n^\pm}{\xi}\right).
\] 
In addition, let $\hat{\rho}_n(y,k) = \Prob{\Po(\hat{\mu}_n(y)) = k}$, with $\hat{\mu}_n(y) = (1 + \phi_n(y))\mu(y)$ and 
where $\phi_n(y)$ is a differentiable function satisfying:
\begin{enumerate}[\upshape i)]
\item For some $0 < \varepsilon < 1$, $\displaystyle \lim_{n \to \infty} \sup_{0 \le y \le (1 - \varepsilon)R_n} |\phi_n(y)| = 0$,
\item $\displaystyle \lim_{n \to \infty}  \sup_{y \in \Kcal_{C}(\ell_n)} |\phi_n^\prime(y)| = 0.$
\end{enumerate}
Then the following holds:
\begin{enumerate}
\item For any continuous function $h : \R_+ \rightarrow  \R$, such that $h(y) = \bigO{e^{\beta y}}$ as $y \to \infty$ for some $\beta < \alpha$, 
\begin{equation}\label{eq:error_bound_int_rho_approx_not_K}
	\int_{\R_+ \setminus (a_n^-, a_n^+)} \hat{\rho}_n(y,k_n) h(y) \alpha e^{-\alpha y} \dd y
	= \bigO{k_n^{-(1+C^2)/2}},
\end{equation}
as $n \to \infty$.
\item If in addition, $h(a_n) \sim h(b_n)$ whenever $a_n \sim b_n$, as $n \to \infty$, then,
\begin{equation}\label{eq:concentration_h_rho_approx}
	\int_0^\infty h(y) \hat{\rho}_n(y,k_n) \alpha e^{-\alpha y} \dd y \sim  
		\int_0^\infty h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y,
\end{equation}
as $n \to \infty$.
\end{enumerate}
\end{lemma}

\begin{proof} \hfill

\paragraph{Proof of statement 1.}
Let $0 < \varepsilon < 1$ be such that condition ii) holds and take $\varepsilon^\prime = \min\{\varepsilon,1/3\} < 1/2$. We first show that the integration over $(1-\varepsilon^\prime)R \le y \le R$ is negligible.
 
Since $h(y) = \bigO{e^{\beta y}}$ we have
\begin{align*}
	\int_{(1-\varepsilon^\prime)R_n}^{R_n} h(y) \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
	&= \bigO{1} \hat{\rho}_n((1-\varepsilon^\prime)R,k_n) e^{-(\alpha-\beta)(1-\varepsilon^\prime)R} \\
	&= \bigO{\hat{\rho}_n((1-\varepsilon^\prime)R,k_n) n^{-2(\beta-\alpha)(1-\varepsilon^\prime)}}.
\end{align*}
By assumption on $\hat{\mu}_n(y)$ we have that $\hat{\mu}_n((1-\varepsilon^\prime)R) = \bigT{\mu((1-\varepsilon^\prime)R} = \bigT{n^{2(1-\varepsilon^\prime)}}$. Since $k_n = \smallO{n}$, by our choice of $\varepsilon^\prime$, $\hat{\mu}_n((1-\varepsilon^\prime)R)/k_n = \omega\left(n^{1 - 2\varepsilon^\prime}\right) \to \infty$ as $n \to \infty$. We can now use Stirling's approximation to bound $\hat{\rho}_n((1-\varepsilon^\prime)R,k_n)$ as
\begin{align*}
	\hat{\rho}_n((1-\varepsilon^\prime)R,k_n) &= \Prob{\Po(\hat{\mu}_n((1-\varepsilon^\prime)R)) = k_n} \\
	&= \frac{\hat{\mu}_n((1-\varepsilon^\prime)R)^{k_n}}{k_n!} e^{-\hat{\mu}_n((1-\varepsilon^\prime)R)}\\
	&= \bigO{1} k_n^{-1/2} \left(\frac{\hat{\mu}_n((1-\varepsilon^\prime)R)}{k_n}\right)^{k_n} e^{k_n - \hat{\mu}_n((1-\varepsilon^\prime)R)}\\
	&= \bigO{1} k_n^{-1/2} e^{k_n\left(1 - \frac{\hat{\mu}_n((1-\varepsilon^\prime)R)}{k_n}\right)+ \log\left(\frac{\hat{\mu}_n((1-\varepsilon^\prime)R)}{k_n}\right)}\\
	&\le \bigO{1} k_n^{-1/2} e^{-\hat{\mu}_n((1-\varepsilon^\prime)R)/2},
\end{align*}
where the last line follows since $1 - x + \log(x) \le -x/2$ for large enough $x$. We conclude that
\[
	\int_{(1-\varepsilon^\prime)R_n}^{R_n} h(y) \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
	= \bigO{k_n^{-1/2} n^{-2(\beta-\alpha)(1-\varepsilon^\prime)} e^{-n^{2(1-\varepsilon^\prime)}}}
	= \bigO{k_n^{(1+C^2)/2}}.
\]

We are left to show that for sufficiently large $C > 0$,
\begin{equation}\label{eq:concentration_argument_an_-}
	 \int_0^{a_n^-} \hat{\rho}_n(y,k_n) e^{(\beta-\alpha) y} \dd y = \bigO{k_n^{-(1+C^2)/2}},
\end{equation}
and
\begin{equation}\label{eq:concentration_argument_an_+}
	\int_{a_n^+}^{(1-\varepsilon^\prime)R_n} \hat{\rho}_n(y,k_n) e^{(\beta-\alpha) y} \dd y = \bigO{k_n^{-(1+C^2)/2}}.
\end{equation}
%\TM{ Why can we change the upper limit of the integral? PLease elaborate (in the paper) }

For simplicity we write $\mu(y) := \mu\left(\BallPo{y}\right)$. Now fix some $0 < \delta < 1$ and let $n$ be large enough such that 
\[
\sup_{0 < y \le (1-\varepsilon^\prime)R_n} |\phi_n(y)| < \delta, \quad
\lambda_n^+(1 - \delta) > k_n \quad \text{and} \quad
\lambda_n^-(1 + \delta) < k_n.
\]

Next, recall that the function $\lambda \mapsto \Prob{\Po(\lambda) = k}$ is monotonic increasing on $[0,k]$ and monotonic decreasing on $[k, \infty)$. Then since for $n$ large enough we have 
\[
	\hat{\mu}_n(y) = \mu(y)(1 + \phi_n(y)) \ge \mu(y)(1 - \delta) \ge \mu(a_n^+)(1 - \delta)
	= (\ell_n + C \kappa_n)(1 - \delta) > k_n,
\]
it follows that 
\[
	\hat{\rho}_n(y,k_n) = \Prob{\Po(\hat{\mu}_n(y)) = k_n} \le \Prob{\Po(\mu(y)(1-\delta)) = k_n},
\]
for all $a_n^+ \le y \le (1-\varepsilon^\prime)R_n$. By making the change of variables $z = \mu^{-1}(\mu(y)(1-\delta)) = y + 2 \log(1-\delta)$ we then get
\begin{align*}
	\int_{a_n^+}^{(1-\varepsilon^\prime)R_n} \hat{\rho}_n(y,k_n) e^{(\beta - \alpha)y} \dd y
	&\le \int_{a_n^+}^{(1-\varepsilon^\prime)R_n} \Prob{\Po(\mu(y)(1-\delta)) = k_n} 
		e^{(\beta-\alpha) y} \dd y\\
	&= (1-\delta)^{\beta - \alpha} \int_{a_n^+ + 2\log(1-\delta)}^{(1-\varepsilon^\prime)R_n + 2\log(1-\delta)} 
		\Prob{\Po(\mu(z)) = k_n} e^{(\beta - \alpha)z} \dd z\\
	&= \bigO{1} \int_{a_n^+}^{\infty} \rho(z,k_n) e^{(\beta - \alpha)z} \dd z\\
	&= \bigO{k_n^{-(1+C^2)/2}},
\end{align*}
where the last line is due to Lemma~\ref{lem:concentration_argument}. This proves~\eqref{eq:concentration_argument_an_+}.

%implies that for large enough $C$,
%\[
%	\lim_{n \to \infty} k_n^s \int_{a_n^+}^{\infty} \rho(z,k_n) e^{(\beta - \alpha)z} \dd z = 0,
%\]
%we have proven~\eqref{eq:concentration_argument_an_+}.

The proof of~\eqref{eq:concentration_argument_an_-} follows the same line of reasoning. This time we use that for $0 \le y \le a_n^-$,
\[
	\hat{\mu}_n(y) \le \mu(y)(1 + \delta) \ge \mu(a_n^-)(1 + \delta)
		= (\ell_n - C \kappa_n)(1 + \delta) < k_n,
\]
so that 
\[
	\hat{\rho}_n(y,k_n) = \Prob{\Po(\hat{\mu}_n(y)) = k_n} \le \Prob{\Po(\mu(y)(1+\delta)) = k_n}.
\]
Making a similar change of variables $z = y + 2 \log(1+\delta)$ we then get
\begin{align*}
	\int_0^{a_n^-} \hat{\rho}_n(y,k_n) e^{(\beta - \alpha)y} \dd y
	&= \int_0^{a_n^-}\Prob{\Po(\mu(y)(1-\delta)) = k_n} 
		e^{(\beta-\alpha) y} \dd y\\
	&\le (1+\delta)^{\beta - \alpha} \int_0^{a_n^- + 2\log(1+\delta)} 
		\rho(z,k_n) e^{(\beta - \alpha)z} \dd z,
\end{align*}
and hence~\eqref{eq:concentration_argument_an_-} follows by another application of Lemma~\ref{lem:concentration_argument}. 

\paragraph{Proof of statement 2.}

The proof of the second statement follows the same line of reasoning as above. First, by the mean value theorem for definite integrals 
\[
	\int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) h(y) e^{-\alpha y} \dd y
	= h(c_n) \int_{a_n^-}^{a_n^+} \rho(z,k_n) e^{-\alpha z} \dd z,
\]
for some $c_n \in (a_n^-, a_n^+)$. Since, $c_n \sim 2 \log(k_n/\xi)$, by assumption on $h$, $h(c_n)\sim h(2\log(k_n/\xi))$. Therefore it is enough to show that
\[
	\int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
	= \left(1 + o(1)\right) \int_{a_n^-}^{a_n^+} \rho(z,k_n) e^{-\alpha z} \dd z.
\] 
or equivalently,
\[
	\int_{a_n^-}^{a_n^+} \rho(z,k_n) e^{-\alpha z} \dd z
	= \left(1 + o(1)\right)\int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y.
\] 

Using the change of variable $z = \mu^{-1}(\hat{\mu}_n(y))$ and writing $\hat{a}_n^\pm = \hat{\mu}_n^{-1}(\mu(a_n^\pm))$, we get
\begin{align*}
	\int_{a_n^-}^{a_n^+} \rho(z,k_n) e^{-\alpha z} \dd z 
	&= \int_{a_n^-}^{a_n^+} \Prob{\Po(\mu(z)) = k_n} e^{-\alpha z} \dd z\\
	&= \int_{\hat{a}_n^-}^{\hat{a}_n^+} \Prob{\Po(\hat{\mu}_n(y)) = k_n} e^{-\alpha \mu^{-1}(\hat{\mu}_n(y))} 
		\frac{\hat{\mu}_n^\prime(y)}{\mu^\prime(\mu^{-1}(\hat{\mu}_n(y)))} \dd y,
\end{align*}
where the fraction in the last line follows from the chain rule and the fact that $(\mu^{-1})^\prime(t) = (\mu^\prime(\mu^{-1}(t)))^{-1}$.

Now recall that $\hat{\mu}_n(y) = \mu(y)(1 + \phi_n(y))$, with $\phi_n(y)$ satisfying conditions i) and ii). It then follows $\hat{\mu}_n^\prime(y) = (1 + \smallO{1})\mu^\prime(y)$ as $n \to \infty$, uniformly on $(a_n^-, a_n^+)$. Next we note that $\mu^\prime(y) = \mu(y)/2$ from which it follows that uniformly on $[a_n^-, a_n^+]$,
\[
	\frac{\hat{\mu}_n^\prime(y)}{\mu^\prime(\mu^{-1}(\hat{\mu}_n(y)))}
	= \frac{2\hat{\mu}_n^\prime(y)}{\hat{\mu}_n(y)}
	= \frac{(1 + \smallO{1})2\mu^\prime(y)}{(1 + \smallO{1})\mu(y)}
	= (1+\smallO{1})
\]
Therefore,
\begin{align*}
	\int_{a_n^-}^{a_n^+} \rho(z,k_n) e^{-\alpha z} \dd z
	&= (1 + \smallO{1})\int_{\hat{a}_n^-}^{\hat{a}_n^+} \Prob{\Po(\hat{\mu}_n(y)) = k_n} e^{-\alpha y} \dd y\\
	&= (1 + \smallO{1}) \int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y\\
	&= (1 + \smallO{1}) \int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
\end{align*}
which finishes the proof.
\end{proof}

To apply this lemma to $\rho_{\Po}(y,k_n)$ or $\rho_{\text{box}}(y,k_n)$ we need to show that both these functions are of the form $\rho(y,k_n)(1 + \phi_n(y))$, where $\phi_n(y)$ satisfies the conditions i) and ii) in Lemma~\ref{lem:concentration_argument_rho_approximation}. We will do this in the next two sections and establish that the results from Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n}
and~\ref{cor:concentration_heights_asymptotics_n} hold when we replace $\rho(y,k_n)$ with either $\rho_{\text{box}}(y,k_n)$
or $\rho_{\Po}(y,k_n)$. 

\begin{remark}[Generalized concentration of heights arguments]
Since the results from Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n} and~\ref{cor:concentration_heights_asymptotics_n} hold for any of the three functions $\rho(y,k_n)$, $\rho_{\text{box}}(y,k_n)$ and $\rho_{\Po}(y,k_n)$, we will will refer only to one of these three when using a concentration of heights argument of for any of the three models $\GPo$, $\Gbox$ and $\Ginf$. 
\end{remark}

\subsection{Concentration of heights for the finite box model}\label{ssec:average_degree_P_n}

The following lemma immediately implies that $\Mu{\BallPon{y}}$ satisfies the conditions of Lemma~\ref{lem:concentration_argument_rho_approximation}.

\begin{lemma}\label{lem:average_degree_P_n}
For all $y > 2\log(\pi/2)$,
\[
	\Mu{\BallPon{p}} = \Mu{\BallPo{p}}\left(1 - \phi_n(y)\right)
\]
%\TM{ where did the curly B's go? }\PvdH{Typo. Fixed}
where $\phi_n(y) \ge 0$ is given by
\[
	\phi_n(y) = \left(\frac{\pi}{2}\right)^{-(2\alpha - 1)}e^{-(\alpha-\frac{1}{2})(R_n - y)}
	- \frac{(2\alpha - 1)\pi}{4\alpha}\left(\left(\frac{\pi}{2}\right)^{-2\alpha} 
	e^{-(\alpha - \frac{1}{2})(R_n - y)} - e^{-(\alpha - \frac{1}{2})R_n - \frac{y}{2}}\right).
\]
On the other hand, if $y \le 2 \log(\pi/2)$ then
\[
	\mu_{\alpha,\nu}(\BallPon{p}) = \mu_{\alpha,\nu}(\BallPo{p})\left(1 - e^{-(\alpha - \frac{1}{2})R_n}\right).
\]
\end{lemma}

\begin{proof}
First note that since we have identified the boundaries of $[-\frac{\pi}{2}e^{\frac{R_n}{2}}, \frac{\pi}{2}e^{\frac{R_n}{2}}]$ we can assume, without loss of generality, that $p = (0,y)$. We then have that the boundaries of $\BallPon{p}$ are given by the equations $x^\prime = \pm e^{\frac{y+y^\prime}{2}}$, which intersect the left and right boundaries of $[-\frac{\pi}{2}e^{\frac{R_n}{2}}, \frac{\pi}{2}e^{\frac{R_n}{2}}]$ at height
\[
	h(y) = R_n + 2 \log\left(\frac{\pi}{2}\right) - y.
\]
Therefore, if $y \le 2 \log(\pi/2)$ this intersection occurs above the height $R_n$ of the box $\Rcal$ while in the other case the full region of the box above $h(y)$ is connected to $p$. 

We will first consider the case where $y > 2 \log(\pi/2)$. Recall that $\mu_{\alpha,\nu}(\BallPo{p}) = \xi e^{\frac{y}{2}}$ where $\xi = \frac{4\alpha \nu}{(2\alpha - 1)\pi}$. Then, after some simple algebra, we have that
\begin{align*}
	\mu_{\alpha,\nu}(\BallPon{p})
	&= \int_0^{h(y)} \int_{-\frac{\pi}{2}e^{\frac{R_n}{2}}}^{\frac{\pi}{2}e^{\frac{R_n}{2}}} 
		\ind{|x^\prime| \le e^{\frac{y+y^\prime}{2}}} f_{\alpha,\nu}(x^\prime,y^\prime) \, dx^\prime \, dy^\prime\\
	&\hspace{10pt}+ \int_{h(y)}^{R_n} \int_{-\frac{\pi}{2}e^{\frac{R_n}{2}}}^{\frac{\pi}{2}e^{\frac{R_n}{2}}} 
		f_{\alpha,\nu}(x^\prime,y^\prime) \, dx^\prime \, dy^\prime\\
	&= \frac{2 \alpha \nu}{\pi} e^{\frac{y}{2}} \int_0^{h(y)} e^{-(\alpha - \frac{1}{2})y^\prime} \, dy^\prime
		+ \alpha \nu e^{\frac{R_n}{2}} \int_{h(y)}^{R_n} e^{-\alpha y^\prime} \, dy^\prime \\
	&= \xi e^{\frac{y}{2}}\left(1 - \left(\frac{\pi}{2}\right)^{-(2\alpha - 1)} 
		e^{-(\alpha - \frac{1}{2})(R_n - y)}\right)\\
	&\hspace{10pt}+ \nu e^{\frac{R_n}{2}}\left(\left(\frac{\pi}{2}\right)^{-2\alpha} e^{-\alpha(R_n - y)} 
		- e^{-\alpha R_n}\right)\\
	&= \mu_{\alpha,\nu}(\BallPo{p})\left(1 - \phi_n(y)\right).
\end{align*}
Since, for all $\alpha > \frac{1}{2}$,
\[
	\left(\frac{\pi}{2}\right)^{-(2\alpha - 1)} \ge \frac{(2\alpha - 1)\pi}{4\alpha} \left(\frac{\pi}{2}\right)^{-2\alpha}
\]
it follows that $\phi_n(y) \ge 0$.

When $y \le 2 \log(\pi/2)$ we have
\begin{align*}
	\mu_{\alpha,\nu}(\BallPon{p})
	&= \int_0^{R_n} \int_{-\frac{\pi}{2}e^{\frac{R_n}{2}}}^{\frac{\pi}{2}e^{\frac{R_n}{2}}} 
		\ind{|x^\prime| \le e^{\frac{y+y^\prime}{2}}} f_{\alpha,\nu}(x^\prime,y^\prime) \, dx^\prime \, dy^\prime\\
	&= \frac{2 \alpha \nu}{\pi} e^{\frac{y}{2}} \int_0^{R_n} e^{-(\alpha - \frac{1}{2})y^\prime} \, dy^\prime\\
	&= \mu_{\alpha,\nu}(\BallPo{p})\left(1 - e^{-(\alpha - \frac{1}{2})R_n}\right).
\end{align*}
\end{proof}

The following is now immediate.

\begin{corollary}\label{cor:concentration_of_heights_Gbox}
The statement in Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n}
and~\ref{cor:concentration_heights_asymptotics_n} hold when we replace $\rho(y,k_n)$ with $\rho_{\text{box}}(y,k_n)$.
\end{corollary}

\subsection{Concentration of heights for the KPKVB model}\label{ssec:average_degree_HP_n}

%\TM{  the term ``average degree" does not fit very well with what goes on in this section. We are considering the expected number of points in a ball, but not yet computing the average degree of the graph. }\PvdH{I agree and have changed the header.}

We will now show that a concentration of heights argument also applies to the KPKVB model. Due to the hyperbolic distance formula, the computations are however more involved than for the finite box model. Recall that under the coupling between the hyperbolic random graph and the finite box model, for two points $p, p^\prime$ with $y + y^\prime < R_n$, $p^\prime \in \BallHyp{p}$ exactly when $|x-x^\prime|_{\pi e^{R_n/2}} \le \Phi(y,y^\prime)$. In this setting, the coupling lemma (Lemma~\ref{lem:asymptotics_Omega_hyperbolic}) gives that  
\[
	e^{\frac{1}{2}(y+y^\prime)} - K e^{\frac{3}{2}(y+y^\prime) - R_n} \leq \Phi(y, y^\prime) 
		\leq  e^{\frac{1}{2}(y+y^\prime)} + K e^{\frac{3}{2}(y+y^\prime) - R_n},
\]
for some constant $K$. This result enables us to determine the measure of a ball around a given point $p=(0,y)$. Recall that the hyperbolic ball $\BallHyp{p}$ is a subset of $\Rcal$ and not of the hyperbolic disc $\Dcal_{R_n}$, i.e. the balls $\BallHyp{p}$ "live" in the finite box and not the hyperbolic disc. We start with the following preliminary result.

\begin{lemma}\label{lem:hyperbolic_ball_lower_part}
Let $\Phi(y,y^\prime)$ be defined as in~\eqref{eq:def_Omega_hyperbolic}. Then, for any $0 \le \delta < 1$
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} \frac{2\nu \alpha}{\pi} \int_0^{(1-\delta)(R-y)} \Phi(y,y^\prime) e^{-\alpha y^\prime} = 1.
\]
\end{lemma}

\begin{proof}
Recall that $\Mu{\BallPo{0,y}} = \xi e^{y/2}$ where $\xi = \frac{4\alpha\nu}{\pi(2\alpha - 1)}$. Using Lemma~\ref{lem:asymptotics_Omega_hyperbolic} we have 
\begin{align*}
	\frac{2\nu \alpha}{\pi} \int_0^{(1-\delta)(R-y)} \Phi(y,y^\prime) e^{-\alpha y^\prime} 
	&\le \frac{2\nu \alpha}{\pi} \int_{0}^{(1-\delta)(R-y)} \left(e^{\frac{y + y^\prime}{2}} + K e^{\frac{3}{2}(y + y^\prime) - R_n}\right)
		e^{-\alpha y^\prime} \dd y^\prime\\
	&= \Mu{\BallPo{0,y}}\left(1 - e^{-(\alpha - \frac{1}{2})(1-\delta)(R_n - y)}\right) \\
	&\hspace{10pt}+ \frac{2\nu \alpha}{\pi} K e^{\frac{3 y}{2} - R_n}\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime
\end{align*}

We first compute the integral, which depends on the value of $\alpha$,
\[
	\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime
	= \begin{cases}
		\frac{2}{3 - 2\alpha}\left(e^{(\frac{3}{2} - \alpha)(1-\delta)(R-y)} - 1\right) &\mbox{if } 1/2 < \alpha < 3/2,\\
		(1-\delta)(R-y) &\mbox{if } \alpha = 3/2,\\
		\frac{2}{2\alpha-3}\left(1 - e^{-(\alpha - \frac{3}{2})(1-\delta)(R-y)}\right) &\mbox{if } \alpha > 3/2.
	\end{cases}
\]
Therefore we get
\begin{align*}
	&\frac{2\nu \alpha}{\pi} K e^{\frac{3 y}{2} - R_n}
		\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime\\
	&= \Mu{\BallPo{0,y}}\begin{cases}
		\frac{(2\alpha - 1)K}{3 - 2\alpha}\left(e^{-(\alpha - \frac{1}{2})(R_n - y)-(\frac{3}{2}-\alpha)\delta(R-y)} 
			- e^{-(R_n - y)}\right)
		&\mbox{if } 1/2 < \alpha < 3/2,\\
		\frac{(2\alpha -1)K}{2} (1-\delta)(R - y)e^{-(R_n - y)} &\mbox{if } \alpha = 3/2,\\
		\frac{(2\alpha - 1)K}{2\alpha - 3} \left(e^{-(R_n - y)} - e^{-(\alpha - \frac{1}{2})(R_n - y) 
			-(\alpha - \frac{3}{2})(R-y)}\right)
		&\mbox{if } \alpha > 3/2,
	\end{cases}
\end{align*}
and hence
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1}
	\frac{2\nu \alpha}{\pi} K e^{\frac{3 y}{2} - R_n}
			\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime = 0.
\]
Since $\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} e^{-(\alpha - \frac{1}{2})(1-\delta)(R_n - y)} = 0$, we conclude that
\[
	\limsup_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} \int_0^{(1-\delta)(R-y)} \Phi(y,y^\prime)
		\alpha e^{-\alpha y^\prime} = 1.
\]
The proof that this also holds for the limit infimum immediately follows, by observing that the only difference with the above computations is the change of sign in front of 
\[
	\frac{2 \nu \alpha}{\pi} K e^{\frac{3 y}{2} - R_n}\int_0^{R_n-y} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime.
\]
\end{proof}

We can now show that the measure of the balls in the KPKVB model and the infinite model are asymptotically equivalent.

\begin{lemma}\label{lem:average_degree_hyperbolic}
For any $0 < \varepsilon < 1$
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \frac{\Mu{\BallHyp{y}}}{\Mu{\BallPo{y}}} = 1.
\]
%Let $\eps \in (0, 1)$. Then for all $0 \le y \le (1 - \eps)R_n$
%\[
%	 1 - \phi_{\H,n}^{(1)}(y) - \phi_{\H,n}^{(2)}(y) \le \frac{\Mu{\BallHyp{0,y}}}{\Mu{\BallPo{0,y}}} 
%	 \le 1 - \phi_{\H,n}^{(1)}(y) + \phi_{\H,n}^{(2)}(y),
%\]
%where
%\[
%	\phi_{\H,n}^{(1)}(y) = \frac{2\alpha - 1 - 4\pi}{4\pi} e^{-(\alpha - \frac{1}{2})(R_n - y)} 
%		+ \left(\alpha - \frac{1}{2}\right)\pi e^{-(\alpha - \frac{1}{2})R_n - y/2},
%\]
%and
%\[
%	\phi_{\H,n}^{(2)}(y) = 
%	+ \begin{cases}
%			\frac{(2\alpha - 1)K}{3 - 2\alpha}\left(e^{-(\alpha - \frac{1}{2})(R_n - y)} - e^{-(R_n - y)}\right)
%			&\mbox{if } 1/2 < \alpha < 3/2,\\
%			\frac{(2\alpha -1)K}{2} (R_n - y)e^{-(R_n - y)} &\mbox{if } \alpha = 3/2,\\
%			\frac{(2\alpha - 1)K}{2\alpha - 3} \left(e^{-(R_n - y)} - e^{-(\alpha - \frac{1}{2})(R_n - y)}\right)
%			&\mbox{if } \alpha > 3/2,
%		\end{cases}
%\]
%with $K$ being the constant coming from the approximation of $\Phi$ in Lemma~\ref{lem:asymptotics_Omega_hyperbolic}.
%%\TM{ We want to say in the lemma where $K$ comes from. (not everyone reads surrounding text, or reads linearly, in a paper as long as this one.) }
\end{lemma}

\begin{proof}
We perform the computation of $\Mu{\BallHyp{0,y}}$ by splitting the integration with respect to the height $y^\prime$ into the cases $y^\prime > R_n - y$ and $y^\prime \le R_n - y$,
\[
	\Mu{\BallHyp{y}} 
	= \Mu{\BallHyp{y} \cap \Rcal ([0,R_n - y))} + \Mu{\BallHyp{y} \cap \Rcal ([R_n - y, R_n])}.
\]

For the first part we have that
\[
	\Mu{\BallHyp{(0,y)} \cap\Rcal[(0,R_n-y)]} = \frac{2\nu \alpha}{\pi} \int_0^{R-y} \Phi(y,y^\prime) e^{-\alpha y^\prime}
	\dd y^\prime.
\]
Hence, by applying Lemma~\ref{lem:hyperbolic_ball_lower_part} with $\delta = 0$ we conclude that
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1}
	\Mu{\BallHyp{(0,y)} \cap\Rcal[(0,R_n-y)]} = 1.
\]

For the second part we observer that $\BallHyp{(0,y)} \cap \Rcal ([R_n - y, R_n])= \Rcal([R_n-y,R_n])$. 
Thus, 
\begin{align*}
	&\hspace{-30pt}\Mu{\BallHyp{(0,y)} \cap \Rcal ([R_n - y, R_n])} \\
	&= \int_{R_n - y}^{R_n} \int_{I_n} f_{\alpha,\nu}(x^\prime, y^\prime) \dd x^\prime \dd y^\prime
		= \nu \alpha e^{R_n/2}\left(e^{-\alpha(R_n - y)} - e^{-\alpha R_n}\right)\\
	&= \Mu{\BallPo{0,y}} \frac{2\alpha - 1}{4\pi} \left( e^{-(\alpha - \frac{1}{2})(R_n - y)}
		- e^{-(\alpha - \frac{1}{2})R_n - y/2}\right), \numberthis \label{eq:mu_hyperbolic_ball_part_1}
\end{align*}
from which we conclude that
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} 
	\Mu{\BallHyp{(0,y)} \cap \Rcal ([R_n - y, R_n])} = 0,
\]
which finishes the proof.
\end{proof}

A direct consequence of Lemma~\ref{lem:average_degree_hyperbolic} is that $\Mu{\BallHyp{y}} = \Mu{\BallPo{y}}(1 + \phi_n(y))$, where $\phi_n(y) := \Mu{\BallHyp{y}}/\Mu{\BallPo{y}} - 1$ satisfies condition i) in Lemma~\ref{lem:concentration_argument_rho_approximation}. To show that condition ii) is also satisfied we need to analyze
\[
	\phi_n^\prime(y) = 
	\Mu{\BallPo{y}}^{-1} \frac{\partial}{\partial y} \mu\left(\BallHyp{y}\right) -  \frac{1}{2} \frac{\Mu{\BallHyp{y}}}{\Mu{\BallPo{y}}},
\]
where we used that $\frac{\partial}{\partial y}\Mu{\BallPo{y}} = \frac{1}{2}\Mu{\BallPo{y}}$. Again, Lemma~\ref{lem:average_degree_hyperbolic} implies that 
\[
	\lim_{n \to \infty} \sup_{0 \le y \le (1-\varepsilon)R_n} \frac{1}{2} \frac{\Mu{\BallHyp{y}}}{\Mu{\BallPo{y}}}
	= \frac{1}{2}.
\]
The following lemma shows that the same holds for the first term from which we conclude that $\phi_n(y)$ satisfies condition ii) in Lemma~\ref{lem:concentration_argument_rho_approximation}.

\begin{lemma}
For any $0 < \varepsilon < 1$,
\[
	\lim_{n \to \infty} \sup_{0 \le y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1}
	\frac{\partial}{\partial y} \mu\left(\BallHyp{y}\right) 
	= \frac{1}{2}.
\]
\end{lemma}

\begin{proof}
We again split $\Mu{\BallHyp{y}}$ over the top and bottom part,
\[
	\Mu{\BallHyp{y}} 
	= \Mu{\BallHyp{y} \cap \Rcal ([0,R_n - y))} + \Mu{\BallHyp{y} \cap \Rcal ([R_n - y, R_n])},
\]
where
\[
	\Mu{\BallHyp{y} \cap \Rcal ([0,R_n - y))} = \frac{2\alpha \nu}{\pi}\int_0^{R - y} \Phi(y,y^\prime) 
		e^{-\alpha y^\prime} \dd y^\prime,
\]
with $\Phi(y,y^\prime)$ defined as in~\eqref{eq:def_Omega_hyperbolic} and, see~\eqref{eq:mu_hyperbolic_ball_part_1},
\[
	\Mu{\BallHyp{y} \cap \Rcal ([R_n - y, R_n])}
	= \xi e^{y/2}\frac{2\alpha - 1}{4\pi} \left( e^{-(\alpha - \frac{1}{2})(R_n - y)}
	- e^{-(\alpha - \frac{1}{2})R_n - y/2}\right).
\]
Taking the derivative of the last expression gives
\begin{align*}
	&\frac{\partial}{\partial y} \Mu{\BallHyp{y} \cap \Rcal ([R_n - y, R_n])}\\
	&= \frac{1}{2}\Mu{\BallHyp{y} \cap \Rcal ([R_n - y, R_n])}
		+ \xi e^{y/2}\frac{2\alpha - 1}{4\pi}\left(
		\left(\alpha - \frac{1}{2}\right)e^{-(\alpha - \frac{1}{2})(R_n - y)} 
		+ \frac{1}{2}e^{-(\alpha - \frac{1}{2})R_n - y/2}\right)\\
	&= \frac{1}{2}\Mu{\BallHyp{y} \cap \Rcal ([R_n - y, R_n])}\left(1 +
		\frac{(2\alpha - 1)e^{-(\alpha - \frac{1}{2})(R_n - y)} + e^{-(\alpha - \frac{1}{2})R_n - y/2}}
		{e^{-(\alpha - \frac{1}{2})(R_n - y)} - e^{-(\alpha - \frac{1}{2})R_n - y/2}}\right).
\end{align*}
Since, $\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} \Mu{\BallHyp{y} \cap \Rcal ([R_n - y, R_n])} = 0$, we are left to show that
\begin{equation}\label{eq:derivative_mu_hyp_ball_main}
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} \frac{2\alpha \nu}{\pi} \frac{\partial}{\partial y} \int_0^{R - y} \Phi(r,r^\prime) e^{-\alpha y^\prime} \dd y^\prime
	= \frac{1}{2}.
\end{equation}

We start with some preliminary computations. For convenience we define
\[
	\Xi_n(y,y^\prime) = 1 - \frac{\cosh(R- y)\cosh(R-y^\prime) - \cosh(R)}{\sinh(R - y) \sinh(R - y^\prime)},
\]
so that
\[
	\Phi(R -y, R - y^\prime) = \frac{1}{2}e^{R/2} \arccos\left(1 - \Xi_n(y,y^\prime)\right).
\]
Next, following the same calculation as in the proof of~\cite[Lemma 28]{fountoulakis2018law}, we write
\begin{align*}
	\Xi(y,y^\prime)
	&= 2 e^{-(R - y - y^\prime)} \frac{\left(1 - e^{y^\prime - y - R}\right)\left(1 - e^{y - y^\prime - R}\right)}
		{\left(1 - e^{-2(R - y^\prime)}\right)\left(1 - e^{-2(R- y)}\right)}\\
	&:= 2 e^{-(R - y - y^\prime)} \frac{h_1(y) h_2(y)}{h_3(y^\prime) h_3(y)},
\end{align*}
with
\[
	h_1(y) = 1 - e^{y^\prime - y - R}, \quad h_2(y) = 1 - e^{y - y^\prime - R}
	\quad \text{and} \quad h_3(y) = 1 - e^{-2(R- y)}.
\]
We suppressed the dependence on $n$ and, in some cases, on $y^\prime$ for notation convenience.

We make two important observations. First, $\Xi(y,y^\prime)$ is an increasing function in both arguments, for $y, y^\prime < R$ and $y + y^\prime < R$. Second, for all $y + y^\prime < R$, $h_1(y) \le h_3(y^\prime)$ and $h_2(y) \le h_3(y)$, while $h_3(y), h_3(y^\prime) < 1$, so that
\begin{equation}\label{eq:derivative_hyp_ball_Xi_bounds}
	2 e^{-(R - y - y^\prime)}h_1(y) h_2(y) \le \Xi_n(y,y^\prime) \le 2 e^{-(R - y - y^\prime)}.
\end{equation}
In particular, there exists a $0 < \delta < 1$ such that $1 \le \Xi(y,y^\prime) \le 2$ for all $0 < y < R$ and $(1-\delta)(R-y) < y^\prime < R$.

Next, taking the derivative of $\Xi_n(y,y^\prime)$ yields,
\begin{align*}
	\frac{\partial}{\partial y} \Xi(y,y^\prime) &= \Xi(y,y^\prime) + 2 e^{-(R - y - y^\prime)}
		\left(\frac{h_1^\prime(y) h_2(y)}{h_3(y^\prime) h_3(y)} + \frac{h_1(y)h_2^\prime(y)}{h_3(y^\prime) h_3(y)}
		- \frac{h_1(y) h_2(y) h_3^\prime(y)}{h_3(y^\prime) h_3(y)^2}\right)\\
	&= \Xi(y,y^\prime)\left(1 + \frac{h_1^\prime(y)}{h_1(y)} + \frac{h_2^\prime(y)}{h_2(y)} 
		- \frac{h_3^\prime(y)}{h_3(y)}\right)\\
	&:= \Xi(y,y^\prime)\left(1 + \varphi_n(y,y^\prime)\right),
\end{align*}
with
\[
	\varphi_n(y,y^\prime) = \frac{e^{y^\prime - y- R}}{1 - e^{y^\prime - y - R}} 
	- \frac{e^{y - y^\prime - R}}{1 - e^{y - y^\prime - R}} - \frac{2e^{-2(R - y)}}{1 - e^{-2(R-y)}}. 
\]
Therefore, by the chain rule,
\begin{align*}
	\frac{\partial}{\partial y} \Phi(R -y, R - y^\prime)
	&= \frac{1}{2}e^{R/2} \frac{1}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}} 
		\frac{\partial}{\partial y} \Xi(y,y^\prime)\\
	&=  \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}\left(1 + 
		\varphi_n(y,y^\prime)\right). \numberthis \label{eq:derivative_Phi}
\end{align*}
Applying the Leibniz's rule we then get
\begin{align*}
	&\hspace{-30pt}\frac{\partial}{\partial y} \int_0^{R - y} \Phi(y,y^\prime) \alpha e^{-\alpha y^\prime} \dd y^\prime\\
	&= - \alpha\Phi(y,R - y)e^{-\alpha(R-y)} + \int_0^{R - y} \frac{\partial}{\partial y}  \Phi(y,y^\prime) 
		\alpha e^{-\alpha y^\prime} \dd y^\prime\\
	&= -\frac{\pi}{2}e^{-(\alpha-\frac{1}{2})R_n + \alpha y} + \int_0^{R- y} \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
		\left(1 + \varphi_n(y,y^\prime)\right) \alpha e^{-\alpha y^\prime} \dd y^\prime\\
	&= -\frac{\pi}{2}e^{-(\alpha-\frac{1}{2})R_n + \alpha y}  + \int_0^{(1-\delta)(R- y)} \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}
		{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
		\left(1 + \varphi_n(y,y^\prime)\right) \alpha e^{-\alpha y^\prime} \dd y^\prime\\
	&\hspace{10pt}+ \int_{(1-\delta)(R- y)}^{R - y} \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}
			{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
			\left(1 + \varphi_n(y,y^\prime)\right) \alpha e^{-\alpha y^\prime} \dd y^\prime\\
	&:= -I_1(y) + I_2(y) + I_3(y),
\end{align*}
with $\delta$ such that $1 \le \Xi(y,y^\prime) \le 2$ for all $0 < y < R$ and $(1-\delta)(R-y) < y^\prime < R$.

We proceed by showing that
\begin{equation}\label{eq:derivative_hyp_ball_error_1}
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} I_t(y) = 0, \quad \text{for } t = 1,3
\end{equation}
while
\begin{equation}\label{eq:derivative_hyp_ball_main_part}
	\lim_{n \to \infty} \sup_{0 \le y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} \frac{2\nu \alpha}{\pi} I_2(y) = \frac{1}{2}.
\end{equation}
This then implies~\eqref{eq:derivative_mu_hyp_ball_main} and finishes the proof.

Let us first consider $I_1(y)$. Since 
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} I_1(y) 
	\le \lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \frac{\pi}{2\xi} e^{-(\alpha - \frac{1}{2})(R - y)} = 0.
\]

For $I_3(y)$ we first use that $y^\prime < R - y$ to bound $\varphi(y,y^\prime)$ as follows,
\[
	\varphi_n(y,y^\prime) \le \frac{e^{y^\prime - y - R}}{1 - e^{y^\prime - y - R}} \le \frac{e^{-2y}}{1 - e^{-2y}}.
\]
This then yields that
\[
	I_3(y) \le \frac{\alpha}{2}\left(1 + \frac{e^{-2y}}{1 - e^{-2y}}\right)e^{R/2}
	\int_{(1-\delta)(R- y)}^{R - y} \frac{ \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
	e^{-\alpha y^\prime} \dd y^\prime.
\]
Since for all $1 \le x < 2$,
\[
	\frac{1}{\sqrt{1- (1-x)^2}} \le \frac{2}{\sqrt{2(2-x)}},
\]
and $1 \le \Xi(y,y^\prime) \le 2$, for all $(1-\delta)(R -y) \le y\prime < R-y$ and $y < R$, it follows that
\begin{align*}
	&\hspace{-30pt}\int_{(1-\delta)(R- y)}^{R - y} \frac{ \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
		e^{-\alpha y^\prime} \dd y^\prime \\
	&\le 2 \int_{(1-\delta)(R- y)}^{R - y} \frac{\Xi(y,y^\prime)}{\sqrt{2(2-\Xi(y,y^\prime))}} e^{-\alpha y^\prime} 
		\dd y^\prime \\
	&\le 2 e^{-\alpha(R - y)} \int_{(1-\delta)(R- y)}^{R - y} 
		\frac{e^{-(R - y - y^\prime)}}{\sqrt{1 - e^{-(R - y - y^\prime)}}} e^{\alpha (R - y - y^\prime)} \dd y^\prime.
\end{align*}
Making the change of variables $z = e^{-(R - y - y^\prime)}$ ($\dd y^\prime = z^{-1} \dd z$) we get that
\begin{align*}
	2 e^{-\alpha(R - y)} \int_{(1-\delta)(R- y)}^{R - y} 
			\frac{e^{-(R - y - y^\prime)}}{\sqrt{1 - e^{-(R - y - y^\prime)}}} e^{\alpha (R - y - y^\prime)} \dd y^\prime
	&= 2 e^{-\alpha(R - y)} \int_{e^{-\delta (R - y)}}^{1} \frac{z^{-\alpha}}{\sqrt{1 - z}} \dd z\\
	&\le 2 e^{-\alpha(R - y)} \sqrt{1 - e^{-\delta (R - y)}}\\
	&\le 2 e^{-\alpha (R -y)}.
\end{align*}
We therefore conclude that
\[
	I_3(y) \le \alpha \left(1 + \frac{e^{-2y}}{1 - e^{-2y}}\right)e^{-(\alpha -\frac{1}{2})R + \alpha y}.
\]
which implies
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} I_3(y) 
	\le \lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \alpha \left(1 + \frac{e^{-2y}}{1 - e^{-2y}}\right) e^{-(\alpha - \frac{1}{2})(R - y)} = 0.
\]

Finally, to show~\eqref{eq:derivative_hyp_ball_main_part} we define 
\begin{align*}
	\varphi^-_n &:= \sup_{0 < y \le (1-\varepsilon)R_n} \, \inf_{0 \le y^\prime \le (1 - \delta)(R-y)} 
		\varphi_n(y,y^\prime)\\
	\varphi^+_n &:= \sup_{0 < y \le (1-\varepsilon)R_n} \, \sup_{0 \le y^\prime \le (1 - \delta)(R-y)} \varphi_n(y,y^\prime)
\end{align*}
and note that since for $0 \le y^\prime \le (1-\delta)(R-y)$,
\[
	\frac{e^{-(R + y)}}{1 - e^{-(R+y)}} - \frac{e^{-(R- y)}}{1 - e^{-(R-y)}} - \frac{2e^{-2(R-y)}}{1 - e^{-2(R-y)}}
	\le \varphi_n(y,y^\prime) \le \frac{e^{-\delta(R-y)}}{1 - e^{-\delta(R-y)}}.
\] 
we get $\lim_{n \to \infty} \varphi^\pm_n = 0$. Next, recall that $\Phi(y,y^\prime) = \frac{1}{2}e^{R/2}\Xi(y,y^\prime)$. Then, since $\Xi(y,y^\prime) < 2$ for all $y^\prime < (1-\delta)(R-y)$ and $y < R$, there exists a $K > 0$ such that (see Lemma~\ref{lem:arccos_approx}),
\[
	\frac{1}{2}\Phi(y,y^\prime)\left(1 - \frac{(1+\sqrt{2})\Xi(y,y^\prime)}{1 + \Xi(y,y^\prime)}\right)
	\le \frac{\frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}} 
	\le \frac{1}{2}\Phi(y,y^\prime)\left(1 + \frac{(1+K)\Xi(y,y^\prime)}{1 - \Xi(y,y^\prime)}\right)
\]
for all $y^\prime < (1-\delta)(R - y)$ and $y < R$. Using that $e^{-(r-y)} \le e^{-(R - y - y^\prime)} \le e^{-\delta(R- y)}$, for $0 < y^\prime < (1-\delta)(R-y)$, we get
\[
	1 - \frac{(1+\sqrt{2})\Xi(y,y^\prime)}{1 + \Xi(y,y^\prime)} \ge 1 - 2(1+\sqrt{2})e^{-(R-y)}
\]
and
\[
	1 + \frac{(1+K)\Xi(y,y^\prime)}{1 - \Xi(y,y^\prime)} 
	\le 1 + \frac{2(1 + K)e^{-\delta(R - y)}}{1-e^{-\delta(R-y)}}.
\]

We thus have the following upper and lower bound for $I_2(y)$
\begin{align*}
	I_2(y) \le \frac{1}{2} \left(1 + \phi_n^+\right)
	\left(1 + \frac{2(1 + K)e^{-\delta(R - y)}}{1-e^{-\delta(R-y)}}\right)
	\int_{0}^{(1-\delta)(R-y)} \Phi(y,y^\prime) \alpha e^{-\alpha y^\prime} \dd y^\prime,
\end{align*}
and
\[
	I_2(y) \ge \frac{1}{2} \left(1 + \phi_n^-\right)\left(1 - 2(1+\sqrt{2})e^{-(R-y)}\right)
	\int_{0}^{(1-\delta)(R-y)} \Phi(y,y^\prime) \alpha e^{-\alpha y^\prime} \dd y^\prime.
\]
From this~\eqref{eq:derivative_hyp_ball_main_part} follows since, $\lim_{n \to \infty} \varphi_n^\pm = 0$ and by Lemma~\ref{lem:hyperbolic_ball_lower_part},
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R_n} \Mu{\BallPo{y}}^{-1} \frac{2\nu \alpha}{\pi} 
	\int_{0}^{(1-\delta)(R-y)} \Phi(y,y^\prime) \alpha e^{-\alpha y^\prime} \dd y^\prime
	= 1.
\] 
\end{proof}

We now conclude that similar to Corollary~\ref{cor:concentration_of_heights_Gbox}, the concentration of heights results also hold for $\rho_{\Po}(y,k_n)$.

\begin{corollary}\label{cor:concentration_of_heights_GPo}
The statement in Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n}
and~\ref{cor:concentration_heights_asymptotics_n} hold when we replace $\rho(y,k_n)$ with $\rho_{\Po}(y,k_n)$.
\end{corollary}

