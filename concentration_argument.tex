\section{Concentration of heights for vertices with degree $k$}\label{sec:concentration_argument}

Here we show that if we integrate with respect to the function $\hat{\rho}_n(y,k_n) = \Prob{\Po(\mu_n(y)) = k_n}$ then we may restrict integration with respect to the \emph{height} $y$ to an interval on which $\mu_n(y) = \bigT{k_n}$. We will refer to such a result as a \emph{concentration of heights} result. In addition, if $\mu_n(y)$ is equivalent to $\mu(y)$ on this interval, then we may replace $\hat{\rho}_n(y,k_n)$ in the integral with $\rho(y,k_n) = \Prob{\Po(\mu(y)) = k_n}$ (the degree distribution of the typical point in $\Ginf$). 

We start with a concentration of heights result for the infinite model $\Ginf$ (Lemma~\ref{lem:concentration_argument}) and explain in Remark~\ref{rmk:concentration_argument} how such a result will be used throughout the paper. We then present a generalization of this result (Lemma~\ref{lem:concentration_argument}) and use this to establish concentration of heights results for the Poissonized KPKVB $\GPo$ and finite box model $\Gbox$. 

Finally we provide a general result that allow to substitute $\hat{\rho}_n(y,k_n)$ in the integrand with $\rho(y,k_n)$ and show that this holds in particular for the degree distributions in $\GPo$ and $\Gbox$, given by, respectively $\rho_{\Po}(y,k_n) := \Prob{\Po(\Mu{\BallHyp{y}}) = k_n}$ and $\rho_{\text{box}}(y,k_n) := \Prob{\Po(\Mu{\BallPon{y}}) = k_n}$.

\subsection{Concentration of heights argument for the infinite model}

The next lemma states that for a large class of functions $h(y)$ and $k_n \to \infty$, to compute the integral 
\[
	\int_{0}^\infty \rho(y,k_n) h(y) e^{-\alpha y} \dd y
\]
it is enough to consider integration over a small interval on which $e^{y/2} \approx k_n$, instead of $\R_+$. 

\begin{lemma}\label{lem:concentration_argument}
Let $\alpha > \frac{1}{2}$, $\nu > 0$, $(k_n)_{n \ge 1}$ be any positive sequence such that $k_n \to \infty$ and $k_n = \smallO{n}$ and let $\ell_n = k_n(1 + \epsilon_n)$, with $\epsilon_n \to 0$. In addition, define for any constant $C > 0$,
\[
	\lambda_n^\pm = (\ell_n \pm C \sqrt{\ell_n \log(\ell_n)}) \wedge \xi, 
	\quad a_n^\pm = 2 \log\left(\frac{\lambda_n^\pm}{\xi}\right).
\] 
Then the following holds.
\begin{enumerate}
\item For any continuous function $h : \R_+ \rightarrow  \R$, such that $h(y) = \bigO{e^{\beta y}}$ as $y \to \infty$ for some $\beta < \alpha$, 
\begin{equation}\label{eq:error_bound_int_rho_not_K}
	\int_{\R_+ \setminus (a_n^-, a_n^+)} \rho(y,k_n) h(y) \alpha e^{-\alpha y} \dd y
	= \bigO{k_n^{-(1+C^2)/2}},
\end{equation}
as $n \to \infty$.
\item If in addition $C > \sqrt{4\alpha + 1}$ and $h(a_n) \sim h(b_n)$ whenever $a_n \sim b_n$, as $n \to \infty$. Then, 
\begin{equation}\label{eq:concentration_h_rho}
	\int_0^\infty h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y \sim  
		2\alpha \xi^{2\alpha} h(2\log(k_n/\xi)) k_n^{-(2\alpha + 1)},
\end{equation}
as $n \to \infty$.
\end{enumerate}
\end{lemma}

\begin{proof}\hfill

\paragraph{Proof of the first statement.}
Recall (see proof of Proposition~\ref{prop:asymp}) that $\rho(y,k_n)$, as a function of $y$, is strictly increasing on $[0,a_n^-]$ and strictly decreasing on $[a_n^+,\infty)$. Therefore, by our assumption on $h(y)$,
\begin{align*}
	&\hspace{-20pt}\int_{\R_+ \setminus (a_n^-, a_n^+)} h(y) \rho(y,k_n) 
		\alpha e^{-\alpha y} \dd y\\
    &= \bigO{1} \int_0^{a_n^-} e^{\beta y} \rho(y,k_n) \alpha e^{-\alpha y} \dd y 
    	+ \bigO{1}\int_{a_n^+}^{\infty} e^{\beta y} \rho(y,k_n) \alpha e^{-\alpha y} \dd y \\
    &= \bigO{1} \int_0^{a_n^-} \rho(y,k_n) e^{-(\alpha-\beta) y} \dd y 
   		+ \bigO{1} \int_{a_n^+}^{\infty} \rho(y,k_n) e^{-(\alpha-\beta) y} \dd y\\
   	&\le \bigO{1}\rho(a_n^-,k_n)\int_0^{a_n^-} e^{-(\alpha-\beta) y} \, \dd y
   		+ \bigO{1} \rho(a_n^+,k_n) \int_{a_n^+}^{\infty} e^{-(\alpha-\beta) y} \, \dd y.
\end{align*}
Since $\alpha - \beta > 0$, we conclude that
\begin{equation}\label{eq:concentration_lemma_integral_bound}
	\int_{\R_+ \setminus (a_n^-, a_n^+)} h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \bigO{1} \left(\rho(a_n^-,k_n) + \rho(a_n^+,k_n)\right).
\end{equation}

We shall now bound the terms $\rho(a_n^\pm,k_n)$. We explicitly show the bound for $\rho(a_n^+,k_n)$, the computation for $\rho(a_n^-,k_n)$ is similar. Using Stirling's approximation $k! \sim \sqrt{2\pi} k^{k + 1/2} e^{-k}$ as $k \to \infty$ we write
\begin{align*}
	\rho(a_n^+,k_n) &= \frac{\mu(a_n^+)^{k_n}}{k_n!} e^{-\mu(a_n^+)} \\
	&\sim (2\pi)^{-1/2} k_n^{-1/2} \left(\frac{\mu(a_n^+)}{k_n}\right)^{k_n} e^{-(\mu(a_n^+) - k_n)}\\
	&= (2\pi)^{-1/2} k_n^{-1/2} 
		e^{-k_n\left(\frac{\mu(a_n^+)}{k_n} - 1 - \log\left(\frac{\mu(a_n^+)}{k_n}\right)\right)}.
\end{align*}

Since 
\[
	\frac{\mu(a_n^+)}{k_n} = \frac{\lambda_n^{+}}{k_n} = 1 + \epsilon_n + C \frac{\kappa_n}{k_n} 
	= 1 + \epsilon_n + C \sqrt{\frac{(1+\epsilon_n)\log((1+\epsilon_n)k_n)}{k_n}},
\]
and as $x - \log(1 + x) \sim x^2/2$ as $x \to 0$, we get 
\begin{align*}
	\rho(a_n^+,k_n) 
	&\le \sqrt{2\pi} k_n^{-1/2} 
		e^{-k_n\left(\epsilon_n + C \frac{\kappa_n}{k_n} - \log\left(1 + \epsilon_n + C \frac{\kappa_n}{k_n}\right)\right)}\\
	&\sim (2\pi)^{-1/2} k_n^{-1/2} e^{-\frac{k_n \left(\epsilon_n + C \kappa_n/k_n\right)^2}{2}} \\
	&= \bigO{k_n^{-(1+C^2)/2}},		\numberthis \label{eq:concentration_lemma_bound_an+}
\end{align*}
where for the last line we used that
\[
	-k_n \frac{\left(\epsilon_n + C \kappa_n/k_n\right)^2}{2} = -\frac{C^2}{2}\log(k_n) + \bigT{1}.
\]
A similar analysis as above yields
\begin{equation}\label{eq:concentration_lemma_bound_an-}
	\rho(a_n^-,k_n) \le \bigT{1} k_n^{-1/2} e^{-\frac{k_n \left(\epsilon_n - C \kappa_n/k_n\right)^2}{2}} = \bigO{k_n^{-(1+C^2)/2}}.
\end{equation} 
Plugging~\eqref{eq:concentration_lemma_bound_an-} and~\eqref{eq:concentration_lemma_bound_an+}  into~\eqref{eq:concentration_lemma_integral_bound} yields the result. 

\paragraph{Proof of the second statement.} By the mean value theorem for definite integrals, there exists a $c_n \in (a_n^-, a_n^+)$ such that
\[
	\int_{a_n^-}^{a_n^+} h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= h(c_n) \int_{a_n^+}^{a_n^+} \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
Since $\int_0^\infty \rho(y,k_n) \alpha e^{-\alpha y} \dd y = \bigT{k_n^{-(2\alpha + 1)}}$, taking any $C > \sqrt{4\alpha + 1}$, \eqref{eq:error_bound_int_rho_not_K} implies that
\[
	\int_{a_n^+}^{a_n^+} \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= (1 + \smallO{1})\int_0^\infty \rho(y,k_n) \alpha e^{-\alpha y} \dd y,
\]
from which we conclude that (see~\eqref{eq:degree_distribution_P_asymptotics}),
\[
	\int_{a_n^+}^{a_n^+} \rho(y,k_n) \alpha e^{-\alpha y} \dd y = (1 + \smallO{1}) 2\alpha \xi^{2\alpha} k_n^{-(2\alpha + 1)},
\]
as $n \to \infty$. Finally, since $c_n \in (a_n^-, a_n^+)$ it follows that
\[
	\left|\frac{c_n}{2\log(k_n/\xi)} - 1\right| \le 2 C \sqrt{\frac{\log(k_n)}{k_n}}, 
\]
so that $c_n \sim 2\log(k_n/\xi)$. Therefore, by assumption on $h$ 
\[
	\int_{a_n^-}^{a_n^+} h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	\sim h(c_n) 2\alpha \xi^{2\alpha} k_n^{-(2\alpha + 1)} 
	\sim 2\alpha \xi^{2\alpha} h(2\log(k_n/\xi)) k_n^{-(2\alpha + 1),}
\]
as $n \to \infty$.
\end{proof}

Note that we can tune the error in~\eqref{eq:error_bound_int_rho_not_K} by selecting an appropriately large $C > 0$, i.e. by restricting the function $h(y)$ inside the integral to an appropriate interval around $2\log(k_n/\xi)$. This makes Lemma~\ref{lem:concentration_argument} very powerful. Below we list several important corollaries. 

\begin{corollary}\label{cor:concentration_of_heights_asymptotics}
Let $h : \R_+ \to \R$ be any continuous function such that for some $\beta < \alpha$, $h(y) = \bigO{e^{\beta y}}$ as $y \to \infty$ and $h(a_n) \sim h(b_n)$ whenever $a_n \sim b_n$. Then for any other continuous function $g: \R_+ \to \R$, such that $g(y) \sim h(y)$ as $y \to \infty$
\begin{equation}\label{eq:concentration_h_sim_rho}
	\int_0^\infty g(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y \sim  
		2\alpha \xi^{2\alpha} h(2\log(k_n/\xi)) k_n^{-(2\alpha + 1)},
\end{equation}
as $n \to \infty$.
\end{corollary}

\begin{proof}
By assumption, $g$ satisfies the conditions of the second statement of Lemma~\ref{lem:concentration_argument}. Since in addition $g(2\log(k_n/\xi)) \sim h(2\log(k_n/\xi))$, the result follows.
\end{proof}


For any $C > 0$ we define
\begin{equation}\label{eq:def_K_C_set}
	\Kcal_C(k_n) = \left\{y \in \R_+ : \frac{k_n - C \sqrt{a_n \log(k_n)}}{\xi} \vee 1 \le e^{\frac{y}{2}}
	\le \frac{k_n + C \sqrt{k_n \log(k_n)}}{\xi} \right\}.
\end{equation}
%In addition we define
%\begin{equation}\label{eq:def_K_C_n_set}
%	\Kcal_{C,n}(a_n) := (-I_n, I_n] \times ((0,R] \cap \Kcal_{C}(a_n)),
%\end{equation}
%where $I_n := \frac{\pi}{2}e^{R/2}$. Recall that $\Rcal = (-I_n, I_n] \times [0,R]$. 
The following corollary allows us to bound integrals of functions $h_n(y)$ by considering their maximum of $\Kcal_{C}(k_n)$.

\begin{corollary}\label{cor:concentration_heights_bounds_n}
Let $h_n : \R_+ \to \R_+$ be a sequence of continuous functions which such that for some $s \in \R$ and $\beta < \alpha$, as $n \to \infty$, $h_n(y) = \bigO{k_n^{s} e^{\beta y}}$ and $h_n(y) = \Omega(1)$, uniformly on $0 \le y \le R$. Then, as $n \to \infty$,
\[
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y 
	= (1 + \smallO{1}) \, n \int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
In particular,
\[
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y = \bigO{1} n \, k_n^{-(2\alpha + 1)} \max_{y \in \Kcal_{C}(k_n)} h_n(y),
\]
as $n \to \infty$.
\end{corollary}

\begin{proof}
The second result follows immediately from the first. For the first result we note that by the first statement of Lemma~\ref{lem:concentration_argument}
\begin{align*}
	\int_{[0,R] \setminus (a_n^-, a_n^+)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	&\le \bigO{k_n^s} \int_{\R_+ \setminus (a_n^-, a_n^+)} e^{\beta y } \rho(y,k_n) \alpha e^{-\alpha y} \dd y\\
	&= \bigO{k_n^{s - (1+C^2)/2}}.
\end{align*}
By assumption on $h_n(y)$,
\[
	\int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y 
	= \bigO{k_n^{s+2\beta}} \int_{\Kcal_{C}(k_n)} \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \bigO{k_n^{s+2\beta - (2\alpha + 1)}},
\]
and
\[
	\int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y 
	= \Omega(1) \int_{\Kcal_{C}(k_n)} \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \Omega(k_n^{-(2\alpha + 1)}).
\]
Hence, by taking $C > 0$ such that $(1+C^2)/2 > \max\{2\alpha + 1 + s, 2\alpha +1 - \beta\}$ we get that
\[
	\int_{[0,R] \setminus (a_n^-, a_n^+)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y
	= \smallO{1} \int_{\Kcal_{C}(k_n)} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
The result then follows since
\[
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y
	= n \int_{0}^{R} h_n(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y.
\]
\end{proof}

For functions $h_n(y) = k_n^s h(y)$ we obtain an asymptotic equivalent expression for the associated integral.

\begin{corollary}\label{cor:concentration_heights_asymptotics_n}
Let $h : \R_+ \to \R$ be a continuous function which  satisfies the conditions of Lemma~\ref{lem:concentration_argument} and let $h_n$ be a sequence of functions such that, as $n \to \infty$, $h_n(y) = \Omega(1)$ and $h_n(y) = \bigO{k_n^{s}} h(y)\rho(y,k_n)$, uniformly on $0 \le y \le R$. Then,
\begin{equation}
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y 
	\sim 2\alpha \xi^{2\alpha} \, n \, h_n(2\log(k_n/\xi)) k_n^{-(2\alpha + 1)},
\end{equation}
as $n \to \infty$.
\end{corollary}

\begin{proof}
The result immediately follows by first applying Corollary~\ref{cor:concentration_heights_bounds_n} and then using the second statement from Lemma~\ref{lem:concentration_argument}.
\end{proof}

\begin{remark}[Concentration of heights argument]\label{rmk:concentration_argument}
%\TM{ again, this is a loaded term. I would in the very least change to ``concentration of height'' everywhere }
All the above corollaries use the same reasoning, namely that when the integrand contains $h_n(y) \rho(y,k_n)$, for some "nice" functions $h_n(y)$, then the main contribution is determined by the integration over $\Kcal_{C}(k_n)$.  This implies, for instance, that we only need to carefully analyze the functions $h_n(y)$ on $\Kcal_{C}(y)$, while for a certain class of functions we can even simply replace it with $h_n(2\log(k_n/\xi))$. We will refer collectively to any of these arguments as a \emph{concentration of heights argument}. For example, suppose we know that $h_n(y) = \Omega(1)$ and we can obtain some general crude bound $h_n(y) = \bigO{k_n^s} e^{\alpha/2 y}$ for some $s > 0$ for $y \in \R_+$. Then, if we can obtain a more precise bound $h_n(y) = (1 + \smallO{1}) k_n^2 e^{\alpha/2 y}$ uniformly on $\Kcal_{C}(k_n)$, by a concentration of heights argument (in this case Corollary~\ref{cor:concentration_heights_asymptotics_n})
\begin{align*}
	\int_{\Rcal} h_n(y) \rho(y,k_n) f(x,y) \dd x \dd y 
	&= (1 + \smallO{1}) 2 \alpha \xi^{2\alpha} \, n \, k_n^2 (k_n/\xi)^{\alpha/2} k_n^{-(2\alpha + 1)} \\
	&= (1 + \smallO{1}) 2\alpha \xi^{5\alpha/2} \, n \, k_n^{1 + 5\alpha/2}.
\end{align*}
\end{remark}



\begin{remark}[Proof of Proposition~\ref{prop:asymp} revisited]
Note that due to Proposition~\ref{prop:asymptotics_P}, the function $P(y)$ from Section~\ref{sec:asymptotics_average_clustering_ast_P} satisfies all the necessary conditions in Corollary~\ref{cor:concentration_of_heights_asymptotics} with
\[
	h(y) := \begin{cases}
		e^{-\frac{y}{2}(4\alpha - 2)} c_\alpha \xi^{4\alpha - 2} &\mbox{if } \frac{1}{2} < \alpha < \frac{3}{4},\\
		\frac{y}{2} e^{-\frac{y}{2}} &\mbox{if } \alpha = \frac{3}{4},\\
		e^{-\frac{y}{2}} \frac{\alpha - \frac{1}{2}}{\alpha - \frac{3}{4}} &\mbox{if } \alpha > \frac{3}{4}.
	\end{cases}
\] 
Hence, Proposition~\ref{prop:asymp} directly follows from Proposition~\ref{prop:asymptotics_P} and a concentration of heights argument (Corollary~\ref{cor:concentration_of_heights_asymptotics}).
\end{remark}


%
%
%The next proposition establishes this result and we will spend the rest of this section on its proof.
%
%\begin{proposition}\label{prop:concentration_argument_all}
%The conclusions from Lemmas~\ref{lem:concentration_argument} and Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n} and~\ref{cor:concentration_heights_asymptotics_n} still hold if we replace $\rho(y,k_n)$ with either $\rho_{\Po}(y,k_n)$ or $\rho_{\text{box}}(y,k_n)$.
%\end{proposition}

\subsection{A more general concentration of heights argument}\label{ssec:general_concentration_lemma}

Although powerful, the current versions of the concentration of heights arguments are only valid for the function $\rho(y,k_n) := \Prob{\Po\left(\Mu{\BallPo{y}}\right) = k_n}$, which uses the neighbourhoods in the infinite model $\Ginf$. 
Since we will also be working in the Poissonized KPKVB model $\GPo$ and the finite box model $\Gbox$, we would like to use concentration of heights arguments for the degree distribution function in these models. To be more precise, let us define
\[
	\rho_{\Po}(y,k) = \Prob{\Po(\mu(\BallHyp{y})) = k}
\] 
and
\[
	\rho_{\mathrm{box}}(y,k) = \Prob{\Po(\mu(\BallPon{y})) = k}
\] 
Then we want when Lemma~\ref{lem:concentration_argument} to remain true if we replace $\rho(y,k_n)$ with either the function $\rho_{\Po}(y,k_n)$ or $\rho_{\text{box}}(y,k_n)$. To establish these result we first prove a more general version of Lemma~\ref{lem:concentration_argument}.

\begin{lemma}\label{lem:concentration_argument_rho_approximation}
Let $\alpha > \frac{1}{2}, \nu > 0$ and $0 < \varepsilon < 1$. Furthermore, let $k_n \to \infty$ such that $k_n = \bigO{n^{1-\varepsilon}}$, $\ell_n = (1 + \epsilon_n)k_n$, with $\epsilon_n \to 0$ and define
\[
	\lambda_n^\pm = (\ell_n \pm C \sqrt{\ell_n \log(\ell_n)}) \wedge \xi, \quad \text{and} \quad a_n^\pm = 2 \log\left(\frac{\lambda_n^\pm}{\xi}\right),
\] 
for some $C > 0$. Finally, let $\hat{\rho}_n(y,k) = \Prob{\Po(\hat{\mu}_n(y)) = k}$, where $\hat{\mu}_n(y)$ is a differentiable function that satisfies for some $0 < \varepsilon^\prime < 1$
\begin{align*}
	&\mathrm{i)} \, \lim_{n \to \infty} \sup_{0 \le y \le (1 - \varepsilon^\prime)R} 
		\left|\frac{\hat{\mu}_n(y)}{\mu(\BallPo{y})} - 1\right| = 0
	\quad \text{and}
	&&\mathrm{ii)} \, \lim_{n \to \infty}  \sup_{0 \le y \le (1 - \varepsilon^\prime)R} 	
		\left|\frac{\hat{\mu}_n^\prime(y)}{\mu(\BallPo{y})} - \frac{1}{2}\right| = 0.
\end{align*}
Then the following holds for $C > 0$ large enough:
\begin{enumerate}
\item For any continuous function $h : \R_+ \rightarrow  \R$, such that $h(y) = \bigO{e^{\beta y}}$ as $y \to \infty$ for some $\beta < \alpha$, 
\begin{equation}\label{eq:error_bound_int_rho_approx_not_K}
	\int_{\R_+ \setminus (a_n^-, a_n^+)} \hat{\rho}_n(y,k_n) h(y) \alpha e^{-\alpha y} \dd y
	= \bigO{k_n^{-(1+C^2)/2}},
\end{equation}
as $n \to \infty$.
\item If in addition, $h(a_n) \sim h(b_n)$ whenever $a_n \sim b_n$, as $n \to \infty$, then,
\begin{equation}\label{eq:concentration_h_rho_approx}
	\int_0^\infty h(y) \hat{\rho}_n(y,k_n) \alpha e^{-\alpha y} \dd y \sim  
		\int_0^\infty h(y) \rho(y,k_n) \alpha e^{-\alpha y} \dd y,
\end{equation}
as $n \to \infty$.
\end{enumerate}
\end{lemma}

\begin{proof} \hfill

For simplicity we write $\mu(y) := \mu\left(\BallPo{y}\right) = \xi e^{y/2}$ throughout the proof. Observe that $\mu^\prime(y) = \mu(y)/2$ and $\mu^{-1}(y z) = \mu^{-1}(y) + \mu^{-1}(z)$.


\paragraph{Proof of statement 1.}

Let $0 < \varepsilon < 1$ be such that conditions i) and ii) hold, 
Take any $0 < \delta < \min\{\varepsilon, \varepsilon^\prime/3,1/3\} < 1/2$ and let $Q > 0$ be such that $\hat{\mu}_n(Q) \ge \xi$. We first show that we can restrict to integration over $(Q, (1-\delta)R)$, starting with showing that the integration over $(1-\delta)R \le y \le R$ is negligible.

By construction $\delta < \varepsilon^\prime$, and hence by condition i) we have that $\hat{\mu}_n((1-\delta)R) = \bigT{\mu((1-\delta)R} = \bigT{n^{(1-\delta)}}$. Therefore, since $\delta<\varepsilon$ and $k_n = \bigO{n^{1-\varepsilon}}$, it follows that $\hat{\mu}_n((1-\delta)R)/k_n = \omega\left(n^{\varepsilon - \delta}\right)$ as $n \to \infty$. In particular $\hat{\mu}((1-\delta)R) = \omega{k_n}$ and hence $\hat{\rho}_n(y,k_n) \le \hat{\rho}((1-\delta)R,k_n)$ for all $y \ge (1-\delta)R$. It now follow that
\begin{align*}
	\int_{(1-\delta)R}^{R} h(y) \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
	&= \bigO{1} \hat{\rho}_n((1-\delta)R,k_n) e^{-(\alpha-\beta)(1-\delta)R} \\
	&= \bigO{\hat{\rho}_n((1-\delta)R,k_n) n^{-2(\alpha-\beta)(1-\delta)}},
\end{align*}
where we used that that $h(y) = \bigO{e^{\beta y}}$.
Using Stirling's approximation to bound $\hat{\rho}_n((1-\delta)R,k_n)$ we get
\begin{align*}
	\hat{\rho}_n((1-\delta)R,k_n) &= \Prob{\Po(\hat{\mu}_n((1-\delta)R)) = k_n} \\
	&= \frac{\hat{\mu}_n((1-\delta)R)^{k_n}}{k_n!} e^{-\hat{\mu}_n((1-\delta)R)}\\
	&= \bigO{1} k_n^{-1/2} \left(\frac{\hat{\mu}_n((1-\delta)R)}{k_n}\right)^{k_n} e^{k_n - \hat{\mu}_n((1-\delta)R)}\\
	&= \bigO{1} k_n^{-1/2} e^{k_n\left(1 - \frac{\hat{\mu}_n((1-\delta)R)}{k_n}+ \log\left(\frac{\hat{\mu}_n((1-\delta)R)}{k_n}\right)\right)}\\
	&\le \bigO{1} k_n^{-1/2} e^{-\hat{\mu}_n((1-\delta)R)/2},
\end{align*}
where the last line follows since $1 - x + \log(x) \le -x/2$ for large enough $x$ and $\hat{\mu}_n((1-\delta)R)/k_n \to \infty$. We thus conclude that for any $C > 0$
\[
	\int_{(1-\delta)R}^{R} h(y) \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
	= \bigO{k_n^{-1/2} n^{-2(\beta-\alpha)(1-\delta)} e^{-n^{(1-\delta)}}}
	= \bigO{k_n^{-(1+C^2)/2}}.
\]

For the range $(0,Q)$ we have, for any $C > 0$,
\begin{align*}
	\int_0^Q h(y) \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
	&= \bigO{1} \hat{\rho}_n(Q, k_n) \\
	&= \bigO{1} k_n^{-1/2} e^{-k_n(\log(k_n)-\hat{\mu}_n(Q))} = \bigO{k_n^{-(1+C^2)/2}}.
\end{align*}

We are thus left to show that for sufficiently large $C > 0$,
\begin{equation}\label{eq:concentration_argument_an_-}
	 \int_\delta^{a_n^-} \hat{\rho}_n(y,k_n) e^{(\beta-\alpha) y} \dd y = \bigO{k_n^{-(1+C^2)/2}},
\end{equation}
and
\begin{equation}\label{eq:concentration_argument_an_+}
	\int_{a_n^+}^{(1-\varepsilon^\prime)R} \hat{\rho}_n(y,k_n) e^{(\beta-\alpha) y} \dd y = \bigO{k_n^{-(1+C^2)/2}}.
\end{equation}
To prove this we first establish a result that will also help with proving statement 2. 

Let $(a, b) \subseteq (Q,(1-\delta)R)$ and consider the change of variable $z = \mu^{-1}(\hat{\mu}_n(y))$. Then, writing $\hat{a} = \hat{\mu}_n^{-1}(\mu(a))$ and similar for $\hat{b}$, we get
\begin{align*}
	\int_{a}^{b} \rho(z,k_n) e^{-\alpha z} \dd z 
	&= \int_{a}^{b} \Prob{\Po(\mu(z)) = k_n} e^{-\alpha z} \dd z\\
	&= \int_{\hat{a}}^{\hat{b}} \Prob{\Po(\hat{\mu}_n(y)) = k_n} e^{-\alpha \mu^{-1}(\hat{\mu}_n(y))} 
		\frac{\hat{\mu}_n^\prime(y)}{\mu^\prime(\mu^{-1}(\hat{\mu}_n(y)))} \dd y,
\end{align*}
where the fraction in the last line follows from the chain rule and the fact that $(\mu^{-1})^\prime(t) = (\mu^\prime(\mu^{-1}(t)))^{-1}$.

Now recall that $\hat{\mu}_n(y)$ satisfies conditions i) and ii). Since $\mu^\prime(y) = \mu(y)/2$ it follows that, uniformly on $(a,b)$,
\[
	\frac{\hat{\mu}_n^\prime(y)}{\mu^\prime(\mu^{-1}(\hat{\mu}_n(y)))}
	= \frac{2\hat{\mu}_n^\prime(y)}{\hat{\mu}_n(y)}
	= \frac{(1 + \smallO{1})2\hat{\mu}_n^\prime(y)}{(1 + \smallO{1})\mu(y)}
	= (1+\smallO{1}).
\]
Moreover, we have
\[
	e^{-\alpha \mu^{-1}(\hat{\mu}_n(y))} = e^{-\alpha (y + \mu^{-1}(1+\smallO{1}))} = (1+\smallO{1})e^{-\alpha y},
\]
uniformly on $(a,b)$. These results then imply
\begin{equation}\label{eq:equivalence_integral_rho_change_variables}
	\int_{a}^{b} \rho(z,k_n) e^{-\alpha z} \dd z 
	= (1+\smallO{1}) \int_{\hat{a}}^{\hat{b}} \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y.
\end{equation}

Now, using~\eqref{eq:equivalence_integral_rho_change_variables} with $a = \mu^{-1}(\hat{\mu}_n(Q))$ and $b = \mu^{-1}(\hat{\mu}_n(a_n^-)$ we get
\begin{align*}
	\int_a^b \rho(y,k_n) e^{(\beta-\alpha) y} \dd y
	&= (1+\smallO{1}) \int_{Q}^{a_n^-} \hat{\rho}_n(y,k_n) e^{(\beta - \alpha)y} \dd y.
\end{align*}
Since $\mu^{-1}(\hat{\mu}_n(a_n^-) = (1+\smallO{1})a_n^-$ and $b \ge 0$ the left hand side is
\[
	\bigO{1} \int_0^{a_n^-} \rho(y,k_n) e^{(\beta-\alpha) y} \dd y,
\]
and hence~\eqref{eq:concentration_argument_an_-} follows from Lemma~\ref{lem:concentration_argument}. The proof of~\eqref{eq:concentration_argument_an_+} follows in a similar way.

\paragraph{Proof of statement 2.}

The proof of the second statement follows the same line of reasoning as above, using~\eqref{eq:equivalence_integral_rho_change_variables}. First, the mean value theorem for definite integrals implies that
\[
	\int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) h(y) e^{-\alpha y} \dd y
	= h(c_n) \int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y,
\]
for some $c_n \in (a_n^-, a_n^+)$. Since $c_n \sim 2 \log(k_n/\xi)$, $h(c_n)\sim h(2\log(k_n/\xi))$ by assumption on $h$. 
Therefore it is enough to show that
\[
	\int_{a_n^-}^{a_n^+} \hat{\rho}_n(y,k_n) e^{-\alpha y} \dd y
	= \left(1 + o(1)\right) \int_{a_n^-}^{a_n^+} \rho(z,k_n) e^{-\alpha z} \dd z.
\] 
This however follows immediately from~\eqref{eq:equivalence_integral_rho_change_variables} by picking $a = \mu^{-1}(\hat{\mu}_n(a_n^-))$ and $b = \mu^{-1}(\hat{\mu}_n(a_n^+))$.
\end{proof}

To apply this lemma to $\rho_{\Po}(y,k_n)$ or $\rho_{\text{box}}(y,k_n)$ we need to show that both these functions satisfies the conditions i) and ii) in Lemma~\ref{lem:concentration_argument_rho_approximation}. We will do this in the next two sections and establish that the results from Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n}
and~\ref{cor:concentration_heights_asymptotics_n} hold when we replace $\rho(y,k_n)$ with either $\rho_{\text{box}}(y,k_n)$
or $\rho_{\Po}(y,k_n)$. 



\subsection{Concentration of heights for the finite box model}\label{ssec:average_degree_P_n}

The following lemma immediately implies that $\Mu{\BallPon{y}}$ satisfies the conditions of Lemma~\ref{lem:concentration_argument_rho_approximation}.

\begin{lemma}\label{lem:average_degree_P_n}
For all $y > 2\log(\pi/2)$,
\[
	\Mu{\BallPon{p}} = \Mu{\BallPo{p}}\left(1 - \phi_n(y)\right)
\]
%\TM{ where did the curly B's go? }\PvdH{Typo. Fixed}
where $\phi_n(y) \ge 0$ is given by
\[
	\phi_n(y) = \left(\frac{\pi}{2}\right)^{-(2\alpha - 1)}e^{-(\alpha-\frac{1}{2})(R - y)}
	- \frac{(2\alpha - 1)\pi}{4\alpha}\left(\left(\frac{\pi}{2}\right)^{-2\alpha} 
	e^{-(\alpha - \frac{1}{2})(R - y)} - e^{-(\alpha - \frac{1}{2})R - \frac{y}{2}}\right).
\]
On the other hand, if $y \le 2 \log(\pi/2)$ then
\[
	\mu(\BallPon{p}) = \mu(\BallPo{p})\left(1 - e^{-(\alpha - \frac{1}{2})R}\right).
\]
\end{lemma}

\begin{proof}
First note that since we have identified the boundaries of $[-\frac{\pi}{2}e^{\frac{R}{2}}, \frac{\pi}{2}e^{\frac{R}{2}}]$ we can assume, without loss of generality, that $p = (0,y)$. We then have that the boundaries of $\BallPon{p}$ are given by the equations $x^\prime = \pm e^{\frac{y+y^\prime}{2}}$, which intersect the left and right boundaries of $[-\frac{\pi}{2}e^{\frac{R}{2}}, \frac{\pi}{2}e^{\frac{R}{2}}]$ at height
\[
	h(y) = R + 2 \log\left(\frac{\pi}{2}\right) - y.
\]
Therefore, if $y \le 2 \log(\pi/2)$ this intersection occurs above the height $R$ of the box $\Rcal$ while in the other case the full region of the box above $h(y)$ is connected to $p$. 

We will first consider the case where $y > 2 \log(\pi/2)$. Recall that $\mu(\BallPo{p}) = \xi e^{\frac{y}{2}}$ where $\xi = \frac{4\alpha \nu}{(2\alpha - 1)\pi}$. Then, after some simple algebra, we have that
\begin{align*}
	\mu(\BallPon{p})
	&= \int_0^{h(y)} \int_{-\frac{\pi}{2}e^{\frac{R}{2}}}^{\frac{\pi}{2}e^{\frac{R}{2}}} 
		\ind{|x^\prime| \le e^{\frac{y+y^\prime}{2}}} f_{\alpha,\nu}(x^\prime,y^\prime) \, dx^\prime \, dy^\prime\\
	&\hspace{10pt}+ \int_{h(y)}^{R} \int_{-\frac{\pi}{2}e^{\frac{R}{2}}}^{\frac{\pi}{2}e^{\frac{R}{2}}} 
		f_{\alpha,\nu}(x^\prime,y^\prime) \, dx^\prime \, dy^\prime\\
	&= \frac{2 \alpha \nu}{\pi} e^{\frac{y}{2}} \int_0^{h(y)} e^{-(\alpha - \frac{1}{2})y^\prime} \, dy^\prime
		+ \alpha \nu e^{\frac{R}{2}} \int_{h(y)}^{R} e^{-\alpha y^\prime} \, dy^\prime \\
	&= \xi e^{\frac{y}{2}}\left(1 - \left(\frac{\pi}{2}\right)^{-(2\alpha - 1)} 
		e^{-(\alpha - \frac{1}{2})(R - y)}\right)\\
	&\hspace{10pt}+ \nu e^{\frac{R}{2}}\left(\left(\frac{\pi}{2}\right)^{-2\alpha} e^{-\alpha(R - y)} 
		- e^{-\alpha R}\right)\\
	&= \mu(\BallPo{p})\left(1 - \phi_n(y)\right).
\end{align*}
Since, for all $\alpha > \frac{1}{2}$,
\[
	\left(\frac{\pi}{2}\right)^{-(2\alpha - 1)} \ge \frac{(2\alpha - 1)\pi}{4\alpha} \left(\frac{\pi}{2}\right)^{-2\alpha}
\]
it follows that $\phi_n(y) \ge 0$.

When $y \le 2 \log(\pi/2)$ we have
\begin{align*}
	\mu(\BallPon{p})
	&= \int_0^{R} \int_{-\frac{\pi}{2}e^{\frac{R}{2}}}^{\frac{\pi}{2}e^{\frac{R}{2}}} 
		\ind{|x^\prime| \le e^{\frac{y+y^\prime}{2}}} f_{\alpha,\nu}(x^\prime,y^\prime) \, dx^\prime \, dy^\prime\\
	&= \frac{2 \alpha \nu}{\pi} e^{\frac{y}{2}} \int_0^{R} e^{-(\alpha - \frac{1}{2})y^\prime} \, dy^\prime\\
	&= \mu(\BallPo{p})\left(1 - e^{-(\alpha - \frac{1}{2})R}\right).
\end{align*}
\end{proof}



From the definition of $\phi_n(y)$ in Lemma~\ref{lem:average_degree_P_n} it is immediate that $\rho_{\mathrm{box}}(y,k)$ satisfies the conditions for $\hat{\rho}_n(y,k)$ in Lemma~\ref{lem:concentration_argument_rho_approximation}. We thus have the following corollary.

\begin{corollary}\label{cor:concentration_of_heights_Gbox}
The statements in Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n}
and~\ref{cor:concentration_heights_asymptotics_n} hold when we replace $\rho(y,k_n)$ with $\rho_{\text{box}}(y,k_n)$.
\end{corollary}

\subsection{Concentration of heights for the KPKVB model}\label{ssec:average_degree_HP_n}

%\TM{  the term ``average degree" does not fit very well with what goes on in this section. We are considering the expected number of points in a ball, but not yet computing the average degree of the graph. }\PvdH{I agree and have changed the header.}

We will now show that a concentration of heights argument also applies to the KPKVB model. Due to the hyperbolic distance formula, the computations are however more involved than for the finite box model. Recall that under the coupling between the hyperbolic random graph and the finite box model, for two points $p, p^\prime$ with $y + y^\prime < R$, $p^\prime \in \BallHyp{p}$ exactly when $|x-x^\prime|_{\pi e^{R/2}} \le \Phi(y,y^\prime)$. In this setting, the coupling lemma (Lemma~\ref{lem:asymptotics_Omega_hyperbolic}) gives that  
\[
	e^{\frac{1}{2}(y+y^\prime)} - K e^{\frac{3}{2}(y+y^\prime) - R} \leq \Phi(y, y^\prime) 
		\leq  e^{\frac{1}{2}(y+y^\prime)} + K e^{\frac{3}{2}(y+y^\prime) - R},
\]
for some constant $K$. This result enables us to determine the measure of a ball around a given point $p=(0,y)$. Recall that the hyperbolic ball $\BallHyp{p}$ is a subset of $\Rcal$ and not of the hyperbolic disc $\Dcal_{R}$, i.e. the balls $\BallHyp{p}$ ``live" in the finite box and not on the hyperbolic disc. We start with the following preliminary result.

\begin{lemma}\label{lem:hyperbolic_ball_lower_part}
Let $\Phi(y,y^\prime)$ be defined as in~\eqref{eq:def_Omega_hyperbolic}. Then, for any $0 \le \delta < 1$
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \left|\Mu{\BallPo{y}}^{-1} \frac{2\nu \alpha}{\pi} \int_0^{(1-\delta)(R-y)} \Phi(y,y^\prime) e^{-\alpha y^\prime} \dd y^\prime  - 1\right| = 0.
\]
\end{lemma}

\begin{proof}
Recall that $\Mu{\BallPo{0,y}} = \xi e^{y/2}$ where $\xi = \frac{4\alpha\nu}{\pi(2\alpha - 1)}$ and that by Lemma~\ref{lem:asymptotics_Omega_hyperbolic}
\[
	\left|\Phi(y,y^\prime) - e^{\frac{y+y^\prime}{2}}\right| \le K e^{\frac{3}{2}(y+y^\prime) - R},
\]
for all $y + y^\prime < R$. Also,
\[
	\Mu{\BallPo{y}} = \frac{2 \nu \alpha}{\pi}\int_0^\infty e^{\frac{y + y^\prime}{2}} e^{-\alpha y^\prime} \dd y^\prime. 
\]

Therefore we have 
\begin{align*}
	&\left|\Mu{\BallPo{y}}^{-1} \frac{2\nu \alpha}{\pi} \int_0^{(1-\delta)(R-y)} \Phi(y,y^\prime) e^{-\alpha y^\prime} 
		\dd y^\prime  - 1\right|\\
	&= \frac{1}{\Mu{\BallPo{y}}}\left|\frac{2\nu \alpha}{\pi} \int_0^{(1-\delta)(R-y)} \Phi(y,y^\prime) 
		e^{-\alpha y^\prime} \dd y^\prime 
		- \frac{2\nu \alpha}{\pi} \int_0^\infty e^{\frac{y + y^\prime}{2}} e^{-\alpha y^\prime} \dd y^\prime\right|\\
	&\le \frac{2\nu \alpha}{\pi \Mu{\BallPo{y}}} \int_0^{(1-\delta)(R-y)}\left|\Phi(y,y^\prime) - 
		e^{\frac{y + y^\prime}{2}} \right| e^{-\alpha y^\prime} \dd y^\prime
		+ \frac{2\nu \alpha}{\pi \Mu{\BallPo{y}}} \int_{(1-\delta)(R-y)}^\infty e^{\frac{y + y^\prime}{2}} 
		e^{-\alpha y^\prime} \dd y^\prime\\
	&\le \frac{2 K \nu \alpha}{\pi \Mu{\BallPo{y}}} e^{\frac{3}{2}y - R} \int_0^{(1-\delta)(R-y)} 	
		e^{(\frac{3}{2}-\alpha)y^\prime} \dd y^\prime +  e^{-(\alpha-\frac{1}{2})(1-\delta)(R-y)}.
\end{align*}
%\begin{align*}
%	\frac{2\nu \alpha}{\pi} \int_0^{(1-\delta)(R-y)} \Phi(y,y^\prime) e^{-\alpha y^\prime} 
%	&\le \frac{2\nu \alpha}{\pi} \int_{0}^{(1-\delta)(R-y)} \left(e^{\frac{y + y^\prime}{2}} + K e^{\frac{3}{2}(y + y^\prime) - R}\right)
%		e^{-\alpha y^\prime} \dd y^\prime\\
%	&= \Mu{\BallPo{0,y}}\left(1 - e^{-(\alpha - \frac{1}{2})(1-\delta)(R - y)}\right) \\
%	&\hspace{10pt}+ \frac{2\nu \alpha}{\pi} K e^{\frac{3 y}{2} - R}\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime
%\end{align*}
For the last term it holds that
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R}  e^{-(\alpha-\frac{1}{2})(1-\delta)(R-y)} = 0.
\]
We first compute the integral in the first term, which depends on the value of $\alpha$,
\[
	\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime
	= \begin{cases}
		\frac{2}{3 - 2\alpha}\left(e^{(\frac{3}{2} - \alpha)(1-\delta)(R-y)} - 1\right) &\mbox{if } 1/2 < \alpha < 3/2,\\
		(1-\delta)(R-y) &\mbox{if } \alpha = 3/2,\\
		\frac{2}{2\alpha-3}\left(1 - e^{-(\alpha - \frac{3}{2})(1-\delta)(R-y)}\right) &\mbox{if } \alpha > 3/2.
	\end{cases}
\]
This implies that
\begin{align*}
	&\frac{2 K \nu \alpha}{\pi \Mu{\BallPo{y}}} e^{\frac{3 y}{2} - R}
		\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime\\
	&= \begin{cases}
		\frac{(2\alpha - 1)K}{3 - 2\alpha}\left(e^{-(\alpha - \frac{1}{2})(R - y)-(\frac{3}{2}-\alpha)\delta(R-y)} 
			- e^{-(R - y)}\right)
		&\mbox{if } 1/2 < \alpha < 3/2,\\
		\frac{(2\alpha -1)K}{2} (1-\delta)(R - y)e^{-(R - y)} &\mbox{if } \alpha = 3/2,\\
		\frac{(2\alpha - 1)K}{2\alpha - 3} \left(e^{-(R - y)} - e^{-(\alpha - \frac{1}{2})(R - y) 
			-(\alpha - \frac{3}{2})(R-y)}\right)
		&\mbox{if } \alpha > 3/2,
	\end{cases}
\end{align*}
and hence
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R}
	\frac{2 K \nu \alpha}{\pi \Mu{\BallPo{y}}} e^{\frac{3 y}{2} - R}
			\int_0^{(1-\delta)(R-y)} e^{(\frac{3}{2} - \alpha)y^\prime} \dd y^\prime = 0,
\]
which completes the proof.
\end{proof}

We can now show that the measure of the balls in the KPKVB model and the infinite model are asymptotically equivalent.

\begin{lemma}\label{lem:average_degree_hyperbolic}
For any $0 < \varepsilon < 1$
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \left|\frac{\Mu{\BallHyp{y}}}{\Mu{\BallPo{y}}} - 1\right| = 0.
\]
\end{lemma}

\begin{proof}
We perform the computation of $\Mu{\BallHyp{y}}$ by splitting the integration with respect to the height $y^\prime$ into the cases $y^\prime > R - y$ and $y^\prime \le R - y$,
\[
	\Mu{\BallHyp{y}} 
	= \Mu{\BallHyp{y} \cap \Rcal ([0,R - y))} + \Mu{\BallHyp{y} \cap \Rcal ([R - y, R])}.
\]

For the first part we have that
\[
	\Mu{\BallHyp{(0,y)} \cap\Rcal[(0,R-y)]} = \frac{2\nu \alpha}{\pi} \int_0^{R-y} \Phi(y,y^\prime) e^{-\alpha y^\prime}
	\dd y^\prime.
\]
Hence, by applying Lemma~\ref{lem:hyperbolic_ball_lower_part} with $\delta = 0$ we conclude that
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \left|
	\frac{\Mu{\BallHyp{(y)} \cap\Rcal[(0,R-y)]}}{\Mu{\BallPo{y}}} - 1\right| = 0.
\]

For the second part we observer that $\BallHyp{(y)} \cap \Rcal ([R - y, R])= \Rcal([R-y,R])$. 
Thus, 
\begin{align*}
	&\hspace{-30pt}\Mu{\BallHyp{(y)} \cap \Rcal ([R - y, R])} \\
	&= \int_{R - y}^{R} \int_{I_n} f_{\alpha,\nu}(x^\prime, y^\prime) \dd x^\prime \dd y^\prime
		= \nu \alpha e^{R/2}\left(e^{-\alpha(R - y)} - e^{-\alpha R}\right)\\
	&= \Mu{\BallPo{y}} \frac{2\alpha - 1}{4\pi} \left( e^{-(\alpha - \frac{1}{2})(R - y)}
		- e^{-(\alpha - \frac{1}{2})R - y/2}\right), \numberthis \label{eq:mu_hyperbolic_ball_part_1}
\end{align*}
from which we conclude that
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \frac{\Mu{\BallHyp{(0,y)} \cap \Rcal ([R - y, R])}}{\Mu{\BallPo{y}}} = 0,
\]
which finishes the proof.
\end{proof}

A direct consequence of Lemma~\ref{lem:average_degree_hyperbolic} is that $\Mu{\BallHyp{y}} = \Mu{\BallPo{y}}(1 + \phi_n(y))$, where $\phi_n(y) := \Mu{\BallHyp{y}}/\Mu{\BallPo{y}} - 1$ satisfies condition i) in Lemma~\ref{lem:concentration_argument_rho_approximation}. To show that condition ii) is also satisfied we need to analyze
\[
	\phi_n^\prime(y) = 
	\Mu{\BallPo{y}}^{-1} \frac{\partial}{\partial y} \mu\left(\BallHyp{y}\right) -  \frac{1}{2} \frac{\Mu{\BallHyp{y}}}{\Mu{\BallPo{y}}},
\]
where we used that $\frac{\partial}{\partial y}\Mu{\BallPo{y}} = \frac{1}{2}\Mu{\BallPo{y}}$. Again, Lemma~\ref{lem:average_degree_hyperbolic} implies that 
\[
	\lim_{n \to \infty} \sup_{0 \le y \le (1-\varepsilon)R} \left|\frac{1}{2} \frac{\Mu{\BallHyp{y}}}{\Mu{\BallPo{y}}}
	- \frac{1}{2}\right| = 0.
\]
The following lemma shows that the same holds for the first term from which we conclude that $\phi_n(y)$ satisfies condition ii) in Lemma~\ref{lem:concentration_argument_rho_approximation}.

\begin{lemma}
For any $0 < \varepsilon < 1$,
\[
	\lim_{n \to \infty} \sup_{0 \le y \le (1-\varepsilon)R} \left|\Mu{\BallPo{y}}^{-1}
	\frac{\partial}{\partial y} \mu\left(\BallHyp{y}\right) - \frac{1}{2}\right| = 0.
\]
\end{lemma}

\begin{proof}
We again split $\Mu{\BallHyp{y}}$ over the top and bottom part,
\[
	\Mu{\BallHyp{y}} 
	= \Mu{\BallHyp{y} \cap \Rcal ([0,R - y))} + \Mu{\BallHyp{y} \cap \Rcal ([R - y, R])},
\]
where
\[
	\Mu{\BallHyp{y} \cap \Rcal ([0,R - y))} = \frac{2\alpha \nu}{\pi}\int_0^{R - y} \Phi(y,y^\prime) 
		e^{-\alpha y^\prime} \dd y^\prime,
\]
with $\Phi(y,y^\prime)$ defined as in~\eqref{eq:def_Omega_hyperbolic} and, see~\eqref{eq:mu_hyperbolic_ball_part_1},
\[
	\Mu{\BallHyp{y} \cap \Rcal ([R - y, R])}
	= \xi e^{y/2}\frac{2\alpha - 1}{4\pi} \left( e^{-(\alpha - \frac{1}{2})(R - y)}
	- e^{-(\alpha - \frac{1}{2})R - y/2}\right).
\]
Taking the derivative of the last expression gives
\begin{align*}
	&\frac{\partial}{\partial y} \Mu{\BallHyp{y} \cap \Rcal ([R - y, R])}\\
	&= \frac{1}{2}\Mu{\BallHyp{y} \cap \Rcal ([R - y, R])}
		+ \xi e^{y/2}\frac{2\alpha - 1}{4\pi}\left(
		\left(\alpha - \frac{1}{2}\right)e^{-(\alpha - \frac{1}{2})(R - y)} 
		+ \frac{1}{2}e^{-(\alpha - \frac{1}{2})R - y/2}\right)\\
	&= \frac{1}{2}\Mu{\BallHyp{y} \cap \Rcal ([R - y, R])}\left(1 +
		\frac{(2\alpha - 1)e^{-(\alpha - \frac{1}{2})(R - y)} + e^{-(\alpha - \frac{1}{2})R - y/2}}
		{e^{-(\alpha - \frac{1}{2})(R - y)} - e^{-(\alpha - \frac{1}{2})R - y/2}}\right).
\end{align*}
Since, $\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \Mu{\BallPo{y}}^{-1} \Mu{\BallHyp{y} \cap \Rcal ([R - y, R])} = 0$, we are left to show that
\begin{equation}\label{eq:derivative_mu_hyp_ball_main}
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \left|\Mu{\BallPo{y}}^{-1} \frac{2\alpha \nu}{\pi} \frac{\partial}{\partial y} \int_0^{R - y} \Phi(y,y^\prime) e^{-\alpha y^\prime} \dd y^\prime
	- \frac{1}{2}\right| = 0.
\end{equation}

We start with some preliminary computations. For convenience we define
\[
	\Xi(y,y^\prime) = 1 - \frac{\cosh(R- y)\cosh(R-y^\prime) - \cosh(R)}{\sinh(R - y) \sinh(R - y^\prime)},
\]
so that
\[
	\Phi(y, y^\prime) = \frac{1}{2}e^{R/2} \arccos\left(1 - \Xi(y,y^\prime)\right).
\]
Next, following the same calculation as in the proof of~\cite[Lemma 28]{fountoulakis2018law}, we write
\begin{align*}
	\Xi(y,y^\prime)
	&= 2 e^{-(R - y - y^\prime)} \frac{\left(1 - e^{y^\prime - y - R}\right)\left(1 - e^{y - y^\prime - R}\right)}
		{\left(1 - e^{-2(R - y^\prime)}\right)\left(1 - e^{-2(R- y)}\right)}\\
	&:= 2 e^{-(R - y - y^\prime)} \frac{h_1(y) h_2(y)}{h_3(y^\prime) h_3(y)},
\end{align*}
with
\[
	h_1(y) = 1 - e^{y^\prime - y - R}, \quad h_2(y) = 1 - e^{y - y^\prime - R}
	\quad \text{and} \quad h_3(y) = 1 - e^{-2(R- y)}.
\]
We suppressed the dependence on $n$ and, in some cases, on $y^\prime$ for notation convenience.

We make two important observations. First, $\Xi(y,y^\prime)$ is an increasing function in both arguments, for $y, y^\prime < R$ and $y + y^\prime < R$. Second, for all $y + y^\prime < R$, $h_1(y) \le h_3(y^\prime)$ and $h_2(y) \le h_3(y)$, while $h_3(y), h_3(y^\prime) < 1$, so that
\begin{equation}\label{eq:derivative_hyp_ball_Xi_bounds}
	2 e^{-(R - y - y^\prime)}h_1(y) h_2(y) \le \Xi(y,y^\prime) \le 2 e^{-(R - y - y^\prime)}.
\end{equation}
In particular, since $R-y$ is an increrasing function of $n$ uniformly on $0 < y < (1-\varepsilon)R$, there exists a $0 < \delta < 1$ such that $1/2 \le \Xi(y,y^\prime) < 2$ for all $y + y^\prime < R$ and $(1-\delta)(R-y) < y^\prime < R$ and $n$ large enough.

Next, taking the derivative of $\Xi(y,y^\prime)$ yields,
\begin{align*}
	\frac{\partial}{\partial y} \Xi(y,y^\prime) &= \Xi(y,y^\prime) + 2 e^{-(R - y - y^\prime)}
		\left(\frac{h_1^\prime(y) h_2(y)}{h_3(y^\prime) h_3(y)} + \frac{h_1(y)h_2^\prime(y)}{h_3(y^\prime) h_3(y)}
		- \frac{h_1(y) h_2(y) h_3^\prime(y)}{h_3(y^\prime) h_3(y)^2}\right)\\
	&= \Xi(y,y^\prime)\left(1 + \frac{h_1^\prime(y)}{h_1(y)} + \frac{h_2^\prime(y)}{h_2(y)} 
		- \frac{h_3^\prime(y)}{h_3(y)}\right)\\
	&:= \Xi(y,y^\prime)\left(1 + \varphi_n(y,y^\prime)\right),
\end{align*}
with
\[
	\varphi_n(y,y^\prime) = \frac{e^{y^\prime - y- R}}{1 - e^{y^\prime - y - R}} 
	- \frac{e^{y - y^\prime - R}}{1 - e^{y - y^\prime - R}} - \frac{2e^{-2(R - y)}}{1 - e^{-2(R-y)}}. 
\]
Therefore, by the chain rule,
\begin{align*}
	\frac{\partial}{\partial y} \Phi(y, y^\prime)
	&= \frac{1}{2}e^{R/2} \frac{1}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}} 
		\frac{\partial}{\partial y} \Xi(y,y^\prime)\\
	&=  \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}\left(1 + 
		\varphi_n(y,y^\prime)\right). \numberthis \label{eq:derivative_Phi}
\end{align*}
Applying the Leibniz's rule we then get
\begin{align*}
	&\hspace{-30pt}\frac{\partial}{\partial y} \int_0^{R - y} \Phi(y,y^\prime) e^{-\alpha y^\prime} \dd y^\prime\\
	&= - \Phi(y,R - y)e^{-\alpha(R-y)} + \int_0^{R - y} \frac{\partial}{\partial y}  \Phi(y,y^\prime) 
		 e^{-\alpha y^\prime} \dd y^\prime\\
	&= -\frac{1}{2}e^{-(\alpha-\frac{1}{2})R + \alpha y} + \int_0^{R- y} \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
		\left(1 + \varphi_n(y,y^\prime)\right) e^{-\alpha y^\prime} \dd y^\prime\\
	&= -\frac{1}{2}e^{-(\alpha-\frac{1}{2})R + \alpha y}  + \int_0^{(1-\delta)(R- y)} \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}
		{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
		\left(1 + \varphi_n(y,y^\prime)\right) e^{-\alpha y^\prime} \dd y^\prime\\
	&\hspace{10pt}+ \int_{(1-\delta)(R- y)}^{R - y} \frac{ \frac{1}{2}e^{R/2} \Xi(y,y^\prime)}
			{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
			\left(1 + \varphi_n(y,y^\prime)\right) e^{-\alpha y^\prime} \dd y^\prime\\
	&:= -I_1(y) + I_2(y) + I_3(y),
\end{align*}
with $0 \le \delta < 1$ such that $0 < \Xi(y,y^\prime) < 2$ for all $0 < y < R$ and $(1-\delta)(R-y) < y^\prime < R$.

We proceed by showing that
\begin{equation}\label{eq:derivative_hyp_ball_error_1}
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \left|\frac{I_t(y)}{\Mu{\BallPo{y}}}\right| 
	= 0, \quad \text{for } t = 1,3
\end{equation}
while
\begin{equation}\label{eq:derivative_hyp_ball_main_part}
	\lim_{n \to \infty} \sup_{0 \le y \le (1-\varepsilon)R} \left|\frac{2\nu \alpha}{\pi \Mu{\BallPo{y}}} I_2(y) - \frac{1}{2}\right| = 0.
\end{equation}
This then implies~\eqref{eq:derivative_mu_hyp_ball_main} and finishes the proof.

For $I_1(y)$ we have 
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \Mu{\BallPo{y}}^{-1} I_1(y) 
	\le \lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \frac{1}{2\xi} e^{-(\alpha - \frac{1}{2})(R - y)} = 0.
\]

For $I_3(y)$ we first use that $y^\prime < R - y$ to bound $\varphi(y,y^\prime)$ as follows,
\[
	\varphi_n(y,y^\prime) \le \frac{e^{y^\prime - y - R}}{1 - e^{y^\prime - y - R}} \le \frac{e^{-2y}}{1 - e^{-2y}}.
\]
This then yields that
\[
	I_3(y) \le \frac{1}{2}\left(1 + \frac{e^{-2y}}{1 - e^{-2y}}\right)e^{R/2}
	\int_{(1-\delta)(R- y)}^{R - y} \frac{ \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
	e^{-\alpha y^\prime} \dd y^\prime.
\]
To bound the integral we recall that $0 < \Xi(y,y^\prime) \le 2e^{-(R-y-y^\prime)} < 2$ and for all $1/2 \le x < 2$,
\[
	\frac{1}{\sqrt{1- (1-x)^2}} \le \frac{2}{\sqrt{2-x}},
\]a
where the right hand side is a monotonic increasing function.
Therefore
\begin{align*}
	\int_{(1-\delta)(R- y)}^{R - y} \frac{ \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
		e^{-\alpha y^\prime} \dd y^\prime
	&\le 2 \int_{(1-\delta)(R- y)}^{R - y} \frac{\Xi(y,y^\prime)}{\sqrt{(2-\Xi(y,y^\prime))}} e^{-\alpha y^\prime} 
		\dd y^\prime \\
	&\le \sqrt{2} e^{-\alpha(R - y)} \int_{(1-\delta)(R- y)}^{R - y} 
		\frac{e^{-(R - y - y^\prime)}}{\sqrt{1 - e^{-(R - y - y^\prime)}}} e^{\alpha (R - y - y^\prime)} \dd y^\prime,
\end{align*}
Making the change of variables $z = e^{-(R - y - y^\prime)}$ ($\dd y^\prime = z^{-1} \dd z$) we get that
\begin{align*}
	&\hspace{-20pt}\sqrt{2} e^{-\alpha(R - y)} \int_{(1-\delta)(R- y)}^{R - y} 
			\frac{e^{-(R - y - y^\prime)}}{\sqrt{1 - e^{-(R - y - y^\prime)}}} e^{\alpha (R - y - y^\prime)} \dd y^\prime\\
	&= \sqrt{2} e^{-\alpha(R - y)} \int_{e^{-\delta (R - y)}}^{1} \frac{z^{-\alpha}}{\sqrt{1 - z}} \dd z
		\le \sqrt{2} e^{-\alpha(R - y)} \sqrt{1 - e^{-\delta (R - y)}}
		\le \sqrt{2} e^{-\alpha (R -y)}.
\end{align*}
We therefore conclude that
\[
	I_3(y) \le \frac{1}{\sqrt{2}} \left(1 + \frac{e^{-2y}}{1 - e^{-2y}}\right)e^{-(\alpha -\frac{1}{2})R + \alpha y}.
\]
which implies~\eqref{eq:derivative_hyp_ball_error_1} for $t=3$.

Finally, to show~\eqref{eq:derivative_hyp_ball_main_part} we first write
\begin{align*}
	\left|\frac{2\alpha \nu}{\pi \Mu{\BallPo{y}}} I_2(y) - \frac{1}{2}\right|
	&\le \left|\frac{2\alpha \nu}{\pi \Mu{\BallPo{y}}}  \int_0^{(1-\delta)(R- y)} \frac{\Phi(y,y^\prime)}{2} 
		e^{-\alpha y^\prime} \dd y^\prime - \frac{1}{2}\right| \\
	&\hspace{10pt}+ \frac{2\alpha \nu}{\pi \Mu{\BallPo{y}}}\left|\int_0^{(1-\delta)(R- y)} 
		\frac{\Phi(y,y^\prime)}{2} e^{-\alpha y^\prime} \dd y^\prime - I_2(y)\right|.
\end{align*}
By Lemma~\ref{lem:hyperbolic_ball_lower_part},
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \left|\frac{2\nu \alpha}{\pi \Mu{\BallPo{y}}} 
	\int_{0}^{(1-\delta)(R-y)} \Phi(y,y^\prime) \alpha e^{-\alpha y^\prime} \dd y^\prime
	- 1\right| = 0,
\] 
and thus it suffices to show that the $\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R}$ of the second term goes to zero.

Recalling the definition of $I_2(y)$ we have
\begin{align*}
	&\hspace{-30pt}\left|\int_0^{(1-\delta)(R- y)} \frac{\Phi(y,y^\prime)}{2} e^{-\alpha y^\prime} \dd y^\prime 
		- I_2(y)\right|\\
	&\le \int_0^{(1-\delta)(R- y)} \left|\frac{\Phi(y,y^\prime)}{2}- \frac{\frac{1}{2}e^{R/2} \Xi(y,y^\prime)}
		{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}(1+\varphi_n(y,y^\prime)\right|e^{-\alpha y^\prime} \dd y^\prime.
		\numberthis \label{eq:derivative_hyp_ball_final_error}
\end{align*}
We will oroceed to bound the term inside the integral. For this we first note that for $0 \le y^\prime \le (1-\delta)(R-y)$,
\[
	\varphi_n(y,y^\prime) \le \frac{e^{-\delta(R-y)}}{1 - e^{-\delta(R-y)}}.
\]
and recall that $\Xi(y,y^\prime) \le 2 e^{-(R-y-y^\prime)}$. Moreover, since $x/\sqrt{1-(1-x)^2} = x/\sqrt{2x-x^2}$ is an increasing function and $e^{-(R - y - y^\prime)} \le e^{-\delta(R- y)}$ for $0 < y^\prime < (1-\delta)(R-y)$,
\[
	\frac{\frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}
	\le e^{R/2} \frac{e^{-\delta(R-y)}}{\sqrt{2e^{-\delta(R-y)} - e^{-2\delta(R-y)}}}.
\]
Next, recall that $\Phi(y,y^\prime) = \frac{1}{2}e^{R/2}\arccos(1-\Xi(y,y^\prime))$. Then, since $\Xi(y,y^\prime) < 1$ for all $y^\prime < (1-\delta)(R-y)$, $y < R$ and $n$ large enough, we have (see Lemma~\ref{lem:arccos_approx}),
\[
	\left|\frac{1}{2}\Phi(y,y^\prime) - \frac{\frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}}\right| \le \frac{1}{2}\Phi(y,y^\prime) \Xi(y,y^\prime).
\]
for all $y^\prime < (1-\delta)(R - y)$ and $y < R$. Togehter these facts imply that for $n$ large enough
\begin{align*}
	&\hspace{-30pt}\left|\frac{\Phi(y,y)}{2} - \frac{\frac{1}{2}e^{R/2} \Xi(y,y^\prime)}{\sqrt{1 - \left(1 - 	
		\Xi(y,y^\prime)\right)^2}}(1+\varphi_n(y,y^\prime))\right|\\
	&\le \frac{\Phi(y,y^\prime)\Xi(y,y^\prime)}{2} 
		+ \frac{\frac{1}{2}e^{R/2} \Xi(y,y^\prime) \varphi_n(y,y^\prime)}
		{\sqrt{1 - \left(1 - \Xi(y,y^\prime)\right)^2}} \\
	&\le e^{-\delta(R-y)} \Phi(y,y^\prime) + \frac{e^{-\delta(R-y)}}{1-e^{-\delta(R-y)}}
		\frac{e^{R/2} e^{-\delta(R-y)}}{\sqrt{2e^{-\delta(R-y)} - e^{-2\delta(R-y)}}}\\
	&\le e^{-\delta(R-y)} \Phi(y,y^\prime) + \frac{e^{\frac{R}{2}}e^{-\frac{3}{2}\delta(R-y)}}
		{\left(1 - e^{-\delta(R-y)}\right)^{3/2}}
\end{align*}

Plugging this into~\eqref{eq:derivative_hyp_ball_final_error} yields
\begin{align*}
	&\hspace{-30pt}\left|\int_0^{(1-\delta)(R- y)} \frac{\Phi(y,y^\prime)}{2} e^{-\alpha y^\prime} \dd y^\prime 
			- I_2(y)\right|\\
	&\le \int_0^{(1-\delta)(R- y)} \left(e^{-\delta(R-y)} \Phi(y,y^\prime) + 
		\frac{e^{\frac{R}{2}}e^{-\frac{3}{2}\delta(R-y)}}{\left(1 - e^{-\delta(R-y)}\right)^{3/2}}\right)
		e^{-\alpha y^\prime} \dd y^\prime \\
	&\le e^{-\delta(R-y)} \Mu{\BallPo{y}} + e^{\frac{y}{2}} \frac{e^{-(\alpha - \frac{1}{2} - (\alpha - \frac{3}{2})\delta)(R-y)}}
		{\alpha \left(1 - e^{-\delta(R-y)}\right)^{3/2}}
\end{align*}
To finish the argument we note that $R-y > 0$ for all $0 < y \le (1-\varepsilon)R$ and observe that $\delta < 1$ implies that $(\alpha - \frac{1}{2} - (\alpha - \frac{3}{2})\delta > 1$. Since $\Mu{\BallPo{y}} = \bigT{e^{\frac{y}{2}}}$ it the
then follows that
\[
	\lim_{n \to \infty} \sup_{0 < y \le (1-\varepsilon)R} \frac{2\alpha \nu}{\pi \Mu{\BallPo{y}}}
	\left|\int_0^{(1-\delta)(R- y)} \frac{\Phi(y,y^\prime)}{2} e^{-\alpha y^\prime} \dd y^\prime - I_2(y)\right| = 0,
\]
which completes the proof.
\end{proof}

We now conclude that similar to Corollary~\ref{cor:concentration_of_heights_Gbox}, the concentration of heights results also hold for $\rho_{\Po}(y,k_n)$.

\begin{corollary}\label{cor:concentration_of_heights_GPo}
The statement in Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n}
and~\ref{cor:concentration_heights_asymptotics_n} hold when we replace $\rho(y,k_n)$ with $\rho_{\Po}(y,k_n)$.
\end{corollary}

\begin{remark}[Generalized concentration of heights arguments]
Since the results from Corollaries~\ref{cor:concentration_of_heights_asymptotics}, \ref{cor:concentration_heights_bounds_n} and~\ref{cor:concentration_heights_asymptotics_n} hold for any of the three functions $\rho(y,k_n)$, $\rho_{\text{box}}(y,k_n)$ and $\rho_{\Po}(y,k_n)$, we will will refer only to one of these three when using a concentration of heights argument of for any of the three models $\GPo$, $\Gbox$ and $\Ginf$. 
\end{remark}
